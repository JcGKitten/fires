{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from fires import FIRES\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paint mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def paint_digit(digit_values):\n",
    "    plt.figure()\n",
    "    plt.imshow(digit_values.reshape(28,28))\n",
    "    plt.gray()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.show"
   ]
  },
  {
   "source": [
    "### Test binary version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data as scikit-multiflow FileStream\n",
    "#\n",
    "stream = FileStream('datasets/binary/mnist_train_binary.csv', target_idx=0)\n",
    "stream.prepare_for_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial fit of the predictive model\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=100)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_model = FIRES(n_total_ftr=stream.n_features,\n",
    "                    target_values=stream.target_values,\n",
    "                    mu_init=0,\n",
    "                    sigma_init=1,\n",
    "                    model='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_selected_ftr = 100\n",
    "\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=10)\n",
    "\n",
    "    # Select features\n",
    "    ftr_weights = fires_model.weigh_features(x, y)  # Get feature weights with FIRES\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x)\n",
    "    print(accuracy_score(y, y_pred))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"235.34pt\" version=\"1.1\" viewBox=\"0 0 235.34 235.34\" width=\"235.34pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-01T11:05:59.731348</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 235.34 \nL 235.34 235.34 \nL 235.34 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 10.7 224.64 \nL 228.14 224.64 \nL 228.14 7.2 \nL 10.7 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pbb9a4eb911)\">\n    <image height=\"218\" id=\"image5eaff0659a\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"10.7\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAADCElEQVR4nO3dQWrDMBBAUbn0/ldOt10EQp3qS47fO4E3nwEPko4xxmMAU32t/gC4A6FBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUHge/UHfKrH4/xrWMdx/OOXsAMTDQJCg4DQICA0CAgNAkKDgNAgcIwxzi98buydPdls9nD7MdEgIDQICA0CQoOA0CAgNAgIDQL2aJPYs/GbiQYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUHAs02TvHMUZecjNpxjokFAaBAQGgSEBgGhQUBoEBAaBFw3d0Ez92yuopvDRIOA0CAgNAgIDQJCg4DQICA0CDiPxp+82uHZwz1nokFAaBAQGgSEBgGhQUBoEBAaBJxHW+DK9zbak51jokFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQ8GzTAq+ubLvydXQ8Z6JBQGgQEBoEhAYBoUFAaBAQGgTs0fiTVzs+zzo9Z6JBQGgQEBoEhAYBoUFAaBAQGgTs0RZw3ux+TDQICA0CQoOA0CAgNAgIDQLHGMO/5glW/sLf+Tq7ux6jMdEgIDQICA0CQoOA0CAgNAgIDQKOyXwgx3D2Y6JBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoE3Ou4wJXPi931XsZ3mWgQEBoEhAYBoUFAaBAQGgSEBgF7tA15v+zzmGgQEBoEhAYBoUFAaBAQGgQ827Sh2b/Yr3xM56pMNAgIDQJCg4DQICA0CAgNAkKDgGMyEDDRICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CPwAv1E6rZqdTSMAAAAASUVORK5CYII=\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 10.7 224.64 \nL 10.7 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 228.14 224.64 \nL 228.14 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 10.7 224.64 \nL 228.14 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 10.7 7.2 \nL 228.14 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbb9a4eb911\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"10.7\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADgElEQVR4nO3dQU4jMRBAURtxj7n/sWbPHcyKxUgDTUg68Q/vLUkkzOKrkErunmutAezv5dEHAL5HrBAhVogQK0SIFSLEChGvl3x5zmnPAydba83//dxkhQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIeH30AdjbWuvTz+acdzwJJitEiBUixAoRYoUIsUKEWCFCrBBhzxr31R6U52KyQoRYIUKsECFWiBArRIgVIqxuNrfzaubobK7Q3ZbJChFihQixQoRYIUKsECFWiBArRNizbmDnXeo1rv277Gn/ZbJChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChHus/5yR3dGn/WubZHJChFihQixQoRYIUKsECFWiBArRNizbuCrXefZe85H7lE9F/gyJitEiBUixAoRYoUIsUKEWCHC6mZzrrDxwWSFCLFChFghQqwQIVaIECtEiBUi7Fk5jStwt2WyQoRYIUKsECFWiBArRIgVIsQKEfasm3NflQ8mK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCHCo0g3d+1rE898lOnR2Y5+t1dCXsZkhQixQoRYIUKsECFWiBArRIgVIuxZOY096m2ZrBAhVogQK0SIFSLEChFihQixQoQ9a9yZ91XHsCvdickKEWKFCLFChFghQqwQIVaIECtE2LNu4OxdKc/BZIUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRLgidwc7X4HzqNEOkxUixAoRYoUIsUKEWCFCrBAhVoiwZ72Do13mNXtYe9Lfw2SFCLFChFghQqwQIVaIECtEiBUi7Fk3YFfKd5isECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFiEtf+fg2xvh7xkGAMcYYfz77YK617nkQ4If8GwwRYoUIsUKEWCFCrBAhVogQK0SIFSLEChHvrUNA337fhHMAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "paint_digits = np.zeros(784)\n",
    "paint_digits[ftr_selection] = 1\n",
    "\n",
    "\n",
    "paint_digit(paint_digits)"
   ]
  },
  {
   "source": [
    "### Test multiclass version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multiclass\n",
    "\n",
    "stream = FileStream('datasets/Multiclass/mnist_train_normalized.csv', target_idx=0)\n",
    "stream.prepare_for_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PerceptronMask(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "               fit_intercept=True, max_iter=1000, n_iter_no_change=5,\n",
       "               n_jobs=None, penalty=None, random_state=0, shuffle=True,\n",
       "               tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "\n",
    "# Initial fit of the predictive model\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=100)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_model = FIRES(n_total_ftr=stream.n_features,\n",
    "                    target_values=stream.target_values,\n",
    "                    mu_init=0,\n",
    "                    sigma_init=1,\n",
    "                    model='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(y) 2\n",
      "obs_class: 0, n obs: 1\n",
      "obs_class: 1, n obs: 3\n",
      "obs_class: 2, n obs: 1\n",
      "obs_class: 3, n obs: 1\n",
      "obs_class: 5, n obs: 1\n",
      "obs_class: 6, n obs: 1\n",
      "obs_class: 7, n obs: 2\n",
      "0.6\n",
      "len(y) 2\n",
      "obs_class: 0, n obs: 3\n",
      "obs_class: 1, n obs: 2\n",
      "obs_class: 2, n obs: 1\n",
      "obs_class: 3, n obs: 1\n",
      "obs_class: 4, n obs: 1\n",
      "obs_class: 9, n obs: 2\n",
      "0.7\n",
      "len(y) 2\n",
      "obs_class: 0, n obs: 1\n",
      "obs_class: 1, n obs: 2\n",
      "obs_class: 2, n obs: 2\n",
      "obs_class: 4, n obs: 1\n",
      "obs_class: 6, n obs: 2\n",
      "obs_class: 7, n obs: 1\n",
      "obs_class: 8, n obs: 1\n",
      "0.8\n",
      "len(y) 2\n",
      "obs_class: 1, n obs: 1\n",
      "obs_class: 3, n obs: 3\n",
      "obs_class: 4, n obs: 2\n",
      "obs_class: 5, n obs: 2\n",
      "obs_class: 8, n obs: 1\n",
      "obs_class: 9, n obs: 1\n",
      "0.4\n",
      "len(y) 2\n",
      "obs_class: 2, n obs: 1\n",
      "obs_class: 3, n obs: 1\n",
      "obs_class: 4, n obs: 1\n",
      "obs_class: 5, n obs: 1\n",
      "obs_class: 6, n obs: 1\n",
      "obs_class: 7, n obs: 3\n",
      "obs_class: 8, n obs: 2\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "n_selected_ftr = 100\n",
    "i = 0\n",
    "while i < 5:  #stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=10)\n",
    "    # Select features\n",
    "    ftr_weights = fires_model.weigh_features(x, y)  # Get feature weights with FIRES\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x)\n",
    "    print(accuracy_score(y, y_pred))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x, y)\n",
    "    i += 1\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"235.34pt\" version=\"1.1\" viewBox=\"0 0 235.34 235.34\" width=\"235.34pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-01T11:10:40.973676</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 235.34 \nL 235.34 235.34 \nL 235.34 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 10.7 224.64 \nL 228.14 224.64 \nL 228.14 7.2 \nL 10.7 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pae7cdad51d)\">\n    <image height=\"218\" id=\"imageee2762310b\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"10.7\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAADCElEQVR4nO3dQWrDMBBAUbn0/ldOt10EQp3qS47fO4E3nwEPko4xxmMAU32t/gC4A6FBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUHge/UHfKrH4/xrWMdx/OOXsAMTDQJCg4DQICA0CAgNAkKDgNAgcIwxzi98buydPdls9nD7MdEgIDQICA0CQoOA0CAgNAgIDQL2aJPYs/GbiQYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUHAs02TvHMUZecjNpxjokFAaBAQGgSEBgGhQUBoEBAaBFw3d0Ez92yuopvDRIOA0CAgNAgIDQJCg4DQICA0CDiPxp+82uHZwz1nokFAaBAQGgSEBgGhQUBoEBAaBJxHW+DK9zbak51jokFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQ8GzTAq+ubLvydXQ8Z6JBQGgQEBoEhAYBoUFAaBAQGgTs0fiTVzs+zzo9Z6JBQGgQEBoEhAYBoUFAaBAQGgTs0RZw3ux+TDQICA0CQoOA0CAgNAgIDQLHGMO/5glW/sLf+Tq7ux6jMdEgIDQICA0CQoOA0CAgNAgIDQKOyXwgx3D2Y6JBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoE3Ou4wJXPi931XsZ3mWgQEBoEhAYBoUFAaBAQGgSEBgF7tA15v+zzmGgQEBoEhAYBoUFAaBAQGgQ827Sh2b/Yr3xM56pMNAgIDQJCg4DQICA0CAgNAkKDgGMyEDDRICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CPwAv1E6rZqdTSMAAAAASUVORK5CYII=\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 10.7 224.64 \nL 10.7 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 228.14 224.64 \nL 228.14 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 10.7 224.64 \nL 228.14 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 10.7 7.2 \nL 228.14 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pae7cdad51d\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"10.7\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADgElEQVR4nO3dQU4jMRBAURtxj7n/sWbPHcyKxUgDTUg68Q/vLUkkzOKrkErunmutAezv5dEHAL5HrBAhVogQK0SIFSLEChGvl3x5zmnPAydba83//dxkhQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIeH30AdjbWuvTz+acdzwJJitEiBUixAoRYoUIsUKEWCFCrBBhzxr31R6U52KyQoRYIUKsECFWiBArRIgVIqxuNrfzaubobK7Q3ZbJChFihQixQoRYIUKsECFWiBArRNizbmDnXeo1rv277Gn/ZbJChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChHus/5yR3dGn/WubZHJChFihQixQoRYIUKsECFWiBArRNizbuCrXefZe85H7lE9F/gyJitEiBUixAoRYoUIsUKEWCHC6mZzrrDxwWSFCLFChFghQqwQIVaIECtEiBUi7Fk5jStwt2WyQoRYIUKsECFWiBArRIgVIsQKEfasm3NflQ8mK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCHCo0g3d+1rE898lOnR2Y5+t1dCXsZkhQixQoRYIUKsECFWiBArRIgVIuxZOY096m2ZrBAhVogQK0SIFSLEChFihQixQoQ9a9yZ91XHsCvdickKEWKFCLFChFghQqwQIVaIECtE2LNu4OxdKc/BZIUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRLgidwc7X4HzqNEOkxUixAoRYoUIsUKEWCFCrBAhVoiwZ72Do13mNXtYe9Lfw2SFCLFChFghQqwQIVaIECtEiBUi7Fk3YFfKd5isECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFiEtf+fg2xvh7xkGAMcYYfz77YK617nkQ4If8GwwRYoUIsUKEWCFCrBAhVogQK0SIFSLEChHvrUNA337fhHMAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "paint_digits = np.zeros(784)\n",
    "paint_digits[ftr_selection] = 1\n",
    "\n",
    "\n",
    "paint_digit(paint_digits)"
   ]
  },
  {
   "source": [
    "### test regression version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}