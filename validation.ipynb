{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39164bit782dbb36b7b848238b8e7e5b770c6244",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Validation notebook\n",
    "Here the FIRES implementation for multiclass and regression is validated and compared to other online features selcetion algorithms.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the functions needed for validate and comparsion\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skmultiflow.data import FileStream, RandomRBFGenerator, ConceptDriftStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier, ExtremelyFastDecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# using plotly for plots\n",
    "#import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paint mnist\n",
    "def paint_digit(digit_values):\n",
    "    fig = px.imshow(digit_values.reshape(28,28), binary_string=True)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    #fig.show()\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stability import stability_factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithms\n",
    "from fires import FIRES\n",
    "from ofs import OFS, MC_OFS\n",
    "from ofssgr import OFSSGD, MC_OFSSGD\n",
    "from fsds import StreamFeatWeight"
   ]
  },
  {
   "source": [
    "## Multiclass Data\n",
    "\n",
    "Here the FIRES softmax implementation is compared to the FSDS, OFS and OFSSGD oun multiclass data.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Load Datasets as Streaming Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set n_selected ftr\n",
    "#per_ftr = 0.5\n",
    "per_ftr = 0.25\n",
    "#per_ftr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data normalized\n",
    "stream = FileStream('datasets/Multiclass/mnist_train_normalized.csv', target_idx=0)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"mnist_norm\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/mnist_test_normalized.csv', header=None)\n",
    "test_y = test_data[0].to_numpy()\n",
    "test_x = test_data.drop(columns=0).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human Activity Recognition\n",
    "# labels changed from [1,...,6] to [0,...,5]\n",
    "# rows shuffled\n",
    "# split into train set with 7352 instances and test set with 2948\n",
    "stream = FileStream('datasets/Multiclass/har_train.csv', target_idx = 561)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"har\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/har_test.csv')\n",
    "test_y = test_data[\"Class\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"Class\").to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human Activity Recognition\n",
    "# labels changed from [1,...,6] to [0,...,5]\n",
    "# rows shuffled\n",
    "# split into train set with 7352 instances and test set with 2948\n",
    "stream = FileStream('datasets/Multiclass/har_train_norm.csv', target_idx = 561)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"har_norm\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 50\n",
    "weights = None\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/har_test_norm.csv')\n",
    "test_y = test_data[\"Class\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"Class\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covtype scaled to 0,1\n",
    "# https://archive.ics.uci.edu/ml/datasets/covertype\n",
    "\n",
    "# rows shuffled\n",
    "# split into train set with 400000 instances and test set with 180000\n",
    "stream = FileStream('datasets/Multiclass/covtype.scale01.test.csv', target_idx = 0)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"covtype\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 50\n",
    "batch_size = 100\n",
    "weights = [0.36460521, 0.48759922, 0.06153746, 0.00472796, 0.01633873, 0.02989095, 0.03530047]\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/covtype.scale01.train.csv', header=None)\n",
    "test_y = test_data[0].to_numpy()\n",
    "test_x = test_data.drop(columns=0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_true_ftrs_indices(label_names, start_char):\n",
    "    indices = []\n",
    "    for i in range(len(label_names)):\n",
    "        if label_names[i].startswith(start_char):\n",
    "            indices.append(i)\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset 1 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_1_train_norm.csv', target_idx=100)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_1\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 50\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_1_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset 2 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_2_train_norm.csv', target_idx=500)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_2\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 50\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_2_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset 3 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_3_train_norm.csv', target_idx=250)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_3\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features)) # 20 are really informative\n",
    "n_window = 10\n",
    "batch_size = 20\n",
    "weights = [0.1, 0.05, 0.15, 0.2, 0.025, 0.125, 0.075, 0.275]\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_3_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset 4 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_4_train_norm.csv', target_idx=210)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_4\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights=None\n",
    "check_ftrs = False\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_4_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()"
   ]
  },
  {
   "source": [
    "## Set trainings algorithms settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_settings = {}\n",
    "\n",
    "MLP_settings = {}\n",
    "\n",
    "hoeffding_settings = {\"leaf_prediction\":\"mc\"}\n",
    "\n",
    "fast_decision_settings = {\"split_criterion\":\"info_gain\",\n",
    "                          \"split_confidence\":0.0001,\n",
    "                          \"leaf_prediction\":\"mc\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_algo = \"perceptron\"\n",
    "pred_algo = \"mlp\"\n",
    "#pred_algo = \"hoeffding\"\n",
    "#pred_algo = 'fast_decision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare folder for plots\n",
    "folder = \"plots/{}/{}/{}\".format(dataset_name, pred_algo,int(100*per_ftr))\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "export_type = \"pdf\" # \"png\", \"jpeg\", \"webp\", \"pdf\", \"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'plots/har/mlp/25'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "folder"
   ]
  },
  {
   "source": [
    "### Test without feature selection\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuarcy_pure = []\n",
    "f1_pure = []\n",
    "precision = []\n",
    "recall = []\n",
    "while stream.has_more_samples():\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    y_pred = predictor.predict(x)\n",
    "    \n",
    "    accuarcy_pure.append(accuracy_score(y, y_pred))\n",
    "    f1_pure.append(f1_score(y, y_pred, stream.target_values, \n",
    "    average=\"weighted\" ))\n",
    "    precision.append(precision_score(y, y_pred, stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "    recall.append(recall_score(y, y_pred, stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    predictor.partial_fit(x,y)\n",
    "\n",
    "pure_moving_average = pd.Series(accuarcy_pure).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "pure_f1 = pd.Series(f1_pure).rolling(window=n_window).mean().iloc[n_window-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_no_ofs = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_no_ofs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = pd.Series(precision).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "recall = pd.Series(recall).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "f1_pure = pd.Series(f1_pure).rolling(window=n_window).mean().iloc[n_window-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names = [\"accuracy\",\"f1\", \"precision\", \"recall\"]\n",
    "#d = {\"accuracy\":pure_moving_average, \"f1\":f1_pure, \"precision\":precision,\n",
    "#\"recall\":recall}\n",
    "#df = pd.DataFrame(d, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig = px.line(df)\n",
    "#fig.show()"
   ]
  },
  {
   "source": [
    "### FIRES Framework"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_model = FIRES(n_total_ftr=stream.n_features,\n",
    "                    target_values=stream.target_values,\n",
    "                    mu_init=0,\n",
    "                    sigma_init=1,\n",
    "                    model='softmax',\n",
    "                    class_probabilities=weights,\n",
    "                    lr_mu=0.5,\n",
    "                    lr_sigma=0.5,\n",
    "                    number_monte_carlo_samples=10)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The marginal likelihood of class 2 reached 0. This will cause the feature weights to become NaN. Try to normalize your data or reduce learning rate.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dd44c510bd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Select features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mftr_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfires_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweigh_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mftr_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftr_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_selected_ftr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfires_cuda_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fires/fires.py\u001b[0m in \u001b[0;36mweigh_features\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcupy_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__softmax_cp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__softmax_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fires/fires.py\u001b[0m in \u001b[0;36m__softmax_cp\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m                                    \u001b[0;34m\"your data or reduce learning rate.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                                    ).format(obs_class)\n\u001b[0;32m--> 270\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0;31m# calculate softmax derivative to theta:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The marginal likelihood of class 2 reached 0. This will cause the feature weights to become NaN. Try to normalize your data or reduce learning rate."
     ]
    }
   ],
   "source": [
    "fires_cuda_accuracy = []\n",
    "fires_f1 = []\n",
    "fires_cuda_times = []\n",
    "\n",
    "fires_cuda_selected_ftrs = []\n",
    "fires_cuda_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "\n",
    "while stream.has_more_samples():\n",
    "#for i in range(1):\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    ftr_weights = fires_model.weigh_features(x,y)\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    fires_cuda_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    fires_cuda_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(fires_cuda_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(fires_cuda_selected_ftrs[-10:])\n",
    "        fires_cuda_stability.append(stability)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    fires_cuda_accuracy.append(accuracy_score(y, y_pred))\n",
    "    fires_f1.append(f1_score(y, y_pred, average=\"weighted\",\n",
    "    labels=stream.target_values))\n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "fires_cuda_run_time = timer() - start_time_all\n",
    "print(\"The whole FIRES run took {}\".format(fires_cuda_run_time))\n",
    "\n",
    "fires_moving_average = pd.Series(fires_cuda_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "fires_f1 = pd.Series(fires_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "    mnist_fig_fires = paint_digit(selection_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fires_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs) * 100\n",
    "    print(\"FIRES found {}% of the true informative features.\".format(fires_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_fires = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### FSDS algorithm\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fsds_model = StreamFeatWeight(m=stream.n_features, k=stream.n_classes)\n",
    "fsds_model.low_rank_approximation(x.T) # needs some pretraining in the first run\n",
    "\n",
    "fsds_selected_ftrs = []\n",
    "fsds_stability = []\n",
    "\n",
    "fsds_accuracy = []\n",
    "fsds_f1 = []\n",
    "fsds_times = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    ftr_weights = fsds_model.low_rank_approximation(x.T)\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    fsds_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "     # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    fsds_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(fsds_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(fsds_selected_ftrs[-10:])\n",
    "        fsds_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    fsds_accuracy.append(accuracy_score(y, y_pred))\n",
    "    fsds_f1.append(f1_score(y, y_pred, average=\"weighted\", \n",
    "    labels=stream.target_values))\n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "fsds_run_time = timer() - start_time_all\n",
    "print(\"The whole fsds run took {}\".format(fsds_run_time))\n",
    "\n",
    "fsds_moving_average = pd.Series(fsds_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "fsds_f1 = pd.Series(fsds_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    \n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "\n",
    "    mnist_fig_fsds = paint_digit(selection_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fsds_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs) * 100\n",
    "    print(\"FSDS found {}% of the true informative features.\".format(fsds_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_fsds = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_fsds))"
   ]
  },
  {
   "source": [
    "### OFS algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ofs = MC_OFS(regularization_param = 0.01, step_size = 0.2, n_selected_ftr=n_selected_ftr, n_total_ftr=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n",
    "ofs_accuracy = []\n",
    "ofs_f1 = []\n",
    "ofs_selected_ftrs = []\n",
    "ofs_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    # Select features\n",
    "    for idx, label in enumerate(y):\n",
    "        ofs.train(x[idx],label)\n",
    "\n",
    "    ftr_selection = ofs.get_feature_indices()\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "     # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    ofs_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(ofs_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(ofs_selected_ftrs[-10:])\n",
    "        ofs_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    ofs_accuracy.append(accuracy_score(y, y_pred))\n",
    "    ofs_f1.append(f1_score(y,y_pred, labels=stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "ofs_run_time = timer() - start_time_all\n",
    "print(\"The whole ofs run took {}\".format(ofs_run_time))\n",
    "\n",
    "ofs_moving_average = pd.Series(ofs_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "ofs_f1 = pd.Series(ofs_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "    mnist_fig_ofs = paint_digit(selection_array)\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    ofs_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs)* 100\n",
    "    print(\"OFS found {}% of the true informative features.\".format(fsds_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_ofs = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_ofs))"
   ]
  },
  {
   "source": [
    "### OFSSGR algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ofssgd_model = MC_OFSSGD(reduction_threshold=0.4, reduction_value=0.1, regularization_param=0.01, step_size=0.2, n_total_ftrs=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n",
    "ofssgd_accuracy = []\n",
    "ofssgd_f1 = []\n",
    "ofssgd_selected_ftrs = []\n",
    "ofssgd_stability = []\n",
    "ofssgd_n_ftrs_selected = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    # Select features\n",
    "    for idx, label in enumerate(y):\n",
    "        ofssgd_model.train(x[idx],label)\n",
    "\n",
    "    ftr_selection = ofssgd_model.get_feature_indices()\n",
    "    ofssgd_n_ftrs_selected.append(len(ftr_selection))\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    ofssgd_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(ofssgd_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(ofssgd_selected_ftrs[-10:])\n",
    "        ofssgd_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    ofssgd_accuracy.append(accuracy_score(y, y_pred))\n",
    "    ofssgd_f1.append(f1_score(y, y_pred, labels=stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "ofssgd_run_time = timer() - start_time_all\n",
    "print(\"The whole ofssgd run took {}\".format(ofssgd_run_time))\n",
    "\n",
    "ofssgd_moving_average = pd.Series(ofssgd_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "ofssgd_f1 = pd.Series(ofssgd_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "    mnist_fig_ofssgd = paint_digit(selection_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    ofssgd_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs) * 100\n",
    "    print(\"OFSSGD found {}% of the true informative features.\".format(ofssgd_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_ofssgd = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_ofssgd))"
   ]
  },
  {
   "source": [
    "### Pick n random ftrs in each iteration as benchmark"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_accuracy = []\n",
    "random_f1 = []\n",
    "random_selected_ftrs = []\n",
    "random_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    # select features\n",
    "    ftr_selection = np.random.choice(len(x[0]), n_selected_ftr)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    random_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(random_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(random_selected_ftrs[-10:])\n",
    "        random_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    random_accuracy.append(accuracy_score(y, y_pred))\n",
    "    random_f1.append(f1_score(y, y_pred, labels=stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "random_run_time = timer() - start_time_all\n",
    "print(\"The whole random run took {}\".format(random_run_time))\n",
    "random_moving_average = pd.Series(random_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "random_f1 = pd.Series(random_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n"
   ]
  },
  {
   "source": [
    "### Plot all\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability\n",
    "title = \"Stability on dataset {}\".format(dataset_name)\n",
    "col_names = [\"FIRES\", \"OFS\", \"OFSSGD\", \"FSDS\"]\n",
    "d = {\"FIRES\":fires_cuda_stability, \"OFS\":ofs_stability, \"OFSSGD\":ofssgd_stability, \"FSDS\":fsds_stability} #\"random\":random_stability\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y = col_names, title=title, labels={\"index\":\"batches\", \"value\":\"stability\"},color_discrete_map={'FIRES': 'red', \n",
    "                                                    'OFS': 'purple','FSDS': 'green', \"OFSSGD\":\"yellow\"})\n",
    "fig.write_image(\"{}/stability.{}\".format(folder, export_type))\n",
    "stability_trace = fig['data']\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean values\n",
    "csv_name = \"{}/stability_avg.csv\".format(folder)\n",
    "df.mean().to_csv(csv_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving averages\n",
    "title = \"Moving averages over accuracy while learning with window {} on dataset {}\".format(n_window, dataset_name)\n",
    "col_names = [\"Pure\",\"FIRES\", \"OFS\", \"OFSSGD\", \"random\",\"FSDS\"]# \n",
    "d = {\"Pure\":pure_moving_average, \"FIRES\":fires_moving_average, \"OFS\":ofs_moving_average, \n",
    "\"OFSSGD\":ofssgd_moving_average,  \"random\":random_moving_average,\"FSDS\":fsds_moving_average}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y=col_names, title=title, labels={\"index\":\"batches\", \"value\":\"accuracy\"}, color_discrete_map={\"Pure\":\"blue\",'FIRES': 'red', \n",
    "                                                    'OFS': 'purple','FSDS': 'green', \"OFSSGD\":\"yellow\", \"random\":\"cyan\"})\n",
    "fig.write_image(\"{}/accuracy.{}\".format(folder, export_type))\n",
    "accuracy_trace = fig['data']\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean values\n",
    "csv_name = \"{}/accuracy_avg.csv\".format(folder)\n",
    "df.mean().to_csv(csv_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving averages\n",
    "title = \"Moving averages over f1 while learning with window {} on dataset {}\".format(n_window, dataset_name)\n",
    "col_names = [\"Pure\",\"FIRES\", \"OFS\", \"OFSSGD\", \"FSDS\", \"random\"]\n",
    "d = {\"Pure\":pure_f1, \"FIRES\":fires_f1, \"OFS\":ofs_f1, \n",
    "\"OFSSGD\":ofssgd_f1, \"FSDS\":fsds_f1, \"random\":random_f1}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y=col_names, title=title, labels={\"index\":\"batches\", \"value\":\"accuracy\"}, color_discrete_map={\"Pure\":\"blue\",'FIRES': 'red', \n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\", \"random\":\"cyan\"})\n",
    "fig.write_image(\"{}/f1.{}\".format(folder, export_type))\n",
    "f1_trace = fig['data']\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean values\n",
    "csv_name = \"{}/f1_avg.csv\".format(folder)\n",
    "df.mean().to_csv(csv_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.1) # subplot_titles=(\"Stability\",\"Accuracy\", \"F1-Score\"),\n",
    "for i in range(len(stability_trace)):\n",
    "    stability_trace[i][\"showlegend\"] = False\n",
    "    if stability_trace[i][\"name\"] == \"FIRES\":\n",
    "        trace = stability_trace[i]\n",
    "        print(trace[\"showlegend\"])\n",
    "    else:\n",
    "        fig.add_trace(stability_trace[i], row=1, col=1)\n",
    "\n",
    "fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for i in range(len(accuracy_trace)):\n",
    "    if accuracy_trace[i][\"name\"] == \"FIRES\":\n",
    "        trace = accuracy_trace[i]\n",
    "    else:\n",
    "        fig.add_trace(accuracy_trace[i], row=2, col=1)\n",
    "\n",
    "fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "for i in range(len(f1_trace)):\n",
    "    f1_trace[i][\"showlegend\"] = False\n",
    "    if f1_trace[i][\"name\"] == \"FIRES\":\n",
    "        trace = f1_trace[i]\n",
    "        trace[\"showlegend\"] = False\n",
    "    else:\n",
    "        fig.add_trace(f1_trace[i], row=3, col=1)\n",
    "\n",
    "fig.add_trace(trace, row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"batches\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Stability\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Accuracy\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"F1-Score\", row=3, col=1)\n",
    "fig.write_image(\"{}/all_scores_{}.{}\".format(folder, dataset_name, export_type))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    trace1 = mnist_fig_fires['data'][0]\n",
    "    trace2 = mnist_fig_fsds['data'][0]\n",
    "    trace3 = mnist_fig_ofs['data'][0]\n",
    "    trace4 = mnist_fig_ofssgd['data'][0]\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=(\"FIRES\", \"FSDS\", \"OFS\", \"OFSSGD\"))\n",
    "    fig.add_trace(trace1, row=1,col=1)\n",
    "    fig.add_trace(trace2, row=1,col=2)\n",
    "    fig.add_trace(trace3, row=2,col=1)\n",
    "    fig.add_trace(trace4, row=2,col=2)\n",
    "    fig.update_xaxes(\n",
    "        visible=False \n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        visible=False\n",
    "    )\n",
    "    fig.update_layout(height=500, width=500)\n",
    "    fig.write_image(\"{}/digits.{}\".format(folder, export_type))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on test data\n",
    "col_names = [\"Pure\",\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\"]\n",
    "values = [accuracy_no_ofs, accuracy_fires, accuracy_fsds, accuracy_ofs, accuracy_ofssgd]\n",
    "fig = px.bar(x=col_names, y=values, title=\"Accuracy on test data\", labels={\"y\":\"accuracy\", \"x\":\"\"}, color=col_names, color_discrete_map={\"Pure\":\"blue\",'FIRES': 'red',\n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\"})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/test_acc.csv\".format(folder), \"a\") as outfile:\n",
    "    outfile.write(\"{},{},{},{},{}\\n\".format(col_names[0],col_names[1],col_names[2], col_names[3],col_names[4]))\n",
    "    outfile.write(\"{},{},{},{},{}\\n\".format(values[0],values[1],values[2],values[3],values[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run times\n",
    "col_names = [\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\"]\n",
    "values = [fires_cuda_run_time, fsds_run_time, ofs_run_time, ofssgd_run_time]\n",
    "fig = px.bar(x=col_names, y=values, title=\"Runtime\", labels={\"y\":\"s\", \"x\":\"\"}, color=col_names, color_discrete_map={'FIRES': 'red', \n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\"})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/runtime.csv\".format(folder), \"a\") as outfile:\n",
    "    outfile.write(\"{},{},{},{}\\n\".format(col_names[0],col_names[1],col_names[2], col_names[3]))\n",
    "    outfile.write(\"{},{},{},{}\\n\".format(values[0],values[1],values[2],values[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    col_names = [\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\"]\n",
    "    values = [fires_perc_ftr_found, fsds_perc_ftr_found, ofs_perc_ftr_found, ofssgd_perc_ftr_found]\n",
    "    fig = px.bar(x=col_names, y=values, title=\"True labels found\", labels={\"y\":\"%\", \"x\":\"\"}, color=col_names, color_discrete_map={'FIRES': 'red', \n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\"})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(ofssgd_n_ftrs_selected))\n"
   ]
  }
 ]
}