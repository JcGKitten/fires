{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Validation notebook\n",
    "Here the FIRES implementation for multiclass and regression is validated and compared to other online features selcetion algorithms.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the functions needed for validate and comparsion\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from skmultiflow.data.random_rbf_generator_drift import RandomRBFGeneratorDrift\n",
    "\n",
    "# using plotly for plots\n",
    "#import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paint mnist\n",
    "def paint_digit(digit_values):\n",
    "    fig = px.imshow(digit_values.reshape(28,28), binary_string=True)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    fig.show()\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability measurment as proposed in \"Measurment the Stability of Feature Selection\"\n",
    "\n",
    "def pearson_stability_ij(arr1,arr2):\n",
    "    d = len(arr1)\n",
    "    k_i = np.sum(arr1)\n",
    "    k_j = np.sum(arr2)\n",
    "    x_hat_i = k_i / d\n",
    "    x_hat_j = k_j / d\n",
    "    arr1 = arr1 - x_hat_i\n",
    "    arr2 = arr2 - x_hat_j\n",
    "    dividend = 1/d * np.sum(arr1*arr2)\n",
    "    divisor = np.sqrt(1/d*np.sum(arr1**2))*np.sqrt(1/d*np.sum(arr2**2))\n",
    "    return dividend/divisor\n",
    "\n",
    "def stability_factor(selected_ftrs):\n",
    "   M = len(selected_ftrs)\n",
    "   sum_stabilities = 0\n",
    "   for i in range(M):\n",
    "       for j in range(i+1, M):\n",
    "           sum_stabilities += pearson_stability_ij(selected_ftrs[i], selected_ftrs[j])\n",
    "   return 1/(M*(M-1))*sum_stabilities * 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithms\n",
    "from fires import FIRES\n",
    "from ofs import OFS, MC_OFS\n",
    "from ofssgr import OFSSGD, MC_OFSSGD\n",
    "from fsds import StreamFeatWeight"
   ]
  },
  {
   "source": [
    "## Multiclass Data\n",
    "\n",
    "Here the FIRES softmax implementation is compared to the FSDS, OFS and OFSSGD oun multiclass data.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Load Datasets as Streaming Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data\n",
    "stream = FileStream('datasets/Multiclass/mnist_train_normalized.csv', target_idx=0)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"mnist\"\n",
    "n_selected_ftr = 100\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/mnist_test_normalized.csv', header=None)\n",
    "test_y = test_data[0].to_numpy()\n",
    "test_x = test_data.drop(columns=0).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human Activity Recognition\n",
    "# labels changed from [1,...,6] to [0,...,5]\n",
    "# rows shuffled\n",
    "# split into train set with 7352 instances and test set with 2948\n",
    "stream = FileStream('datasets/Multiclass/har_train.csv', target_idx = 561)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"har\"\n",
    "n_selected_ftr = 100\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/har_test.csv')\n",
    "test_y = test_data[\"Class\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"Class\").to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covtype scaled to 0,1\n",
    "# https://archive.ics.uci.edu/ml/datasets/covertype\n",
    "\n",
    "# rows shuffled\n",
    "# split into train set with 400000 instances and test set with 180000\n",
    "stream = FileStream('datasets/Multiclass/covtype.scale01.test.csv', target_idx = 0)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"covtype\"\n",
    "n_selected_ftr = 25\n",
    "n_window = 50\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/covtype.scale01.train.csv', header=None)\n",
    "test_y = test_data[0].to_numpy()\n",
    "test_x = test_data.drop(columns=0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_true_ftrs_indices(label_names, start_char):\n",
    "    indices = []\n",
    "    for i in range(len(label_names)):\n",
    "        if label_names[i].startswith(start_char):\n",
    "            indices.append(i)\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset 1 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_1_test.csv', target_idx=100)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_1\"\n",
    "n_selected_ftr = 20 # 15 are really informative\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_1_test.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset 2 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_2_test.csv', target_idx=500)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_2\"\n",
    "n_selected_ftr = 30 # 25 are really informative\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_2_test.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset 3 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_3_test.csv', target_idx=250)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_3\"\n",
    "n_selected_ftr = 20 # 20 are really informative\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = [0.1, 0.05, 0.15, 0.2, 0.025, 0.125, 0.075, 0.275]\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_3_test.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream generator to test how algorithms perform on data with concept drift\n",
    "stream = RandomRBFGeneratorDrift(model_random_state=99, sample_random_state = 50,\n",
    " n_classes = 4, n_features = 10, n_centroids = 50, change_speed=0.87,\n",
    " num_drift_centroids=50)"
   ]
  },
  {
   "source": [
    "### Test without feature selection\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuarcy_pure = []\n",
    "while stream.has_more_samples():\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    y_pred = predictor.predict(x)\n",
    "    accuarcy_pure.append(accuracy_score(y, y_pred))\n",
    "    predictor.partial_fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(y = accuarcy_pure, title=\"Accuracy without ftr selection\", labels={\"x\":\"batches\", \"y\":\"accuracy\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_no_ofs = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_no_ofs))"
   ]
  },
  {
   "source": [
    "### FIRES Framework"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still without d, regularizer set 0.1 without being in the derivatives\n",
    "fires_model = FIRES(n_total_ftr=stream.n_features,\n",
    "                    target_values=stream.target_values,\n",
    "                    mu_init=0,\n",
    "                    sigma_init=1,\n",
    "                    model='softmax',\n",
    "                    class_probabilities=weights)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fires_cuda_accuracy = []\n",
    "#fsds_f1 = []\n",
    "fires_cuda_times = []\n",
    "\n",
    "fires_cuda_selected_ftrs = []\n",
    "fires_cuda_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    ftr_weights = fires_model.weigh_features(x,y)\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    fires_cuda_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    fires_cuda_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(fires_cuda_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(fires_cuda_selected_ftrs[-10:])\n",
    "        fires_cuda_stability.append(stability)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    fires_cuda_accuracy.append(accuracy_score(y, y_pred))\n",
    "    #fsds_f1.append(f1_score(y, y_pred, average=None, labels=stream.target_values))\n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "fires_cuda_run_time = timer() - start_time_all\n",
    "print(\"The whole FIRES run took {}\".format(fires_cuda_run_time))\n",
    "fires_moving_average = pd.Series(fires_cuda_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fires_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs)\n",
    "    print(\"FIRES found {} \\% of the true informative features.\".format(fires_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_fires = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_fires))"
   ]
  },
  {
   "source": [
    "### FIRES without cuda\n",
    "\n",
    "Only one batch because of long calculation time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "print(\"Choosen dataset: {}\".format(dataset_name))\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_model = FIRES(n_total_ftr=stream.n_features,\n",
    "                    target_values=stream.target_values,\n",
    "                    mu_init=0,\n",
    "                    sigma_init=1,\n",
    "                    model='softmax')\n",
    "print(fires_model.n_mc_samples)\n",
    "\n",
    "\n",
    "x, y = stream.next_sample(batch_size=batch_size)\n",
    "# Select features\n",
    "start_time = timer()\n",
    "ftr_weights = fires_model.weigh_features(x, y)  # Get feature weights with FIRES\n",
    "ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "print(timer()-start_time)     "
   ]
  },
  {
   "source": [
    "### FSDS algorithm\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "print(\"Choosen dataset: {}\".format(dataset_name))\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fsds_model = StreamFeatWeight(m=stream.n_features, k=stream.n_classes)\n",
    "fsds_model.low_rank_approximation(x.T) # needs some pretraining in the first run\n",
    "\n",
    "fsds_selected_ftrs = []\n",
    "fsds_stability = []\n",
    "\n",
    "fsds_accuracy = []\n",
    "#fsds_f1 = []\n",
    "fsds_times = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    ftr_weights = fsds_model.low_rank_approximation(x.T)\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    fsds_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "     # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    fsds_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(fsds_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(fsds_selected_ftrs[-10:])\n",
    "        fsds_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    fsds_accuracy.append(accuracy_score(y, y_pred))\n",
    "    #fsds_f1.append(f1_score(y, y_pred, average=None, labels=stream.target_values))\n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "fsds_run_time = timer() - start_time_all\n",
    "print(\"The whole fsds run took {}\".format(fsds_run_time))\n",
    "fsds_moving_average = pd.Series(fsds_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fires_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs)\n",
    "    print(\"FIRES found {} \\% of the true informative features.\".format(fires_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_fsds = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_fsds))"
   ]
  },
  {
   "source": [
    "### OFS algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ofs = MC_OFS(regularization_param = 0.01, step_size = 0.1, n_selected_ftr=n_selected_ftr, n_total_ftr=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n",
    "ofs_accuracy = []\n",
    "ofs_selected_ftrs = []\n",
    "ofs_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    # Select features\n",
    "    for idx, label in enumerate(y):\n",
    "        ofs.train(x[idx],label)\n",
    "\n",
    "    ftr_selection = ofs.get_feature_indices()\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "     # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    ofs_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(ofs_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(ofs_selected_ftrs[-10:])\n",
    "        ofs_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    ofs_accuracy.append(accuracy_score(y, y_pred))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "ofs_run_time = timer() - start_time_all\n",
    "print(\"The whole ofs run took {}\".format(ofs_run_time))\n",
    "ofs_moving_average = pd.Series(ofs_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fires_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs)\n",
    "    print(\"FIRES found {} \\% of the true informative features.\".format(fires_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_ofs = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_ofs))"
   ]
  },
  {
   "source": [
    "### OFSSGR algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofssgd_model = MC_OFSSGD(reduction_threshold=0.4, reduction_value=0.1, regularization_param=0.01, step_size=0.2, n_total_ftrs=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n",
    "ofssgd_accuracy = []\n",
    "ofssgd_selected_ftrs = []\n",
    "ofssgd_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    # Select features\n",
    "    for idx, label in enumerate(y):\n",
    "        ofssgd_model.train(x[idx],label)\n",
    "\n",
    "    ftr_selection = ofssgd_model.get_feature_indices()\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    ofssgd_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(ofssgd_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(ofssgd_selected_ftrs[-10:])\n",
    "        ofssgd_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    ofssgd_accuracy.append(accuracy_score(y, y_pred))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "ofssgd_run_time = timer() - start_time_all\n",
    "print(\"The whole ofssgd run took {}\".format(ofssgd_run_time))\n",
    "ofssgd_moving_average = pd.Series(ofssgd_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fires_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs)\n",
    "    print(\"FIRES found {} \\% of the true informative features.\".format(fires_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_ofssgd = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_ofssgd))"
   ]
  },
  {
   "source": [
    "### Pick n random ftrs in each iteration as benchmark"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "predictor = PerceptronMask()\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_accuracy = []\n",
    "random_selected_ftrs = []\n",
    "random_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    # select features\n",
    "    ftr_selection = np.random.choice(len(x[0]), n_selected_ftr)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    random_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(random_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(random_selected_ftrs[-10:])\n",
    "        random_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    random_accuracy.append(accuracy_score(y, y_pred))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "random_run_time = timer() - start_time_all\n",
    "print(\"The whole random run took {}\".format(random_run_time))\n",
    "random_moving_average = pd.Series(ofssgd_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "source": [
    "### Plot all\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability\n",
    "title = \"Stability on dataset {}\".format(dataset_name)\n",
    "col_names = [\"FIRES\", \"OFS\", \"OFSSGD\", \"FSDS\", \"random\"]\n",
    "d = {\"FIRES\":fires_cuda_stability, \"OFS\":ofs_stability, \n",
    "\"OFSSGD\":ofssgd_stability, \"FSDS\":fsds_stability, \"random\":random_stability}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y = col_names, title=title, labels={\"index\":\"batches\", \"value\":\"stability\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving averages\n",
    "title = \"Moving averages over accuracy while learning with window {} on dataset {}\".format(n_window, dataset_name)\n",
    "col_names = [\"FIRES\", \"OFS\", \"OFSSGD\", \"FSDS\", \"random\"]\n",
    "d = {\"FIRES\":fires_moving_average, \"OFS\":ofs_moving_average, \n",
    "\"OFSSGD\":ofssgd_moving_average, \"FSDS\":fsds_moving_average, \"random\":random_moving_average}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y=col_names, title=title, labels={\"index\":\"batches\", \"value\":\"accuracy\"})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = mnist_fig_fires['data'][0]\n",
    "trace2 = mnist_fig_fsds['data'][0]\n",
    "trace3 = mnist_fig_ofs['data'][0]\n",
    "trace4 = mnist_fig_ofssgd['data'][0]\n",
    "fig = make_subplots(rows=1, cols=4, subplot_titles=(\"FIRES\", \"FSDS\", \"OFS\", \"OFSSGD\"))\n",
    "fig.add_trace(trace1, row=1,col=1)\n",
    "fig.add_trace(trace2, row=1,col=2)\n",
    "fig.add_trace(trace3, row=1,col=3)\n",
    "fig.add_trace(trace4, row=1,col=4)\n",
    "fig.update_xaxes(\n",
    "    visible=False \n",
    ")\n",
    "fig.update_yaxes(\n",
    "    visible=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on test data\n",
    "col_names = [\"Pure\",\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\"]\n",
    "values = [accuracy_no_ofs, accuracy_fires, accuracy_fsds, accuracy_ofs, accuracy_ofssgd]\n",
    "fig = px.bar(x=col_names, y=values, title=\"Accuracy on test data\", labels={\"y\":\"accuracy\", \"x\":\"\"}, color=col_names)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run times\n",
    "col_names = [\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\", ]\n",
    "values = [fires_run_time, fsds_run_time, ofs_run_time, ofssgd_run_time]\n",
    "fig = px.bar(x=col_names, y=values, title=\"Runtime\", labels={\"y\":\"run time\", \"x\":\"\"}, color=col_names)\n",
    "fig.show()"
   ]
  }
 ]
}