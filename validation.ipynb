{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd09e4c97bd779caefcb7cd845411b070731e96d735053e38eececd02f8b1decf55",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Validation notebook\n",
    "Here the FIRES implementation for multiclass and regression is validated and compared to other online features selcetion algorithms.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the functions needed for validate and comparsion\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skmultiflow.data import FileStream, RandomRBFGenerator, ConceptDriftStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier, ExtremelyFastDecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# using plotly for plots\n",
    "#import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paint mnist\n",
    "def paint_digit(digit_values):\n",
    "    fig = px.imshow(digit_values.reshape(28,28), binary_string=True)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    #fig.show()\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability measurment as proposed in \"Measurment the Stability of Feature Selection\"\n",
    "\n",
    "# TODO: check for case where nothing changes\n",
    "\n",
    "\n",
    "def pearson_stability_ij(arr1,arr2):\n",
    "    d = len(arr1)\n",
    "    k_i = np.sum(arr1)\n",
    "    k_j = np.sum(arr2)\n",
    "\n",
    "    # catch edge cases as proposed in the paper under 4.1\n",
    "    if (k_i == 0 or k_i == d) and k_i != k_j :\n",
    "        return 0\n",
    "    elif (k_j == 0 or k_j == d) and k_i != k_j :\n",
    "        return 0\n",
    "    elif (k_i == 0 or k_i == d) and k_i == k_j :\n",
    "        return 1\n",
    "    x_hat_i = k_i / d\n",
    "    x_hat_j = k_j / d\n",
    "    arr1 = arr1 - x_hat_i\n",
    "    arr2 = arr2 - x_hat_j\n",
    "    dividend = 1/d * np.sum(arr1*arr2)\n",
    "    divisor = np.sqrt(1/d*np.sum(arr1**2))*np.sqrt(1/d*np.sum(arr2**2))\n",
    "    return dividend/divisor\n",
    "\n",
    "def stability_factor(selected_ftrs):\n",
    "   M = len(selected_ftrs)\n",
    "   sum_stabilities = 0\n",
    "   for i in range(M):\n",
    "       for j in range(i+1, M):\n",
    "           sum_stabilities += pearson_stability_ij(selected_ftrs[i], selected_ftrs[j])\n",
    "   return 1/(M*(M-1))*sum_stabilities * 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithms\n",
    "from fires import FIRES\n",
    "from ofs import OFS, MC_OFS\n",
    "from ofssgr import OFSSGD, MC_OFSSGD\n",
    "from fsds import StreamFeatWeight"
   ]
  },
  {
   "source": [
    "## Multiclass Data\n",
    "\n",
    "Here the FIRES softmax implementation is compared to the FSDS, OFS and OFSSGD oun multiclass data.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Load Datasets as Streaming Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set n_selected ftr\n",
    "per_ftr = 0.5\n",
    "#per_ftr = 0.25\n",
    "#per_ftr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# MNIST data normalized\n",
    "stream = FileStream('datasets/Multiclass/mnist_train_normalized.csv', target_idx=0)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"mnist_norm\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights = None\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/mnist_test_normalized.csv', header=None)\n",
    "test_y = test_data[0].to_numpy()\n",
    "test_x = test_data.drop(columns=0).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# Human Activity Recognition\n",
    "# labels changed from [1,...,6] to [0,...,5]\n",
    "# rows shuffled\n",
    "# split into train set with 7352 instances and test set with 2948\n",
    "stream = FileStream('datasets/Multiclass/har_train.csv', target_idx = 561)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"har\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 50\n",
    "weights = None\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/har_test.csv')\n",
    "test_y = test_data[\"Class\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"Class\").to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# Human Activity Recognition\n",
    "# labels changed from [1,...,6] to [0,...,5]\n",
    "# rows shuffled\n",
    "# split into train set with 7352 instances and test set with 2948\n",
    "stream = FileStream('datasets/Multiclass/har_train_norm.csv', target_idx = 561)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"har_norm\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 50\n",
    "weights = None\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/har_test_norm.csv')\n",
    "test_y = test_data[\"Class\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"Class\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# Covtype scaled to 0,1\n",
    "# https://archive.ics.uci.edu/ml/datasets/covertype\n",
    "\n",
    "# rows shuffled\n",
    "# split into train set with 400000 instances and test set with 180000\n",
    "stream = FileStream('datasets/Multiclass/covtype.scale01.test.csv', target_idx = 0)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"covtype\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 50\n",
    "batch_size = 100\n",
    "weights = [0.36460521, 0.48759922, 0.06153746, 0.00472796, 0.01633873, 0.02989095, 0.03530047]\n",
    "\n",
    "check_ftrs = False\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Multiclass/covtype.scale01.train.csv', header=None)\n",
    "test_y = test_data[0].to_numpy()\n",
    "test_x = test_data.drop(columns=0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_true_ftrs_indices(label_names, start_char):\n",
    "    indices = []\n",
    "    for i in range(len(label_names)):\n",
    "        if label_names[i].startswith(start_char):\n",
    "            indices.append(i)\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# synthetic dataset 1 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_1_train_norm.csv', target_idx=100)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_1\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 50\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_1_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# synthetic dataset 2 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_2_train_norm.csv', target_idx=500)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_2\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 50\n",
    "weights = None\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_2_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# synthetic dataset 3 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_3_train_norm.csv', target_idx=250)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_3\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features)) # 20 are really informative\n",
    "n_window = 10\n",
    "batch_size = 20\n",
    "weights = [0.1, 0.05, 0.15, 0.2, 0.025, 0.125, 0.075, 0.275]\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_3_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()\n",
    "\n",
    "# get index of real ftrs\n",
    "true_ftrs = find_true_ftrs_indices(test_data.columns, \"y\")\n",
    "check_ftrs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/anaconda3/lib/python3.8/site-packages/skmultiflow/data/base_stream.py:191: FutureWarning:\n\n'prepare_for_use' has been deprecated in v0.5.0 and will be removed in v0.7.0.\nNew instances of the Stream class are now ready to use after instantiation.\n\n"
     ]
    }
   ],
   "source": [
    "# synthetic dataset 4 (see data_generation.ipynb)\n",
    "stream = FileStream('datasets/Multiclass/dataset_4_train_norm.csv', target_idx=210)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"syn_ds_4\"\n",
    "n_selected_ftr = int(np.ceil(per_ftr * stream.n_features))\n",
    "n_window = 10\n",
    "batch_size = 100\n",
    "weights=None\n",
    "check_ftrs = False\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"datasets/Multiclass/dataset_4_test_norm.csv\")\n",
    "test_y = test_data[\"label\"].to_numpy()\n",
    "test_x = test_data.drop(columns=\"label\").to_numpy()"
   ]
  },
  {
   "source": [
    "## Set trainings algorithms settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_settings = {}\n",
    "\n",
    "MLP_settings = {}\n",
    "\n",
    "hoeffding_settings = {\"leaf_prediction\":\"mc\"}\n",
    "\n",
    "fast_decision_settings = {\"split_criterion\":\"info_gain\",\n",
    "                          \"split_confidence\":0.0001,\n",
    "                          \"leaf_prediction\":\"mc\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_algo = \"perceptron\"\n",
    "pred_algo = \"mlp\"\n",
    "#pred_algo = \"hoeffding\"\n",
    "#pred_algo = 'fast_decision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare folder for plots\n",
    "folder = \"plots/{}/{}/{}\".format(dataset_name, pred_algo,int(100*per_ftr))\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "export_type = \"pdf\" # \"png\", \"jpeg\", \"webp\", \"pdf\", \"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'plots/syn_ds_4/mlp/50'"
      ]
     },
     "metadata": {},
     "execution_count": 672
    }
   ],
   "source": [
    "folder"
   ]
  },
  {
   "source": [
    "### Test without feature selection\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 673
    }
   ],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "d samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning:\n",
      "\n",
      "Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "/home/kitten/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuarcy_pure = []\n",
    "f1_pure = []\n",
    "precision = []\n",
    "recall = []\n",
    "while stream.has_more_samples():\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    y_pred = predictor.predict(x)\n",
    "    \n",
    "    accuarcy_pure.append(accuracy_score(y, y_pred))\n",
    "    f1_pure.append(f1_score(y, y_pred, stream.target_values, \n",
    "    average=\"weighted\" ))\n",
    "    precision.append(precision_score(y, y_pred, stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "    recall.append(recall_score(y, y_pred, stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    predictor.partial_fit(x,y)\n",
    "\n",
    "pure_moving_average = pd.Series(accuarcy_pure).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "pure_f1 = pd.Series(f1_pure).rolling(window=n_window).mean().iloc[n_window-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For the test dataset the previous trained predictor reached: 0.1808\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_no_ofs = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_no_ofs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = pd.Series(precision).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "recall = pd.Series(recall).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "f1_pure = pd.Series(f1_pure).rolling(window=n_window).mean().iloc[n_window-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names = [\"accuracy\",\"f1\", \"precision\", \"recall\"]\n",
    "#d = {\"accuracy\":pure_moving_average, \"f1\":f1_pure, \"precision\":precision,\n",
    "#\"recall\":recall}\n",
    "#df = pd.DataFrame(d, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig = px.line(df)\n",
    "#fig.show()"
   ]
  },
  {
   "source": [
    "### FIRES Framework"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 679
    }
   ],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_model = FIRES(n_total_ftr=stream.n_features,\n",
    "                    target_values=stream.target_values,\n",
    "                    mu_init=0,\n",
    "                    sigma_init=1,\n",
    "                    model='softmax',\n",
    "                    class_probabilities=weights,\n",
    "                    lr_mu=0.05,\n",
    "                    lr_sigma=0.05,\n",
    "                    number_monte_carlo_samples=10)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "The whole FIRES run took 11.443306557001051\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n",
      "/home/kitten/BA_FIRES/fires/fires.py:144: UserWarning:\n",
      "\n",
      "Sigma has automatically been rescaled to [0, inf], because it contained negative values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fires_cuda_accuracy = []\n",
    "fires_f1 = []\n",
    "fires_cuda_times = []\n",
    "\n",
    "fires_cuda_selected_ftrs = []\n",
    "fires_cuda_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "\n",
    "while stream.has_more_samples():\n",
    "#for i in range(1):\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    ftr_weights = fires_model.weigh_features(x,y)\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    fires_cuda_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    fires_cuda_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(fires_cuda_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(fires_cuda_selected_ftrs[-10:])\n",
    "        fires_cuda_stability.append(stability)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    fires_cuda_accuracy.append(accuracy_score(y, y_pred))\n",
    "    fires_f1.append(f1_score(y, y_pred, average=\"weighted\",\n",
    "    labels=stream.target_values))\n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "fires_cuda_run_time = timer() - start_time_all\n",
    "print(\"The whole FIRES run took {}\".format(fires_cuda_run_time))\n",
    "\n",
    "fires_moving_average = pd.Series(fires_cuda_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "fires_f1 = pd.Series(fires_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "    mnist_fig_fires = paint_digit(selection_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fires_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs) * 100\n",
    "    print(\"FIRES found {}% of the true informative features.\".format(fires_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For the test dataset the previous trained predictor reached: 0.0982\n"
     ]
    }
   ],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_fires = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### FSDS algorithm\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 684
    }
   ],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The whole fsds run took 3.358700012002373\n"
     ]
    }
   ],
   "source": [
    "fsds_model = StreamFeatWeight(m=stream.n_features, k=stream.n_classes)\n",
    "fsds_model.low_rank_approximation(x.T) # needs some pretraining in the first run\n",
    "\n",
    "fsds_selected_ftrs = []\n",
    "fsds_stability = []\n",
    "\n",
    "fsds_accuracy = []\n",
    "fsds_f1 = []\n",
    "fsds_times = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    ftr_weights = fsds_model.low_rank_approximation(x.T)\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    fsds_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "     # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    fsds_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(fsds_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(fsds_selected_ftrs[-10:])\n",
    "        fsds_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    fsds_accuracy.append(accuracy_score(y, y_pred))\n",
    "    fsds_f1.append(f1_score(y, y_pred, average=\"weighted\", \n",
    "    labels=stream.target_values))\n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "fsds_run_time = timer() - start_time_all\n",
    "print(\"The whole fsds run took {}\".format(fsds_run_time))\n",
    "\n",
    "fsds_moving_average = pd.Series(fsds_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "fsds_f1 = pd.Series(fsds_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    \n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "\n",
    "    mnist_fig_fsds = paint_digit(selection_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    fsds_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs) * 100\n",
    "    print(\"FSDS found {}% of the true informative features.\".format(fsds_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For the test dataset the previous trained predictor reached: 0.1132\n"
     ]
    }
   ],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_fsds = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_fsds))"
   ]
  },
  {
   "source": [
    "### OFS algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 688
    }
   ],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The whole ofs run took 5.572109654000087\n"
     ]
    }
   ],
   "source": [
    "ofs = MC_OFS(regularization_param = 0.01, step_size = 0.2, n_selected_ftr=n_selected_ftr, n_total_ftr=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n",
    "ofs_accuracy = []\n",
    "ofs_f1 = []\n",
    "ofs_selected_ftrs = []\n",
    "ofs_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    # Select features\n",
    "    for idx, label in enumerate(y):\n",
    "        ofs.train(x[idx],label)\n",
    "\n",
    "    ftr_selection = ofs.get_feature_indices()\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "     # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    ofs_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(ofs_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(ofs_selected_ftrs[-10:])\n",
    "        ofs_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    ofs_accuracy.append(accuracy_score(y, y_pred))\n",
    "    ofs_f1.append(f1_score(y,y_pred, labels=stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "ofs_run_time = timer() - start_time_all\n",
    "print(\"The whole ofs run took {}\".format(ofs_run_time))\n",
    "\n",
    "ofs_moving_average = pd.Series(ofs_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "ofs_f1 = pd.Series(ofs_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "    mnist_fig_ofs = paint_digit(selection_array)\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    ofs_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs)* 100\n",
    "    print(\"OFS found {}% of the true informative features.\".format(fsds_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For the test dataset the previous trained predictor reached: 0.1542\n"
     ]
    }
   ],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_ofs = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_ofs))"
   ]
  },
  {
   "source": [
    "### OFSSGR algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 692
    }
   ],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The whole ofssgd run took 38.44966359300088\n"
     ]
    }
   ],
   "source": [
    "ofssgd_model = MC_OFSSGD(reduction_threshold=0.4, reduction_value=0.1, regularization_param=0.01, step_size=0.2, n_total_ftrs=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n",
    "ofssgd_accuracy = []\n",
    "ofssgd_f1 = []\n",
    "ofssgd_selected_ftrs = []\n",
    "ofssgd_stability = []\n",
    "ofssgd_n_ftrs_selected = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    # Select features\n",
    "    for idx, label in enumerate(y):\n",
    "        ofssgd_model.train(x[idx],label)\n",
    "\n",
    "    ftr_selection = ofssgd_model.get_feature_indices()\n",
    "    ofssgd_n_ftrs_selected.append(len(ftr_selection))\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    ofssgd_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(ofssgd_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(ofssgd_selected_ftrs[-10:])\n",
    "        ofssgd_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    ofssgd_accuracy.append(accuracy_score(y, y_pred))\n",
    "    ofssgd_f1.append(f1_score(y, y_pred, labels=stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "ofssgd_run_time = timer() - start_time_all\n",
    "print(\"The whole ofssgd run took {}\".format(ofssgd_run_time))\n",
    "\n",
    "ofssgd_moving_average = pd.Series(ofssgd_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "ofssgd_f1 = pd.Series(ofssgd_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "\n",
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    selection_array = np.zeros((784))\n",
    "    selection_array[ftr_selection] = 1\n",
    "    mnist_fig_ofssgd = paint_digit(selection_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    true_selected_ftr = set(ftr_selection)&set(true_ftrs)\n",
    "    ofssgd_perc_ftr_found = len(true_selected_ftr) / len(true_ftrs) * 100\n",
    "    print(\"OFSSGD found {}% of the true informative features.\".format(ofssgd_perc_ftr_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For the test dataset the previous trained predictor reached: 0.1964\n"
     ]
    }
   ],
   "source": [
    "test_x_selected = np.zeros(test_x.shape)\n",
    "test_x_selected[:,ftr_selection] = test_x[:,ftr_selection]\n",
    "y_pred = predictor.predict(test_x)\n",
    "accuracy_ofssgd = accuracy_score(test_y, y_pred)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(accuracy_ofssgd))"
   ]
  },
  {
   "source": [
    "### Pick n random ftrs in each iteration as benchmark"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 696
    }
   ],
   "source": [
    "stream.restart()\n",
    "if pred_algo == \"perceptron\":\n",
    "    predictor = PerceptronMask()\n",
    "elif pred_algo == \"mlp\":\n",
    "    predictor = MLPClassifier()\n",
    "elif pred_algo == \"hoeffding\":\n",
    "    predictor = HoeffdingTreeClassifier(leaf_prediction=hoeffding_settings[\"leaf_prediction\"])\n",
    "elif pred_algo == 'fast_decision':\n",
    "    predictor = ExtremelyFastDecisionTreeClassifier(split_criterion=fast_decision_settings[\"split_criterion\"],\n",
    "                                                    split_confidence=fast_decision_settings[\"split_confidence\"],\n",
    "                                                    leaf_prediction=fast_decision_settings[\"leaf_prediction\"])\n",
    "x,y = stream.next_sample(batch_size=batch_size)\n",
    "predictor.partial_fit(x,y, stream.target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The whole random run took 2.066991740000958\n"
     ]
    }
   ],
   "source": [
    "random_accuracy = []\n",
    "random_f1 = []\n",
    "random_selected_ftrs = []\n",
    "random_stability = []\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    # select features\n",
    "    ftr_selection = np.random.choice(len(x[0]), n_selected_ftr)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    random_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(random_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(random_selected_ftrs[-10:])\n",
    "        random_stability.append(stability)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    random_accuracy.append(accuracy_score(y, y_pred))\n",
    "    random_f1.append(f1_score(y, y_pred, labels=stream.target_values,\n",
    "    average=\"weighted\"))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "end_time_all = timer()\n",
    "random_run_time = timer() - start_time_all\n",
    "print(\"The whole random run took {}\".format(random_run_time))\n",
    "random_moving_average = pd.Series(random_accuracy).rolling(window=n_window).mean().iloc[n_window-1:].values\n",
    "random_f1 = pd.Series(random_f1).rolling(window=n_window).mean().iloc[n_window-1:].values\n"
   ]
  },
  {
   "source": [
    "### Plot all\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=FIRES<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "line": {
          "color": "red",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FIRES",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.48232804232804255,
          0.5424338624338627,
          0.593650793650794,
          0.6478306878306882,
          0.6884656084656088,
          0.7092063492063495,
          0.7108994708994714,
          0.7121693121693126,
          0.7164021164021168,
          0.6998941798941802,
          0.7024338624338629,
          0.7108994708994714,
          0.7227513227513229,
          0.7274074074074077,
          0.7405291005291008,
          0.7583068783068786,
          0.7714285714285717,
          0.7845502645502649,
          0.8082539682539687,
          0.8179894179894184,
          0.8268783068783073,
          0.826455026455027,
          0.8112169312169316,
          0.8061375661375665,
          0.8116402116402122,
          0.8179894179894184,
          0.8150264550264554,
          0.8179894179894185,
          0.8226455026455032,
          0.8289947089947095,
          0.8374603174603179,
          0.8404232804232808,
          0.8412698412698417,
          0.8438095238095242,
          0.8438095238095242,
          0.8433862433862438,
          0.8391534391534397,
          0.8463492063492067,
          0.8467724867724872,
          0.8518518518518523,
          0.8565079365079369,
          0.8670899470899475,
          0.8755555555555559,
          0.8797883597883601,
          0.8764021164021167,
          0.8823280423280426,
          0.888677248677249,
          0.893756613756614,
          0.8920634920634923,
          0.8844444444444447,
          0.8861375661375664,
          0.8869841269841272,
          0.8848677248677251,
          0.8797883597883601,
          0.8704761904761908,
          0.8704761904761908,
          0.8632804232804236,
          0.8603174603174607,
          0.8535449735449739,
          0.8526984126984131,
          0.855661375661376,
          0.8552380952380956,
          0.8560846560846564,
          0.8552380952380956,
          0.8497354497354501,
          0.8526984126984131,
          0.8611640211640216,
          0.8713227513227516,
          0.8742857142857146,
          0.8768253968253972,
          0.8780952380952384,
          0.8780952380952384,
          0.8751322751322754,
          0.8793650793650797,
          0.8844444444444447,
          0.8946031746031748,
          0.9030687830687835,
          0.9051851851851854,
          0.913650793650794,
          0.8975661375661378,
          0.8924867724867728,
          0.8831746031746036,
          0.8734391534391538,
          0.8700529100529104,
          0.8662433862433866,
          0.8692063492063495,
          0.8789417989417992,
          0.8810582010582013,
          0.8874074074074076,
          0.8979894179894182,
          0.8984126984126987,
          0.8958730158730163,
          0.897566137566138,
          0.893756613756614,
          0.8886772486772491,
          0.8831746031746035,
          0.8802116402116406,
          0.8725925925925929,
          0.8730158730158734,
          0.874708994708995,
          0.8759788359788363,
          0.8814814814814818,
          0.8861375661375664,
          0.8823280423280426,
          0.8734391534391538,
          0.8679365079365082,
          0.8679365079365082,
          0.8768253968253972,
          0.8764021164021167,
          0.8793650793650797,
          0.8810582010582013,
          0.888677248677249,
          0.8967195767195769,
          0.9013756613756617,
          0.9064550264550266,
          0.9047619047619051,
          0.9056084656084659,
          0.9064550264550266,
          0.9022222222222225,
          0.9001058201058203,
          0.8992592592592595,
          0.9026455026455029,
          0.8958730158730162,
          0.8929100529100532,
          0.8882539682539685,
          0.893756613756614,
          0.8992592592592595,
          0.9034920634920637,
          0.900529100529101,
          0.9077248677248679,
          0.913650793650794,
          0.9183068783068786,
          0.9144973544973548,
          0.9119576719576723,
          0.9060317460317462,
          0.9115343915343918,
          0.9187301587301591,
          0.9200000000000004,
          0.9263492063492067,
          0.9284656084656085,
          0.9178835978835982,
          0.916613756613757,
          0.9195767195767199,
          0.9200000000000004,
          0.9259259259259263,
          0.9242328042328045,
          0.9250793650793652,
          0.9284656084656088,
          0.9255026455026456,
          0.9276190476190479,
          0.9305820105820108,
          0.9369312169312172,
          0.9441269841269844,
          0.9483597883597886,
          0.9492063492063494,
          0.9449735449735452,
          0.9398941798941801,
          0.9276190476190479,
          0.9255026455026458,
          0.9208465608465611,
          0.9081481481481485,
          0.9009523809523814,
          0.8979894179894183,
          0.8916402116402119,
          0.8933333333333335,
          0.8984126984126987,
          0.8992592592592596,
          0.9001058201058205,
          0.9001058201058205,
          0.9039153439153441,
          0.9128042328042332,
          0.9140740740740744,
          0.9115343915343919,
          0.9123809523809525,
          0.9098412698412702,
          0.9106878306878309,
          0.9106878306878309,
          0.9022222222222225,
          0.8941798941798946,
          0.8891005291005294,
          0.8869841269841272,
          0.8878306878306881,
          0.8874074074074076,
          0.8933333333333335,
          0.8975661375661378,
          0.9039153439153441,
          0.9111111111111114,
          0.9132275132275136,
          0.9204232804232807,
          0.9238095238095241,
          0.926772486772487,
          0.9238095238095241,
          0.9280423280423283,
          0.9288888888888892,
          0.920846560846561,
          0.9195767195767199,
          0.9119576719576722,
          0.907724867724868,
          0.8979894179894182,
          0.8967195767195769,
          0.8946031746031751,
          0.8929100529100533,
          0.8869841269841272,
          0.8823280423280426,
          0.8810582010582013,
          0.8780952380952384,
          0.8814814814814818,
          0.8865608465608469,
          0.893756613756614,
          0.8996825396825399,
          0.8984126984126987,
          0.8988359788359792,
          0.8992592592592595,
          0.9051851851851854,
          0.905608465608466,
          0.9030687830687832,
          0.9013756613756616,
          0.9022222222222225,
          0.9030687830687835,
          0.9001058201058203,
          0.9043386243386247,
          0.9030687830687832,
          0.9102645502645507,
          0.9064550264550266,
          0.9111111111111113,
          0.9132275132275136,
          0.9128042328042332,
          0.9170370370370372,
          0.9221164021164022,
          0.9229629629629631,
          0.9255026455026456,
          0.9348148148148151,
          0.9335449735449738,
          0.92973544973545,
          0.9322751322751326,
          0.9259259259259263,
          0.9225396825396829,
          0.9178835978835982,
          0.9170370370370373,
          0.9174603174603178,
          0.9233862433862435,
          0.9259259259259263,
          0.9305820105820107,
          0.9394708994708997,
          0.9369312169312172,
          0.940740740740741,
          0.9437037037037039,
          0.9360846560846563,
          0.935661375661376,
          0.9343915343915347,
          0.9322751322751326,
          0.9280423280423283,
          0.9276190476190479,
          0.9280423280423283,
          0.9339682539682541,
          0.9348148148148151,
          0.9293121693121696,
          0.9208465608465611,
          0.9115343915343919,
          0.9098412698412702,
          0.9043386243386247,
          0.9060317460317462,
          0.9081481481481484,
          0.9060317460317462,
          0.9081481481481484,
          0.912804232804233,
          0.9183068783068785,
          0.9271957671957675,
          0.9314285714285715,
          0.9390476190476194,
          0.9424338624338626,
          0.9386243386243389,
          0.9314285714285717,
          0.9276190476190479,
          0.9233862433862436,
          0.9225396825396829,
          0.9255026455026458,
          0.925925925925926,
          0.9314285714285717,
          0.9318518518518522,
          0.9348148148148151,
          0.9310052910052913,
          0.9255026455026456,
          0.9233862433862436,
          0.9233862433862436,
          0.9314285714285715,
          0.9386243386243389,
          0.9386243386243389,
          0.9420105820105821,
          0.9462433862433864,
          0.9453968253968257,
          0.9513227513227516,
          0.9525925925925928,
          0.9513227513227516,
          0.9513227513227516,
          0.9504761904761907,
          0.9496296296296298,
          0.9462433862433864,
          0.9441269841269844,
          0.9475132275132278,
          0.9530158730158732,
          0.956825396825397,
          0.9593650793650795,
          0.9576719576719579,
          0.9525925925925928,
          0.9534391534391536,
          0.9530158730158732,
          0.951746031746032,
          0.9521693121693123,
          0.9559788359788362,
          0.9564021164021166,
          0.9602116402116404,
          0.9576719576719579,
          0.9589417989417991,
          0.9610582010582013,
          0.9602116402116404,
          0.9564021164021166,
          0.956825396825397,
          0.9559788359788362,
          0.954708994708995,
          0.9496296296296298,
          0.9437037037037039,
          0.9403174603174606,
          0.9331216931216934,
          0.9301587301587304,
          0.9238095238095241,
          0.9187301587301591,
          0.9191534391534395,
          0.9128042328042332,
          0.916613756613757,
          0.9170370370370373,
          0.9212698412698416,
          0.9229629629629633,
          0.9216931216931219,
          0.9225396825396827,
          0.9276190476190478,
          0.9322751322751324,
          0.9352380952380955,
          0.9352380952380955,
          0.9365079365079367,
          0.9335449735449738,
          0.937777777777778,
          0.9424338624338626,
          0.945820105820106,
          0.9513227513227516,
          0.9580952380952383,
          0.9644444444444447,
          0.9737566137566139,
          0.9614814814814816,
          0.9589417989417991,
          0.9525925925925928,
          0.9492063492063494,
          0.9492063492063494,
          0.9513227513227516,
          0.9513227513227516,
          0.9492063492063493,
          0.947936507936508,
          0.9475132275132278,
          0.9445502645502648,
          0.9466666666666669,
          0.9504761904761907,
          0.9538624338624341,
          0.9513227513227516,
          0.9479365079365082,
          0.9420105820105823,
          0.9411640211640214,
          0.9441269841269844,
          0.9441269841269844,
          0.9445502645502648,
          0.9466666666666669,
          0.9500529100529103,
          0.9525925925925928,
          0.9559788359788362,
          0.9572486772486775,
          0.9572486772486775,
          0.95978835978836,
          0.9682539682539684,
          0.9733333333333335,
          0.9771428571428573,
          0.9779894179894181,
          0.9805291005291006,
          0.9775661375661376,
          0.9674074074074076,
          0.9593650793650795,
          0.9525925925925928,
          0.9470899470899473,
          0.9453968253968257,
          0.9441269841269844,
          0.9462433862433864,
          0.9483597883597886,
          0.9576719576719579,
          0.9564021164021166,
          0.9534391534391536,
          0.9466666666666669,
          0.9432804232804235,
          0.9420105820105823,
          0.9403174603174606,
          0.9382010582010585,
          0.9386243386243389,
          0.93989417989418,
          0.9386243386243389,
          0.9310052910052913,
          0.9305820105820108,
          0.9238095238095241,
          0.9263492063492067,
          0.932698412698413,
          0.9386243386243389,
          0.9441269841269843,
          0.9479365079365082,
          0.9441269841269844,
          0.9508994708994711,
          0.9525925925925928,
          0.9475132275132278,
          0.9398941798941801,
          0.9382010582010585,
          0.935661375661376,
          0.9335449735449738,
          0.9310052910052913,
          0.9288888888888892,
          0.9271957671957675,
          0.9276190476190479,
          0.9280423280423283,
          0.9365079365079367,
          0.9369312169312172,
          0.9365079365079367,
          0.9365079365079367,
          0.9339682539682542,
          0.9314285714285717,
          0.9331216931216934,
          0.9339682539682542,
          0.9352380952380955,
          0.9437037037037039,
          0.9492063492063494,
          0.9483597883597886,
          0.948783068783069,
          0.9500529100529103,
          0.954708994708995,
          0.9593650793650795,
          0.9576719576719579,
          0.9504761904761907
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFS<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "line": {
          "color": "purple",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.44841557813255944,
          0.5131833575229803,
          0.5487421383647798,
          0.5809143686502178,
          0.6071601354620224,
          0.6342525399129173,
          0.6384857281083697,
          0.6418722786647314,
          0.63933236574746,
          0.6414489598451862,
          0.6389090469279148,
          0.6346758587324626,
          0.6414489598451864,
          0.6469521044992743,
          0.6465287856797293,
          0.6533018867924529,
          0.660498306724722,
          0.6706579583938077,
          0.6897073052733433,
          0.6858974358974361,
          0.6922472181906145,
          0.6918238993710693,
          0.6918238993710694,
          0.6901306240928884,
          0.6897073052733432,
          0.6939404934687955,
          0.6956337687469765,
          0.6985970004837929,
          0.7079100145137881,
          0.7167997097242381,
          0.7201862602806,
          0.7214562167392355,
          0.7163763909046927,
          0.7134131591678762,
          0.7180696661828737,
          0.7070633768746976,
          0.6998669569424285,
          0.7066400580551523,
          0.7041001451378809,
          0.7100266086115143,
          0.7155297532656025,
          0.7303459119496857,
          0.7396589259796807,
          0.7502418964683117,
          0.7510885341074021,
          0.7481253023705854,
          0.750665215287857,
          0.750665215287857,
          0.750241896468312,
          0.765058055152395,
          0.7714078374455735,
          0.7735244315432995,
          0.7862239961296565,
          0.7917271407837447,
          0.7879172714078376,
          0.787070633768747,
          0.7891872278664732,
          0.776064344460571,
          0.7629414610546686,
          0.7396589259796804,
          0.7299225931301403,
          0.7142597968069666,
          0.7079100145137882,
          0.7193396226415096,
          0.7316158684083214,
          0.7396589259796807,
          0.736272375423319,
          0.7379656507014998,
          0.7350024189646833,
          0.7417755200774071,
          0.7544750846637641,
          0.7675979680696663,
          0.7671746492501211,
          0.7532051282051285,
          0.7612481857764877,
          0.7570149975810354,
          0.7608248669569426,
          0.7544750846637641,
          0.7523584905660378,
          0.7515118529269473,
          0.7464320270924047,
          0.7570149975810354,
          0.7544750846637639,
          0.7578616352201258,
          0.7629414610546686,
          0.7709845186260279,
          0.7752177068214806,
          0.773947750362845,
          0.7718311562651186,
          0.7709845186260281,
          0.7663280116110306,
          0.7527818093855831,
          0.740082244799226,
          0.731615868408321,
          0.7333091436865021,
          0.7426221577164974,
          0.7455853894533142,
          0.7574383164005808,
          0.7718311562651189,
          0.7824141267537496,
          0.7866473149492016,
          0.7790275761973873,
          0.7680212868892113,
          0.7430454765360427,
          0.7362723754233189,
          0.7333091436865024,
          0.7223028543783263,
          0.7197629414610551,
          0.7112965650701503,
          0.6981736816642479,
          0.7053701015965167,
          0.7066400580551524,
          0.7066400580551525,
          0.7062167392356072,
          0.7028301886792453,
          0.7091799709724238,
          0.7074866956942429,
          0.71129656507015,
          0.7100266086115143,
          0.714683115626512,
          0.7239961296565071,
          0.7239961296565072,
          0.7193396226415094,
          0.712566521528786,
          0.7117198838896951,
          0.7163763909046929,
          0.7252660861151428,
          0.7294992743105951,
          0.7455853894533142,
          0.7591315916787614,
          0.7697145621673924,
          0.7862239961296567,
          0.7841074020319307,
          0.7828374455732948,
          0.7731011127237545,
          0.757861635220126,
          0.7519351717464926,
          0.7379656507014998,
          0.7294992743105952,
          0.7269593613933237,
          0.7400822447992261,
          0.7477019835510403,
          0.7595549104983069,
          0.7540517658442188,
          0.750665215287857,
          0.7527818093855831,
          0.7443154329946786,
          0.7409288824383166,
          0.7396589259796807,
          0.7375423318819548,
          0.7468553459119499,
          0.7464320270924044,
          0.7426221577164974,
          0.7282293178519593,
          0.718916303821964,
          0.7218795355587809,
          0.7142597968069667,
          0.7176463473633284,
          0.7155297532656023,
          0.7079100145137881,
          0.7045234639574263,
          0.7074866956942429,
          0.7125665215287859,
          0.7091799709724239,
          0.7223028543783261,
          0.7341557813255928,
          0.743892114175133,
          0.7553217223028544,
          0.7629414610546688,
          0.7595549104983066,
          0.7684446057087565,
          0.7519351717464924,
          0.7375423318819546,
          0.7303459119496857,
          0.7278059990324142,
          0.718492985002419,
          0.7227261731978714,
          0.7189163038219643,
          0.715106434446057,
          0.7096032897919692,
          0.7024068698597001,
          0.6939404934687954,
          0.7108732462506049,
          0.7299225931301406,
          0.7472786647314951,
          0.7591315916787619,
          0.7646347363328497,
          0.7637880986937592,
          0.7570149975810353,
          0.7455853894533139,
          0.7316158684083213,
          0.7341557813255928,
          0.7341557813255928,
          0.7299225931301402,
          0.7299225931301403,
          0.7235728108369619,
          0.7189163038219643,
          0.7197629414610546,
          0.7201862602806,
          0.7282293178519595,
          0.7350024189646831,
          0.747278664731495,
          0.7629414610546688,
          0.7599782293178521,
          0.7625181422351235,
          0.7527818093855831,
          0.7464320270924045,
          0.7447387518142236,
          0.7451620706337688,
          0.7548984034833093,
          0.7553217223028547,
          0.7587082728592164,
          0.7540517658442188,
          0.7544750846637636,
          0.7506652152878568,
          0.7392356071601357,
          0.7379656507015,
          0.743468795355588,
          0.7413522012578617,
          0.7472786647314947,
          0.7460087082728591,
          0.7578616352201256,
          0.7561683599419449,
          0.7527818093855831,
          0.7434687953555879,
          0.7265360425737784,
          0.7104499274310594,
          0.6981736816642478,
          0.6825108853410741,
          0.664731494920174,
          0.6672714078374454,
          0.6757377842283502,
          0.6858974358974358,
          0.6918238993710691,
          0.7057934204160621,
          0.7172230285437834,
          0.7248427672955976,
          0.7311925495887762,
          0.7515118529269472,
          0.7544750846637641,
          0.7582849540396712,
          0.7548984034833092,
          0.7455853894533142,
          0.7299225931301403,
          0.7299225931301402,
          0.7358490566037735,
          0.7375423318819546,
          0.7358490566037739,
          0.7417755200774071,
          0.7574383164005809,
          0.7671746492501212,
          0.7794508950169329,
          0.7841074020319304,
          0.7891872278664733,
          0.7836840832123851,
          0.7671746492501211,
          0.7620948234155784,
          0.7595549104983069,
          0.7561683599419452,
          0.7625181422351236,
          0.7731011127237544,
          0.7790275761973877,
          0.7786042573778426,
          0.7743710691823901,
          0.7781809385582972,
          0.7794508950169331,
          0.7794508950169332,
          0.7913038219641998,
          0.8078132559264639,
          0.8137397194000972,
          0.8128930817610065,
          0.8141630382196422,
          0.7959603289791971,
          0.7925737784228353,
          0.7896105466860186,
          0.7798742138364779,
          0.7752177068214805,
          0.7637880986937591,
          0.7527818093855831,
          0.7434687953555879,
          0.7354257377842285,
          0.7282293178519593,
          0.7371190130624095,
          0.7481253023705855,
          0.7460087082728594,
          0.7320391872278664,
          0.7333091436865021,
          0.7519351717464926,
          0.7684446057087567,
          0.7849540396710211,
          0.7904571843251091,
          0.7862239961296569,
          0.7845307208514758,
          0.7841074020319305,
          0.7777576197387519,
          0.776064344460571,
          0.7743710691823902,
          0.768444605708757,
          0.7625181422351235,
          0.7608248669569426,
          0.7701378809869378,
          0.7671746492501212,
          0.7553217223028547,
          0.7574383164005809,
          0.7523584905660381,
          0.7464320270924047,
          0.7481253023705856,
          0.7307692307692308,
          0.7235728108369619,
          0.7146831156265118,
          0.6994436381228835,
          0.6791243347847121,
          0.6816642477019835,
          0.6816642477019834,
          0.6816642477019835,
          0.6867440735365264,
          0.6943638122883407,
          0.701983551040155,
          0.6956337687469764,
          0.698597000483793,
          0.7091799709724238,
          0.7163763909046929,
          0.7231494920174166,
          0.7358490566037735,
          0.7350024189646833,
          0.7460087082728594,
          0.7477019835510403,
          0.7451620706337686,
          0.7481253023705855,
          0.7455853894533142,
          0.7328858248669572,
          0.7303459119496857,
          0.7278059990324142,
          0.7375423318819546,
          0.7362723754233189,
          0.747278664731495,
          0.7540517658442191,
          0.7548984034833094,
          0.7663280116110306,
          0.7557450411223998,
          0.7502418964683116,
          0.7506652152878567,
          0.7548984034833092,
          0.7591315916787615,
          0.7396589259796807,
          0.7299225931301404,
          0.7290759554910499,
          0.7345791001451379,
          0.7426221577164974,
          0.7515118529269472,
          0.7468553459119498,
          0.7515118529269472,
          0.748971940009676,
          0.7455853894533142,
          0.7409288824383166,
          0.7193396226415096,
          0.7045234639574263,
          0.7032535074987906,
          0.7070633768746979,
          0.6985970004837929,
          0.701983551040155,
          0.7151064344460575,
          0.7248427672955978,
          0.7167997097242382,
          0.7011369134010647,
          0.6918238993710693,
          0.6854741170778907,
          0.6875907111756169,
          0.7108732462506048,
          0.7261127237542334,
          0.7421988388969524,
          0.7620948234155784,
          0.7794508950169329,
          0.7807208514755687,
          0.7794508950169328,
          0.7646347363328496,
          0.7646347363328494,
          0.7625181422351235,
          0.7591315916787618,
          0.7493952588292212,
          0.7392356071601356,
          0.7417755200774071,
          0.7366956942428642,
          0.7337324625060477,
          0.7388122883405905,
          0.7413522012578617,
          0.7464320270924045,
          0.7493952588292212,
          0.748971940009676,
          0.7481253023705855,
          0.7519351717464926,
          0.7570149975810356,
          0.7523584905660378,
          0.7523584905660377,
          0.743892114175133,
          0.7286526366715047,
          0.7248427672955975,
          0.736272375423319,
          0.7498185776487666,
          0.7642114175133047,
          0.7701378809869381,
          0.7743710691823901,
          0.7794508950169328,
          0.7701378809869376,
          0.7587082728592165,
          0.7532051282051283,
          0.7502418964683116,
          0.7472786647314947,
          0.7362723754233187,
          0.7066400580551522,
          0.7011369134010644,
          0.7011369134010643,
          0.691400580551524,
          0.6888606676342525,
          0.6909772617319787,
          0.6892839864537977,
          0.6880140299951621,
          0.688014029995162,
          0.7087566521528786,
          0.7286526366715048,
          0.7438921141751332,
          0.7510885341074024,
          0.7472786647314951,
          0.7417755200774069,
          0.7426221577164976,
          0.7328858248669572,
          0.7184929850024192,
          0.7303459119496857,
          0.7417755200774071,
          0.7591315916787614,
          0.7604015481373974,
          0.7781809385582973,
          0.7925737784228353,
          0.7980769230769234,
          0.7993468795355589,
          0.80104015481374,
          0.7989235607160137,
          0.7807208514755684,
          0.7671746492501209,
          0.7540517658442185
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFSSGD<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "line": {
          "color": "yellow",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFSSGD",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.007543677550793836,
          0.008921569637373285,
          0.014962697481999267,
          0.0284691792488242,
          0.027047583279579977,
          0.016286007415581213,
          0.032466628646429595,
          0.032466628646429595,
          0.032780930462005094,
          0.05624316538843177,
          0.04499789164153296,
          0.02220267690313817,
          0.026687373860396695,
          0.024625279522711145,
          0.00834504484855294,
          0.005859494414990436,
          0.002794785355606238,
          -0.006526676824025313,
          -0.00522289193436653,
          -0.00522289193436653,
          -0.008124324938001729,
          0.00205382876174628,
          0.005655301964193858,
          0.0064560530003441,
          0.006456053000344101,
          0.0012974089181681796,
          0.0017391749730272857,
          0.003063237125025467,
          0.015345309789083566,
          0.03070006718461832,
          0.02877631255192217,
          0.028290324558585194,
          0.004212214656727281,
          -0.0012255135592902915,
          -0.003917626394628213,
          0.010036613116126102,
          0.004588490879473519,
          0.0045884908794735215,
          0.002993883043710691,
          0.011935622982899432,
          0.04294296104115345,
          0.04493706952464569,
          0.024116824709950937,
          0.013457596104240828,
          0.039933822091198216,
          0.009449825872575809,
          0.009449825872575805,
          0.01057429330104202,
          0.03381465652961456,
          0.017988080347811748,
          0.03817637161172094,
          0.0640834138681645,
          0.07953943134631847,
          0.08641196251250262,
          0.08612089306566094,
          0.08612089306566094,
          0.0576276562428032,
          0.058761291405698086,
          0.09312142229508868,
          0.09255320712299916,
          0.041196496051772884,
          0.049363131202027864,
          0.01623950189792099,
          0.016239501897920994,
          0.009202013488953019,
          0.010725006569713112,
          0.010725006569713109,
          0.023674613616406274,
          0.04407407664699166,
          0.03997659110955894,
          0.04875272902018252,
          0.07868658651148411,
          0.07897211835839021,
          0.0789721183583902,
          0.07897211835839021,
          0.03330096381084797,
          0.07974336128435189,
          0.03298628657535649,
          0.013088399184568526,
          0.014059684976225886,
          0.014059684976225886,
          -0.01136444801616361,
          -0.010273708199982821,
          -0.010273708199982825,
          0.013973961694150765,
          0.013973961694150765,
          -0.006813878348254935,
          -0.005961039109716197,
          0.0075020927198217,
          0.01988097676523245,
          0.01925138491369819,
          0.019880976765232452,
          0.026436471366286057,
          0.027395737903182,
          0.0037715801108724302,
          0.029678622367315995,
          0.02877825385522386,
          0.03485545896179866,
          0.048204221098575736,
          0.048204221098575736,
          0.04914033018353473,
          0.02947158205409401,
          0.029882056769689132,
          0.029431093042512336,
          0.029431093042512336,
          0.028598683102106073,
          0.023302663129201703,
          0.02531456248078094,
          0.0009690691389328817,
          -0.0010227310174760486,
          0.0036460312203420923,
          0.0036460312203420923,
          -0.001731914336196595,
          -0.0011221829719328237,
          -0.001731914336196595,
          0.007449599976440069,
          0.009229864957874962,
          0.01126480053247525,
          0.0025612539190730615,
          0.002083286219838591,
          -0.0006763050290073315,
          0.009946245086501257,
          0.005874875106588918,
          0.018828396234810692,
          0.011668012604775905,
          -0.0008850300299621,
          -0.0074359237311273745,
          -0.007818645230125815,
          -0.007818645230125815,
          -0.007818645230125815,
          -0.008346667807390042,
          -0.008346667807390042,
          -0.00781864523012581,
          -0.00781864523012581,
          -0.009761791619848905,
          -0.009189366167731024,
          -0.008772323663870398,
          -0.006583466664943537,
          0.0022407373550978613,
          0.009908010394840232,
          0.012587203673409684,
          0.01869671889992457,
          0.018696718899924566,
          0.01731492964485682,
          0.017910227995484248,
          0.04210902287060486,
          0.0259418337181607,
          0.0259418337181607,
          0.04521503327910098,
          0.02862983417746544,
          0.029375857548573164,
          0.01642233642035139,
          0.015616542032021345,
          0.02543028268441903,
          0.024613191682417164,
          0.02461319168241716,
          0.024613191682417157,
          0.006318754460420361,
          0.013369844317001804,
          0.012723706159871737,
          0.028428971451281843,
          0.028917322624842944,
          0.022393571646069494,
          0.013212057333432833,
          0.006603878589166959,
          0.014769371419055117,
          0.039379878907816385,
          0.07963351267067692,
          0.07963351267067692,
          0.13854667760681572,
          0.22886667582004058,
          0.22432482309315546,
          0.3367414534338458,
          0.3367414534338458,
          0.2245669558072475,
          0.23252509128121854,
          0.14276966731139445,
          0.07440983434422116,
          0.07440983434422116,
          0.027950162407643624,
          0.0043849780787068365,
          -0.007818645230125817,
          -0.010913428648833259,
          -0.008843644199545544,
          -0.008296858751987438,
          -0.009359605896511039,
          -0.00935960589651104,
          -0.009359605896511039,
          0.014782417704182631,
          0.015648093192123992,
          0.028601614320345792,
          0.015648093192123992,
          0.016183823278142054,
          -0.0019733943303950076,
          -0.003644210506710245,
          0.01379995217505904,
          0.028730381986060222,
          0.044211015882344905,
          0.028454246137096264,
          0.017208972390197454,
          0.025749176784075997,
          0.01767925883653434,
          0.012208817212777081,
          0.02421154593004563,
          0.008463818903339845,
          0.01751683625374586,
          0.012781964271774866,
          0.01028216027558904,
          0.013400894806508608,
          0.011555818831039837,
          0.024416201570925836,
          0.022903098088970626,
          0.03152638087490493,
          0.04027641260887244,
          0.035439469400346896,
          0.03699574108319062,
          0.024042219954968837,
          0.024900041101778278,
          0.0001296224582492169,
          -0.00972141561328505,
          -0.00972141561328505,
          -0.008634181421253653,
          -0.0014876026832172846,
          0.005007209290406813,
          0.0035935089191103864,
          0.0035935089191103864,
          0.028291666204130483,
          0.028291666204130483,
          0.029012979810002747,
          0.03910055380514653,
          0.014111595717212853,
          0.0075140711510704086,
          -0.008312505030732402,
          -0.007320247628976623,
          -0.007320247628976624,
          -0.008227549432699398,
          -0.009638024026592877,
          -0.009638024026592877,
          -0.0035552260412358653,
          -0.0041585857413368645,
          -0.0010982503376985682,
          0.022373108913744697,
          0.022373108913744697,
          0.02201855492453797,
          0.01613304816814429,
          0.016467115900456894,
          0.021895860875496904,
          0.02853161142049261,
          0.015372109896723435,
          0.015849357934971237,
          -0.007622001316472026,
          0.003976056360412823,
          0.004523567106515925,
          -0.00628519758998303,
          -0.006285197589983027,
          0.017470321057758875,
          0.06366217547114021,
          0.06366217547114021,
          0.06334433937649063,
          0.07192947179340209,
          0.0719294717934021,
          0.13948035050190313,
          0.13948035050190313,
          0.07103242942069964,
          0.061850915108062995,
          0.015849357934971237,
          0.000634654327170615,
          0.0015595129961646363,
          0.001559512996164637,
          0.0024260846550798326,
          0.0181831242822813,
          0.0181831242822813,
          0.017217535468479702,
          0.017567029515435154,
          0.014127728939659067,
          0.00755443978869369,
          0.01286315061600401,
          0.011376623299572777,
          0.01092409384772122,
          0.03462697551974663,
          0.03566928731489294,
          0.022692655651944987,
          0.018802599534612534,
          0.02455042636181841,
          0.014520396414796247,
          0.014520396414796246,
          0.015707792807290705,
          0.004489844089341982,
          0.004842229432428202,
          0.014845084612568104,
          0.0148450846125681,
          0.0148450846125681,
          -0.007645462881229515,
          -0.007645462881229515,
          0.014683085763108596,
          0.004388173914764404,
          0.003836452888632934,
          0.0027264701633515544,
          0.0022711844081114638,
          -0.010682336720110324,
          -0.010682336720110321,
          -0.0064668712054904084,
          -0.00607083484581414,
          0.011603910078275548,
          0.0071627919552381255,
          0.02385906740582433,
          0.05344004474904637,
          0.05634319561981679,
          0.05746335218868431,
          0.05634319561981679,
          0.06335852713962571,
          0.053369226987061,
          0.054356204682533174,
          0.0288832933074678,
          0.008483830276882426,
          -0.0006976840357542354,
          0.006412198714037814,
          0.023302663129201706,
          0.029967457461473737,
          0.02245269632352418,
          0.022823253706819487,
          -0.0012400393748421108,
          -0.002234481667586775,
          0.011294270603398531,
          0.03540621745174597,
          0.03455793806327404,
          0.02743909506680945,
          0.0032644238577331625,
          0.00673593693953455,
          -0.005182527466834721,
          0.011209311936891996,
          -0.005398708198000109,
          0.019152711216876322,
          0.018240550792087126,
          0.0005493988266383683,
          0.012941897194357448,
          0.002961448715672468,
          0.0021246313685945968,
          0.002459384317132646,
          0.007884429634015398,
          0.0187157936921491,
          0.02560917624419497,
          0.006821417791370996,
          0.03643086574737137,
          0.03710995206405202,
          0.02406245010650511,
          0.01907898988201875,
          0.019920854180447648,
          0.009100141712799555,
          0.01003911497452493,
          0.006935738380205079,
          0.0008734266517421934,
          0.0017337472098036797,
          -0.0025437891513940734,
          -0.002543789151394073,
          0.006637725161242586,
          0.008003796880282405,
          -0.0006701794526345704,
          0.022767385191657927,
          0.021946271864923476,
          0.022831813910140497,
          0.03451724961158309,
          0.016748224885910826,
          0.01567892592436471,
          0.01481867654235518,
          0.015678925924364706,
          -0.008341108856434801,
          -0.008341108856434801,
          -0.011544737279606206,
          -0.010453434189681754,
          0.0007645145282669682,
          -0.000730814033154582,
          -0.00032678856165748333,
          0.02297150943373584,
          0.02401582212725328,
          0.023426795188975922,
          0.0015799246913558453,
          0.0029903992852493245,
          0.0039737439509660915,
          0.02590232323558572,
          0.02630229259530421,
          0.026963030697343307,
          0.027309262545359043,
          0.01653925203549959,
          0.016539252035499583,
          0.02852731884689834,
          0.00619877020256022,
          0.014841617196034178,
          0.014404138883492942,
          0.007864264497417683,
          0.02309197635507595,
          0.035582607964353336,
          0.035582607964353336,
          0.031178861020948006,
          0.01339372619928019,
          0.010656149945935124,
          -0.0016458754285197696,
          -0.0008113299075811234,
          -0.008983082989068712,
          0.0032779288097016493,
          0.012459443122338307,
          0.01345790773981556,
          0.014002531803239255,
          0.01452861282481094,
          0.010867017571839818,
          0.009634680875072375,
          0.001307299287312298,
          -0.005090975522776172,
          -0.00550978874482231,
          0.018604899113173964,
          0.018934262279001555,
          0.018604899113173964,
          0.018256992905494363,
          0.017366766483291128,
          0.01736676648329112,
          0.016955270052394625,
          0.03189809877100856,
          0.037241157834452095,
          0.012233067340012603,
          0.010360203867406388,
          0.024574466532170675,
          0.024574466532170675,
          0.025182036512300037,
          0.019462316655098778,
          0.01805071555339722,
          0.027232229866033873,
          0.0002997370100980111,
          0.000841867845433333,
          0.0028556615276239964,
          -0.00783199588872467,
          0.013607740325384435,
          0.017055490511403794,
          0.02910170983590281,
          0.015334633381401752,
          0.01650322367070742,
          0.016503223670707418,
          0.016503223670707418,
          0.016965714469062206,
          0.03532150227326514,
          0.009414460016821544
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=FSDS<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "line": {
          "color": "green",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FSDS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.06243386243386243,
          0.06455026455026457,
          0.04804232804232804,
          0.0471957671957672,
          0.050158730158730166,
          0.05354497354497356,
          0.06031746031746034,
          0.06412698412698416,
          0.064973544973545,
          0.048888888888888885,
          0.053121693121693125,
          0.056507936507936514,
          0.058201058201058205,
          0.05608465608465608,
          0.059047619047619036,
          0.05650793650793651,
          0.06793650793650793,
          0.06582010582010585,
          0.06455026455026457,
          0.07470899470899471,
          0.08825396825396827,
          0.08317460317460316,
          0.07978835978835977,
          0.07513227513227512,
          0.08021164021164022,
          0.08444444444444445,
          0.07047619047619048,
          0.06666666666666667,
          0.06582010582010582,
          0.06285714285714285,
          0.06666666666666668,
          0.06751322751322754,
          0.06751322751322753,
          0.07597883597883597,
          0.07809523809523809,
          0.08148148148148147,
          0.08486772486772486,
          0.07724867724867725,
          0.06455026455026457,
          0.06920634920634923,
          0.07513227513227515,
          0.07978835978835981,
          0.07724867724867727,
          0.09333333333333334,
          0.08994708994708997,
          0.08529100529100529,
          0.07682539682539684,
          0.07894179894179895,
          0.08063492063492063,
          0.07724867724867725,
          0.07005291005291005,
          0.058624338624338614,
          0.06116402116402118,
          0.06285714285714286,
          0.060740740740740734,
          0.05439153439153441,
          0.056084656084656105,
          0.055661375661375675,
          0.048465608465608476,
          0.05947089947089948,
          0.0670899470899471,
          0.06962962962962964,
          0.07428571428571432,
          0.07005291005291008,
          0.06751322751322754,
          0.0632804232804233,
          0.06243386243386245,
          0.06751322751322754,
          0.06835978835978838,
          0.07809523809523812,
          0.07682539682539685,
          0.08063492063492064,
          0.08105820105820107,
          0.08571428571428574,
          0.10264550264550266,
          0.09544973544973549,
          0.10687830687830689,
          0.10306878306878309,
          0.10010582010582011,
          0.09206349206349207,
          0.10476190476190476,
          0.08952380952380956,
          0.08317460317460319,
          0.09714285714285716,
          0.08275132275132276,
          0.08571428571428572,
          0.08994708994708997,
          0.07851851851851854,
          0.08571428571428574,
          0.08740740740740742,
          0.08148148148148149,
          0.08825396825396827,
          0.09291005291005291,
          0.08486772486772487,
          0.08698412698412697,
          0.06962962962962964,
          0.07682539682539681,
          0.07259259259259261,
          0.0738624338624339,
          0.0797883597883598,
          0.09333333333333334,
          0.0865608465608466,
          0.08613756613756617,
          0.08698412698412702,
          0.09121693121693124,
          0.08656084656084659,
          0.08444444444444445,
          0.07428571428571427,
          0.07132275132275134,
          0.0764021164021164,
          0.07343915343915347,
          0.07851851851851852,
          0.06497354497354499,
          0.058624338624338614,
          0.057777777777777775,
          0.05058201058201056,
          0.057777777777777775,
          0.06962962962962964,
          0.07894179894179895,
          0.06624338624338624,
          0.06455026455026457,
          0.05862433862433865,
          0.0670899470899471,
          0.06708994708994712,
          0.06412698412698416,
          0.060317460317460325,
          0.05947089947089948,
          0.05989417989417989,
          0.051005291005291005,
          0.06455026455026455,
          0.07767195767195767,
          0.07682539682539684,
          0.07132275132275132,
          0.06624338624338623,
          0.07851851851851852,
          0.06962962962962964,
          0.08571428571428572,
          0.07682539682539684,
          0.07174603174603177,
          0.07851851851851853,
          0.06285714285714286,
          0.06074074074074074,
          0.06835978835978837,
          0.07005291005291008,
          0.057777777777777775,
          0.05269841269841271,
          0.06285714285714288,
          0.056507936507936514,
          0.05777777777777779,
          0.05439153439153439,
          0.06243386243386245,
          0.06835978835978837,
          0.07640211640211642,
          0.06328042328042328,
          0.05523809523809523,
          0.051428571428571435,
          0.03322751322751323,
          0.0471957671957672,
          0.04719576719576721,
          0.04973544973544974,
          0.041269841269841276,
          0.04169312169312169,
          0.05015873015873016,
          0.059470899470899466,
          0.06920634920634922,
          0.07132275132275134,
          0.07513227513227515,
          0.07851851851851854,
          0.08190476190476194,
          0.07343915343915346,
          0.07809523809523809,
          0.08275132275132277,
          0.08867724867724869,
          0.08783068783068787,
          0.08656084656084659,
          0.08613756613756617,
          0.07597883597883599,
          0.0797883597883598,
          0.0725925925925926,
          0.07047619047619047,
          0.06243386243386244,
          0.06878306878306881,
          0.06539682539682541,
          0.06708994708994709,
          0.058201058201058205,
          0.06370370370370372,
          0.06835978835978837,
          0.06243386243386243,
          0.05185185185185185,
          0.05142857142857143,
          0.05058201058201059,
          0.06074074074074074,
          0.05354497354497356,
          0.04507936507936508,
          0.042116402116402114,
          0.04423280423280423,
          0.0455026455026455,
          0.056084656084656084,
          0.06412698412698413,
          0.06666666666666667,
          0.06285714285714285,
          0.06751322751322753,
          0.07089947089947092,
          0.07089947089947092,
          0.07809523809523812,
          0.0742857142857143,
          0.08021164021164022,
          0.07343915343915343,
          0.07936507936507937,
          0.07597883597883598,
          0.08275132275132276,
          0.0891005291005291,
          0.07005291005291006,
          0.07343915343915344,
          0.07343915343915343,
          0.06920634920634922,
          0.08063492063492063,
          0.07767195767195767,
          0.07682539682539684,
          0.07386243386243388,
          0.07724867724867725,
          0.06328042328042328,
          0.07682539682539685,
          0.06708994708994709,
          0.06624338624338624,
          0.04973544973544974,
          0.05015873015873016,
          0.05777777777777778,
          0.0526984126984127,
          0.05735449735449735,
          0.07386243386243388,
          0.06624338624338627,
          0.06201058201058202,
          0.06370370370370372,
          0.05566137566137568,
          0.06751322751322754,
          0.05904761904761905,
          0.05777777777777776,
          0.06455026455026452,
          0.062010582010582,
          0.06835978835978836,
          0.05566137566137566,
          0.05227513227513228,
          0.06116402116402118,
          0.07174603174603175,
          0.0738624338624339,
          0.0810582010582011,
          0.09333333333333337,
          0.09925925925925924,
          0.10391534391534395,
          0.09883597883597885,
          0.09587301587301585,
          0.09968253968253966,
          0.08698412698412698,
          0.08825396825396827,
          0.08021164021164022,
          0.08105820105820107,
          0.06708994708994707,
          0.07640211640211639,
          0.07428571428571427,
          0.06878306878306878,
          0.0675132275132275,
          0.07005291005291006,
          0.07132275132275134,
          0.07301587301587303,
          0.06031746031746034,
          0.06285714285714286,
          0.06455026455026457,
          0.05989417989417989,
          0.06116402116402116,
          0.0598941798941799,
          0.057777777777777775,
          0.059470899470899466,
          0.058201058201058205,
          0.07005291005291003,
          0.07216931216931217,
          0.07089947089947092,
          0.06708994708994709,
          0.06962962962962962,
          0.08825396825396827,
          0.09714285714285714,
          0.10645502645502646,
          0.10560846560846564,
          0.11153439153439154,
          0.09671957671957673,
          0.10603174603174607,
          0.11322751322751322,
          0.09502645502645504,
          0.08063492063492066,
          0.07343915343915346,
          0.0687830687830688,
          0.06285714285714286,
          0.06920634920634923,
          0.07089947089947092,
          0.07174603174603177,
          0.05523809523809524,
          0.048888888888888885,
          0.06328042328042328,
          0.07174603174603175,
          0.06455026455026455,
          0.07343915343915344,
          0.06835978835978837,
          0.0670899470899471,
          0.06624338624338626,
          0.07301587301587302,
          0.08825396825396828,
          0.08317460317460319,
          0.07767195767195767,
          0.0687830687830688,
          0.0780952380952381,
          0.07132275132275133,
          0.07470899470899472,
          0.08952380952380955,
          0.07851851851851854,
          0.07470899470899474,
          0.0666666666666667,
          0.06835978835978837,
          0.06497354497354496,
          0.06201058201058199,
          0.0675132275132275,
          0.06708994708994707,
          0.06497354497354499,
          0.06793650793650795,
          0.053968253968253985,
          0.05142857142857145,
          0.05693121693121694,
          0.060317460317460325,
          0.05354497354497356,
          0.05989417989417991,
          0.06666666666666668,
          0.07174603174603177,
          0.08317460317460319,
          0.08656084656084659,
          0.08571428571428574,
          0.0721693121693122,
          0.06878306878306882,
          0.06285714285714288,
          0.06666666666666668,
          0.05820105820105821,
          0.05185185185185185,
          0.05989417989417989,
          0.05354497354497354,
          0.05693121693121693,
          0.06285714285714286,
          0.0598941798941799,
          0.06455026455026455,
          0.060317460317460325,
          0.05904761904761905,
          0.057777777777777775,
          0.05777777777777778,
          0.04804232804232804,
          0.061164021164021164,
          0.06582010582010582,
          0.06624338624338624,
          0.07894179894179897,
          0.0776719576719577,
          0.07894179894179897,
          0.08317460317460319,
          0.0835978835978836,
          0.08402116402116404,
          0.0946031746031746,
          0.08021164021164022,
          0.09164021164021167,
          0.08529100529100529,
          0.09121693121693121,
          0.10349206349206351,
          0.09714285714285716,
          0.09714285714285716,
          0.08190476190476194,
          0.07640211640211644,
          0.08656084656084659,
          0.09629629629629631,
          0.09164021164021163,
          0.0857142857142857,
          0.07513227513227515,
          0.07682539682539684,
          0.07301587301587305,
          0.06285714285714288,
          0.06920634920634924,
          0.07005291005291008,
          0.06962962962962964,
          0.0704761904761905,
          0.07640211640211643,
          0.08317460317460319,
          0.07216931216931219,
          0.07343915343915346,
          0.07047619047619048,
          0.0742857142857143,
          0.06878306878306881,
          0.061164021164021184,
          0.06201058201058202,
          0.07174603174603177,
          0.0742857142857143,
          0.07470899470899472,
          0.07597883597883599,
          0.07301587301587302,
          0.07259259259259258,
          0.07767195767195767,
          0.08317460317460318,
          0.08190476190476191,
          0.08105820105820107,
          0.08402116402116402,
          0.06920634920634922,
          0.08275132275132277,
          0.09079365079365082,
          0.08275132275132276,
          0.07047619047619047,
          0.07132275132275132,
          0.06455026455026455,
          0.06751322751322751,
          0.07597883597883599,
          0.0725925925925926,
          0.08656084656084656,
          0.08444444444444446,
          0.0852910052910053,
          0.08698412698412698,
          0.09502645502645504,
          0.09079365079365079,
          0.08275132275132274,
          0.08825396825396824,
          0.08275132275132274,
          0.08317460317460319,
          0.09756613756613758,
          0.08867724867724872,
          0.08910052910052912,
          0.08740740740740742,
          0.08910052910052912,
          0.08952380952380952,
          0.08740740740740742,
          0.0819047619047619,
          0.07597883597883599,
          0.06582010582010582,
          0.05693121693121693,
          0.06708994708994707,
          0.08105820105820107,
          0.07767195767195768,
          0.08105820105820108,
          0.08021164021164022,
          0.08656084656084656,
          0.08740740740740742
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Stability on dataset syn_ds_4"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "batches"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "stability"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# stability\n",
    "title = \"Stability on dataset {}\".format(dataset_name)\n",
    "col_names = [\"FIRES\", \"OFS\", \"OFSSGD\", \"FSDS\"]\n",
    "d = {\"FIRES\":fires_cuda_stability, \"OFS\":ofs_stability, \"OFSSGD\":ofssgd_stability, \"FSDS\":fsds_stability} #\"random\":random_stability\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y = col_names, title=title, labels={\"index\":\"batches\", \"value\":\"stability\"},color_discrete_map={'FIRES': 'red', \n",
    "                                                    'OFS': 'purple','FSDS': 'green', \"OFSSGD\":\"yellow\"})\n",
    "fig.write_image(\"{}/stability.{}\".format(folder, export_type))\n",
    "stability_trace = fig['data']\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean values\n",
    "csv_name = \"{}/stability_avg.csv\".format(folder)\n",
    "df.mean().to_csv(csv_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Pure<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "Pure",
         "line": {
          "color": "blue",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Pure",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.10600000000000001,
          0.10700000000000001,
          0.10900000000000001,
          0.10300000000000001,
          0.097,
          0.09000000000000001,
          0.095,
          0.1,
          0.10200000000000001,
          0.097,
          0.087,
          0.08600000000000001,
          0.08700000000000001,
          0.092,
          0.098,
          0.101,
          0.096,
          0.094,
          0.097,
          0.098,
          0.10800000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10300000000000001,
          0.099,
          0.10500000000000001,
          0.11000000000000001,
          0.10800000000000001,
          0.10800000000000001,
          0.10600000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.10800000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.11400000000000002,
          0.11000000000000001,
          0.11100000000000002,
          0.11099999999999999,
          0.11000000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.11000000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.097,
          0.097,
          0.097,
          0.097,
          0.101,
          0.10799999999999998,
          0.10600000000000001,
          0.10799999999999998,
          0.10600000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11699999999999999,
          0.11299999999999999,
          0.118,
          0.11699999999999999,
          0.10700000000000001,
          0.11100000000000002,
          0.10600000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.10600000000000001,
          0.10700000000000001,
          0.101,
          0.11299999999999999,
          0.10900000000000001,
          0.11699999999999999,
          0.118,
          0.11800000000000002,
          0.11699999999999999,
          0.11600000000000002,
          0.11200000000000002,
          0.11100000000000002,
          0.118,
          0.11299999999999999,
          0.11699999999999999,
          0.11299999999999999,
          0.11499999999999999,
          0.11699999999999999,
          0.125,
          0.127,
          0.137,
          0.141,
          0.135,
          0.13599999999999998,
          0.129,
          0.135,
          0.136,
          0.13199999999999998,
          0.134,
          0.136,
          0.135,
          0.131,
          0.135,
          0.132,
          0.138,
          0.131,
          0.13,
          0.137,
          0.13199999999999998,
          0.129,
          0.135,
          0.14100000000000001,
          0.134,
          0.136,
          0.13399999999999998,
          0.133,
          0.13399999999999998,
          0.134,
          0.12599999999999997,
          0.126,
          0.121,
          0.11500000000000002,
          0.12000000000000002,
          0.119,
          0.123,
          0.123,
          0.12000000000000002,
          0.118,
          0.127,
          0.13,
          0.12800000000000003,
          0.13,
          0.13099999999999998,
          0.134,
          0.12400000000000003,
          0.127,
          0.128,
          0.127,
          0.122,
          0.11599999999999999,
          0.11400000000000002,
          0.121,
          0.11600000000000002,
          0.11499999999999999,
          0.119,
          0.11900000000000002,
          0.127,
          0.128,
          0.13,
          0.135,
          0.13,
          0.11900000000000002,
          0.126,
          0.122,
          0.13,
          0.129,
          0.126,
          0.12600000000000003,
          0.124,
          0.11900000000000002,
          0.123,
          0.12999999999999998,
          0.13,
          0.133,
          0.128,
          0.126,
          0.121,
          0.12,
          0.121,
          0.122,
          0.129,
          0.118,
          0.11400000000000002,
          0.11699999999999999,
          0.119,
          0.127,
          0.126,
          0.127,
          0.132,
          0.13999999999999999,
          0.14200000000000002,
          0.159,
          0.16199999999999998,
          0.157,
          0.156,
          0.152,
          0.15100000000000002,
          0.149,
          0.14100000000000001,
          0.135,
          0.133,
          0.123,
          0.129,
          0.129,
          0.127,
          0.132,
          0.13599999999999998,
          0.143,
          0.151,
          0.153,
          0.14700000000000002,
          0.146,
          0.137,
          0.13999999999999999,
          0.14700000000000002,
          0.13699999999999998,
          0.144,
          0.135,
          0.127,
          0.123,
          0.121,
          0.121,
          0.122,
          0.12400000000000003,
          0.124,
          0.131,
          0.12899999999999998,
          0.135,
          0.142,
          0.148,
          0.151,
          0.15899999999999997,
          0.158,
          0.155,
          0.149,
          0.146,
          0.137,
          0.142,
          0.135,
          0.134,
          0.132,
          0.127,
          0.131,
          0.133,
          0.129,
          0.133,
          0.138,
          0.137,
          0.144,
          0.152,
          0.162,
          0.16,
          0.16099999999999998,
          0.164,
          0.16599999999999998,
          0.164,
          0.16499999999999998,
          0.16399999999999998,
          0.161,
          0.151,
          0.144,
          0.15,
          0.14800000000000002,
          0.144,
          0.152,
          0.154,
          0.155,
          0.14700000000000002,
          0.153,
          0.16,
          0.16599999999999998,
          0.161,
          0.16399999999999998,
          0.17099999999999999,
          0.163,
          0.16299999999999998,
          0.162,
          0.16499999999999998,
          0.155,
          0.146,
          0.14500000000000002,
          0.147,
          0.152,
          0.14400000000000002,
          0.147,
          0.15,
          0.149,
          0.152,
          0.153,
          0.15,
          0.146,
          0.147,
          0.146,
          0.146,
          0.144,
          0.14100000000000001,
          0.13999999999999999,
          0.138,
          0.13599999999999998,
          0.138,
          0.13799999999999998,
          0.13,
          0.12200000000000003,
          0.134,
          0.139,
          0.13799999999999998,
          0.139,
          0.13799999999999998,
          0.14700000000000002,
          0.146,
          0.156,
          0.166,
          0.172,
          0.16799999999999998,
          0.173,
          0.181,
          0.179,
          0.188,
          0.182,
          0.188,
          0.182,
          0.177,
          0.184,
          0.181,
          0.17600000000000002,
          0.17200000000000001,
          0.177,
          0.168,
          0.16899999999999998,
          0.166,
          0.16,
          0.157,
          0.148,
          0.149,
          0.143,
          0.13599999999999998,
          0.129,
          0.12599999999999997,
          0.131,
          0.13199999999999998,
          0.14,
          0.141,
          0.145,
          0.14,
          0.143,
          0.14700000000000002,
          0.155,
          0.15699999999999997,
          0.151,
          0.15300000000000002,
          0.13899999999999998,
          0.14500000000000002,
          0.14600000000000002,
          0.146,
          0.14400000000000002,
          0.143,
          0.13799999999999998,
          0.139,
          0.14100000000000001,
          0.13299999999999998,
          0.144,
          0.14300000000000002,
          0.142,
          0.154,
          0.15899999999999997,
          0.16,
          0.17200000000000001,
          0.179,
          0.186,
          0.191,
          0.178,
          0.176,
          0.16999999999999998,
          0.16699999999999998,
          0.167,
          0.16799999999999998,
          0.162,
          0.157,
          0.15,
          0.158,
          0.166,
          0.166,
          0.167,
          0.167,
          0.172,
          0.17200000000000001,
          0.165,
          0.16599999999999998,
          0.171,
          0.16699999999999998,
          0.17,
          0.176,
          0.18,
          0.175,
          0.169,
          0.16599999999999998,
          0.165,
          0.163,
          0.16599999999999998,
          0.163,
          0.163,
          0.151,
          0.145,
          0.146,
          0.146,
          0.14100000000000001,
          0.148,
          0.155,
          0.147,
          0.148,
          0.152,
          0.15799999999999997,
          0.17200000000000001,
          0.176,
          0.177,
          0.194,
          0.191,
          0.192,
          0.195,
          0.195,
          0.193,
          0.187,
          0.17700000000000002,
          0.16299999999999998,
          0.157,
          0.152,
          0.14900000000000002,
          0.14,
          0.149,
          0.152,
          0.15,
          0.158,
          0.15699999999999997,
          0.17099999999999999,
          0.185,
          0.182,
          0.188,
          0.183,
          0.172,
          0.165,
          0.16699999999999998,
          0.16699999999999998,
          0.164,
          0.15799999999999997,
          0.157,
          0.16099999999999998,
          0.16099999999999998,
          0.16999999999999998,
          0.176,
          0.185,
          0.188,
          0.1893877551020408
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=FIRES<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "line": {
          "color": "red",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FIRES",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.10200000000000001,
          0.10200000000000001,
          0.10699999999999998,
          0.10800000000000001,
          0.10600000000000001,
          0.101,
          0.095,
          0.091,
          0.087,
          0.086,
          0.096,
          0.1,
          0.095,
          0.093,
          0.097,
          0.095,
          0.10600000000000001,
          0.10900000000000001,
          0.10700000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.101,
          0.099,
          0.10400000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.098,
          0.101,
          0.10300000000000001,
          0.10600000000000001,
          0.094,
          0.098,
          0.10400000000000001,
          0.097,
          0.093,
          0.092,
          0.101,
          0.101,
          0.10500000000000001,
          0.10200000000000001,
          0.10400000000000001,
          0.101,
          0.098,
          0.1,
          0.10300000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.101,
          0.099,
          0.097,
          0.099,
          0.10700000000000001,
          0.10700000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.098,
          0.097,
          0.096,
          0.097,
          0.094,
          0.099,
          0.092,
          0.093,
          0.095,
          0.091,
          0.096,
          0.094,
          0.1,
          0.1,
          0.10699999999999998,
          0.101,
          0.101,
          0.101,
          0.1,
          0.10300000000000001,
          0.10300000000000001,
          0.10200000000000001,
          0.1,
          0.096,
          0.093,
          0.10300000000000001,
          0.1,
          0.1,
          0.1,
          0.097,
          0.096,
          0.101,
          0.095,
          0.10200000000000001,
          0.101,
          0.092,
          0.095,
          0.091,
          0.094,
          0.095,
          0.091,
          0.085,
          0.091,
          0.09,
          0.096,
          0.092,
          0.098,
          0.10300000000000001,
          0.101,
          0.097,
          0.10200000000000001,
          0.101,
          0.10300000000000001,
          0.10300000000000001,
          0.10400000000000001,
          0.11399999999999999,
          0.11300000000000002,
          0.11000000000000001,
          0.11300000000000002,
          0.11900000000000002,
          0.121,
          0.12300000000000003,
          0.121,
          0.11499999999999999,
          0.11599999999999999,
          0.11000000000000001,
          0.10799999999999998,
          0.11000000000000001,
          0.11099999999999999,
          0.11499999999999999,
          0.11099999999999999,
          0.11299999999999999,
          0.11699999999999999,
          0.11800000000000002,
          0.10999999999999999,
          0.11600000000000002,
          0.118,
          0.11499999999999999,
          0.11299999999999999,
          0.11099999999999999,
          0.10899999999999999,
          0.11100000000000002,
          0.11000000000000001,
          0.11399999999999999,
          0.12300000000000003,
          0.119,
          0.11900000000000002,
          0.12,
          0.126,
          0.126,
          0.128,
          0.127,
          0.125,
          0.12600000000000003,
          0.121,
          0.12100000000000002,
          0.12,
          0.12200000000000003,
          0.11599999999999999,
          0.11600000000000002,
          0.11599999999999999,
          0.11200000000000002,
          0.10900000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10300000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.096,
          0.099,
          0.1,
          0.10400000000000001,
          0.10300000000000001,
          0.10900000000000001,
          0.11599999999999999,
          0.11300000000000002,
          0.10600000000000001,
          0.10900000000000001,
          0.11300000000000002,
          0.11299999999999999,
          0.10900000000000001,
          0.10800000000000001,
          0.122,
          0.11000000000000001,
          0.10200000000000001,
          0.10699999999999998,
          0.12,
          0.121,
          0.122,
          0.124,
          0.123,
          0.124,
          0.11199999999999999,
          0.123,
          0.132,
          0.12300000000000003,
          0.119,
          0.11900000000000002,
          0.121,
          0.11800000000000002,
          0.126,
          0.124,
          0.126,
          0.11600000000000002,
          0.11300000000000002,
          0.119,
          0.11700000000000002,
          0.12,
          0.119,
          0.124,
          0.122,
          0.132,
          0.134,
          0.137,
          0.13299999999999998,
          0.131,
          0.135,
          0.128,
          0.12400000000000003,
          0.12,
          0.12100000000000002,
          0.11399999999999999,
          0.11300000000000002,
          0.10800000000000001,
          0.11200000000000002,
          0.11099999999999999,
          0.10500000000000001,
          0.10600000000000001,
          0.11299999999999999,
          0.119,
          0.11299999999999999,
          0.11300000000000002,
          0.10899999999999999,
          0.11699999999999999,
          0.11600000000000002,
          0.12,
          0.12000000000000002,
          0.124,
          0.12000000000000002,
          0.11200000000000002,
          0.11900000000000002,
          0.124,
          0.14,
          0.137,
          0.14,
          0.14100000000000001,
          0.144,
          0.14300000000000002,
          0.143,
          0.154,
          0.15,
          0.14100000000000001,
          0.129,
          0.135,
          0.131,
          0.131,
          0.129,
          0.123,
          0.126,
          0.11900000000000002,
          0.119,
          0.122,
          0.123,
          0.12300000000000003,
          0.123,
          0.129,
          0.133,
          0.129,
          0.128,
          0.121,
          0.121,
          0.119,
          0.11800000000000002,
          0.119,
          0.125,
          0.11700000000000002,
          0.119,
          0.13099999999999998,
          0.131,
          0.13599999999999998,
          0.14100000000000001,
          0.146,
          0.145,
          0.142,
          0.138,
          0.13599999999999998,
          0.131,
          0.126,
          0.123,
          0.12100000000000002,
          0.11499999999999999,
          0.10800000000000001,
          0.10600000000000001,
          0.10400000000000001,
          0.10700000000000001,
          0.10500000000000001,
          0.11200000000000002,
          0.11300000000000002,
          0.11300000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.121,
          0.129,
          0.13,
          0.123,
          0.12600000000000003,
          0.118,
          0.11600000000000002,
          0.118,
          0.12000000000000002,
          0.123,
          0.12700000000000003,
          0.125,
          0.126,
          0.131,
          0.13399999999999998,
          0.134,
          0.13599999999999998,
          0.14,
          0.144,
          0.14300000000000002,
          0.13399999999999998,
          0.133,
          0.131,
          0.126,
          0.124,
          0.124,
          0.12400000000000003,
          0.11599999999999999,
          0.11299999999999999,
          0.11599999999999999,
          0.121,
          0.122,
          0.121,
          0.122,
          0.124,
          0.123,
          0.12199999999999997,
          0.124,
          0.121,
          0.11699999999999999,
          0.123,
          0.11499999999999999,
          0.124,
          0.128,
          0.124,
          0.126,
          0.132,
          0.135,
          0.13299999999999998,
          0.133,
          0.11900000000000002,
          0.128,
          0.11700000000000002,
          0.11199999999999999,
          0.11500000000000002,
          0.11399999999999999,
          0.10600000000000001,
          0.11000000000000001,
          0.11299999999999999,
          0.11900000000000002,
          0.128,
          0.12200000000000003,
          0.122,
          0.122,
          0.126,
          0.122,
          0.129,
          0.129,
          0.134,
          0.129,
          0.124,
          0.126,
          0.127,
          0.127,
          0.12000000000000002,
          0.129,
          0.13099999999999998,
          0.127,
          0.122,
          0.129,
          0.135,
          0.137,
          0.14100000000000001,
          0.147,
          0.154,
          0.153,
          0.15,
          0.147,
          0.14700000000000002,
          0.14300000000000002,
          0.142,
          0.142,
          0.135,
          0.13,
          0.131,
          0.132,
          0.132,
          0.139,
          0.14200000000000002,
          0.146,
          0.14500000000000002,
          0.142,
          0.143,
          0.147,
          0.15199999999999997,
          0.15999999999999998,
          0.158,
          0.15099999999999997,
          0.147,
          0.138,
          0.13799999999999998,
          0.14300000000000002,
          0.144,
          0.134,
          0.12100000000000002,
          0.11299999999999999,
          0.10800000000000001,
          0.11000000000000001,
          0.11100000000000002,
          0.119,
          0.11800000000000002,
          0.11199999999999999,
          0.119,
          0.126,
          0.13199999999999998,
          0.136,
          0.141,
          0.144,
          0.13899999999999998,
          0.13,
          0.124,
          0.129,
          0.12600000000000003,
          0.129,
          0.127,
          0.122,
          0.124,
          0.12799999999999997,
          0.14,
          0.147,
          0.15499999999999997,
          0.152,
          0.1553469387755102
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "line": {
          "color": "purple",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.094,
          0.096,
          0.096,
          0.095,
          0.1,
          0.101,
          0.10900000000000001,
          0.11300000000000002,
          0.10600000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.101,
          0.10500000000000001,
          0.11100000000000002,
          0.10900000000000001,
          0.11100000000000002,
          0.10600000000000001,
          0.10200000000000001,
          0.1,
          0.10700000000000001,
          0.11399999999999999,
          0.11600000000000002,
          0.11099999999999999,
          0.10900000000000001,
          0.11299999999999999,
          0.11400000000000002,
          0.11299999999999999,
          0.11499999999999999,
          0.11700000000000002,
          0.10899999999999999,
          0.10300000000000001,
          0.10200000000000001,
          0.099,
          0.1,
          0.092,
          0.09200000000000001,
          0.101,
          0.10200000000000001,
          0.10400000000000001,
          0.10900000000000001,
          0.11099999999999999,
          0.10800000000000001,
          0.11000000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.11200000000000002,
          0.10800000000000001,
          0.11200000000000002,
          0.10400000000000001,
          0.096,
          0.094,
          0.099,
          0.099,
          0.093,
          0.09,
          0.092,
          0.09,
          0.086,
          0.088,
          0.096,
          0.10500000000000001,
          0.10600000000000001,
          0.10899999999999999,
          0.10899999999999999,
          0.10800000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.101,
          0.095,
          0.089,
          0.084,
          0.084,
          0.088,
          0.089,
          0.08900000000000001,
          0.087,
          0.094,
          0.094,
          0.097,
          0.101,
          0.10200000000000001,
          0.10400000000000001,
          0.098,
          0.101,
          0.101,
          0.093,
          0.093,
          0.092,
          0.091,
          0.095,
          0.098,
          0.10300000000000001,
          0.10899999999999999,
          0.10500000000000001,
          0.10300000000000001,
          0.10700000000000001,
          0.101,
          0.10500000000000001,
          0.10300000000000001,
          0.10300000000000001,
          0.10700000000000001,
          0.10300000000000001,
          0.099,
          0.101,
          0.10200000000000001,
          0.10300000000000001,
          0.10899999999999999,
          0.10900000000000001,
          0.10599999999999998,
          0.10700000000000001,
          0.1,
          0.10200000000000001,
          0.11000000000000001,
          0.11200000000000002,
          0.11699999999999999,
          0.12,
          0.11599999999999999,
          0.11299999999999999,
          0.11900000000000002,
          0.11499999999999999,
          0.11900000000000002,
          0.11299999999999999,
          0.10700000000000001,
          0.10600000000000001,
          0.10800000000000001,
          0.11099999999999999,
          0.11100000000000002,
          0.11500000000000002,
          0.11699999999999999,
          0.12000000000000002,
          0.11699999999999999,
          0.12300000000000003,
          0.122,
          0.124,
          0.126,
          0.12300000000000003,
          0.11700000000000002,
          0.12,
          0.11400000000000002,
          0.10300000000000001,
          0.10600000000000001,
          0.101,
          0.10400000000000001,
          0.10500000000000001,
          0.099,
          0.101,
          0.10500000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.101,
          0.094,
          0.092,
          0.091,
          0.09100000000000001,
          0.096,
          0.098,
          0.10899999999999999,
          0.10999999999999999,
          0.10800000000000001,
          0.10599999999999998,
          0.11200000000000002,
          0.121,
          0.12,
          0.125,
          0.118,
          0.12,
          0.11499999999999999,
          0.11500000000000002,
          0.119,
          0.123,
          0.12,
          0.11299999999999999,
          0.11200000000000002,
          0.11099999999999999,
          0.11299999999999999,
          0.11200000000000002,
          0.10600000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.11000000000000001,
          0.10700000000000001,
          0.10800000000000001,
          0.11099999999999999,
          0.11000000000000001,
          0.10600000000000001,
          0.10600000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11299999999999999,
          0.11400000000000002,
          0.11399999999999999,
          0.10699999999999998,
          0.10700000000000001,
          0.10800000000000001,
          0.11299999999999999,
          0.11300000000000002,
          0.10899999999999999,
          0.10400000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10900000000000001,
          0.10800000000000001,
          0.11399999999999999,
          0.10500000000000001,
          0.10200000000000001,
          0.10600000000000001,
          0.11200000000000002,
          0.11499999999999999,
          0.11700000000000002,
          0.128,
          0.124,
          0.128,
          0.12300000000000003,
          0.129,
          0.13,
          0.129,
          0.126,
          0.122,
          0.124,
          0.10899999999999999,
          0.11100000000000002,
          0.10900000000000001,
          0.11000000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.10900000000000001,
          0.10499999999999998,
          0.10500000000000001,
          0.10200000000000001,
          0.10899999999999999,
          0.11299999999999999,
          0.10799999999999998,
          0.10700000000000001,
          0.10500000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10800000000000001,
          0.10900000000000001,
          0.10800000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.10800000000000001,
          0.10700000000000001,
          0.11399999999999999,
          0.11200000000000002,
          0.11499999999999999,
          0.11200000000000002,
          0.11699999999999999,
          0.11100000000000002,
          0.10300000000000001,
          0.093,
          0.096,
          0.099,
          0.093,
          0.10400000000000001,
          0.10600000000000001,
          0.10200000000000001,
          0.097,
          0.10400000000000001,
          0.11099999999999999,
          0.124,
          0.129,
          0.129,
          0.139,
          0.128,
          0.121,
          0.133,
          0.12999999999999998,
          0.127,
          0.121,
          0.11699999999999999,
          0.11300000000000002,
          0.10899999999999999,
          0.10200000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.099,
          0.10400000000000001,
          0.10900000000000001,
          0.11399999999999999,
          0.10900000000000001,
          0.10600000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.12000000000000002,
          0.124,
          0.12500000000000003,
          0.121,
          0.11400000000000002,
          0.10800000000000001,
          0.10700000000000003,
          0.10800000000000001,
          0.11099999999999999,
          0.10700000000000001,
          0.10300000000000001,
          0.097,
          0.097,
          0.099,
          0.10500000000000001,
          0.11299999999999999,
          0.121,
          0.127,
          0.12600000000000003,
          0.122,
          0.121,
          0.121,
          0.121,
          0.126,
          0.123,
          0.11500000000000002,
          0.10800000000000001,
          0.10500000000000001,
          0.1,
          0.11099999999999999,
          0.11599999999999999,
          0.12100000000000002,
          0.12,
          0.11400000000000002,
          0.11699999999999999,
          0.124,
          0.124,
          0.129,
          0.128,
          0.11699999999999999,
          0.11300000000000002,
          0.10900000000000001,
          0.11100000000000002,
          0.11299999999999999,
          0.11300000000000002,
          0.11100000000000002,
          0.118,
          0.10900000000000001,
          0.10700000000000001,
          0.11200000000000002,
          0.11600000000000002,
          0.12,
          0.12000000000000002,
          0.124,
          0.122,
          0.123,
          0.11400000000000002,
          0.119,
          0.125,
          0.128,
          0.12900000000000003,
          0.13,
          0.124,
          0.123,
          0.12300000000000003,
          0.122,
          0.129,
          0.132,
          0.124,
          0.12100000000000002,
          0.123,
          0.125,
          0.129,
          0.126,
          0.13,
          0.131,
          0.131,
          0.127,
          0.13,
          0.12899999999999998,
          0.126,
          0.121,
          0.12,
          0.11800000000000002,
          0.119,
          0.126,
          0.128,
          0.126,
          0.123,
          0.125,
          0.123,
          0.12600000000000003,
          0.137,
          0.138,
          0.128,
          0.11600000000000002,
          0.11299999999999999,
          0.11200000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11400000000000002,
          0.11199999999999999,
          0.10300000000000001,
          0.101,
          0.10900000000000001,
          0.118,
          0.123,
          0.127,
          0.129,
          0.138,
          0.13199999999999998,
          0.127,
          0.129,
          0.133,
          0.131,
          0.13,
          0.131,
          0.139,
          0.139,
          0.133,
          0.129,
          0.133,
          0.129,
          0.126,
          0.127,
          0.126,
          0.121,
          0.11199999999999999,
          0.11199999999999999,
          0.11099999999999999,
          0.11199999999999999,
          0.11300000000000002,
          0.118,
          0.11599999999999999,
          0.10899999999999999,
          0.10600000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10899999999999999,
          0.11499999999999999,
          0.119,
          0.11700000000000002,
          0.11299999999999999,
          0.11700000000000002,
          0.126,
          0.12600000000000003,
          0.131,
          0.13199999999999998,
          0.1343061224489796
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFSSGD<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "line": {
          "color": "yellow",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFSSGD",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.095,
          0.10200000000000001,
          0.10300000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.097,
          0.10200000000000001,
          0.10700000000000001,
          0.10200000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.101,
          0.099,
          0.10300000000000001,
          0.099,
          0.10200000000000001,
          0.095,
          0.094,
          0.1,
          0.096,
          0.101,
          0.10200000000000001,
          0.10300000000000001,
          0.095,
          0.095,
          0.099,
          0.10200000000000001,
          0.10700000000000001,
          0.11099999999999999,
          0.11599999999999999,
          0.11500000000000002,
          0.11699999999999999,
          0.11400000000000002,
          0.12,
          0.119,
          0.11800000000000002,
          0.123,
          0.11800000000000002,
          0.11299999999999999,
          0.10700000000000001,
          0.10200000000000001,
          0.101,
          0.10300000000000001,
          0.099,
          0.1,
          0.1,
          0.096,
          0.094,
          0.098,
          0.10200000000000001,
          0.10600000000000001,
          0.11000000000000001,
          0.11099999999999999,
          0.11500000000000002,
          0.12,
          0.123,
          0.123,
          0.128,
          0.12200000000000003,
          0.118,
          0.125,
          0.119,
          0.11500000000000002,
          0.11000000000000001,
          0.10800000000000001,
          0.11499999999999999,
          0.119,
          0.122,
          0.128,
          0.12500000000000003,
          0.126,
          0.13000000000000003,
          0.13,
          0.131,
          0.13,
          0.11900000000000002,
          0.119,
          0.11300000000000002,
          0.10700000000000001,
          0.11599999999999999,
          0.11100000000000002,
          0.10800000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11200000000000002,
          0.118,
          0.11600000000000002,
          0.11499999999999999,
          0.12,
          0.12,
          0.11699999999999999,
          0.11800000000000002,
          0.11499999999999999,
          0.11400000000000002,
          0.119,
          0.11900000000000002,
          0.122,
          0.125,
          0.123,
          0.12000000000000002,
          0.11599999999999999,
          0.11599999999999999,
          0.11500000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.11399999999999999,
          0.10700000000000001,
          0.10500000000000001,
          0.11000000000000001,
          0.11500000000000002,
          0.13,
          0.14,
          0.14400000000000002,
          0.142,
          0.138,
          0.13999999999999999,
          0.139,
          0.136,
          0.134,
          0.131,
          0.126,
          0.11700000000000002,
          0.11299999999999999,
          0.11000000000000001,
          0.10900000000000001,
          0.10300000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.10900000000000001,
          0.10900000000000001,
          0.10600000000000001,
          0.11400000000000002,
          0.10999999999999999,
          0.11400000000000002,
          0.11400000000000002,
          0.11499999999999999,
          0.11200000000000002,
          0.11199999999999999,
          0.10700000000000001,
          0.10899999999999999,
          0.11000000000000001,
          0.099,
          0.10300000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.11000000000000001,
          0.11299999999999999,
          0.10900000000000001,
          0.11399999999999999,
          0.11199999999999999,
          0.122,
          0.126,
          0.134,
          0.13799999999999998,
          0.138,
          0.129,
          0.129,
          0.125,
          0.11700000000000002,
          0.12,
          0.11600000000000002,
          0.126,
          0.124,
          0.11800000000000002,
          0.11700000000000002,
          0.127,
          0.129,
          0.133,
          0.137,
          0.14100000000000001,
          0.139,
          0.13,
          0.13000000000000003,
          0.134,
          0.143,
          0.138,
          0.14,
          0.14400000000000002,
          0.153,
          0.14300000000000002,
          0.141,
          0.14200000000000002,
          0.13399999999999998,
          0.133,
          0.129,
          0.132,
          0.131,
          0.13199999999999998,
          0.132,
          0.13699999999999998,
          0.14500000000000002,
          0.143,
          0.14700000000000002,
          0.15,
          0.14300000000000002,
          0.142,
          0.14500000000000002,
          0.14900000000000002,
          0.142,
          0.14700000000000002,
          0.145,
          0.148,
          0.154,
          0.155,
          0.16599999999999998,
          0.16899999999999998,
          0.17099999999999999,
          0.15999999999999998,
          0.17099999999999999,
          0.175,
          0.175,
          0.173,
          0.164,
          0.156,
          0.154,
          0.15,
          0.13999999999999999,
          0.138,
          0.13399999999999998,
          0.13199999999999998,
          0.12,
          0.12600000000000003,
          0.124,
          0.135,
          0.133,
          0.13499999999999998,
          0.136,
          0.14100000000000001,
          0.139,
          0.13399999999999998,
          0.14500000000000002,
          0.142,
          0.14800000000000002,
          0.14400000000000002,
          0.147,
          0.156,
          0.16,
          0.159,
          0.156,
          0.162,
          0.15899999999999997,
          0.156,
          0.15799999999999997,
          0.16099999999999998,
          0.152,
          0.14500000000000002,
          0.149,
          0.149,
          0.156,
          0.156,
          0.159,
          0.16299999999999998,
          0.167,
          0.15999999999999998,
          0.168,
          0.16999999999999998,
          0.16799999999999998,
          0.163,
          0.15999999999999998,
          0.158,
          0.159,
          0.16,
          0.153,
          0.161,
          0.15999999999999998,
          0.157,
          0.157,
          0.162,
          0.163,
          0.15699999999999997,
          0.155,
          0.155,
          0.15699999999999997,
          0.156,
          0.155,
          0.154,
          0.153,
          0.15300000000000002,
          0.151,
          0.15,
          0.148,
          0.15,
          0.14700000000000002,
          0.144,
          0.149,
          0.15599999999999997,
          0.162,
          0.16799999999999998,
          0.16599999999999998,
          0.168,
          0.16599999999999998,
          0.162,
          0.16599999999999998,
          0.166,
          0.158,
          0.155,
          0.15000000000000002,
          0.148,
          0.155,
          0.154,
          0.154,
          0.154,
          0.154,
          0.15899999999999997,
          0.157,
          0.152,
          0.15,
          0.145,
          0.144,
          0.153,
          0.157,
          0.153,
          0.15,
          0.14,
          0.141,
          0.14200000000000002,
          0.13899999999999998,
          0.14500000000000002,
          0.13,
          0.125,
          0.128,
          0.13399999999999998,
          0.14100000000000001,
          0.148,
          0.154,
          0.15,
          0.154,
          0.147,
          0.163,
          0.161,
          0.153,
          0.14900000000000002,
          0.13999999999999999,
          0.138,
          0.14,
          0.142,
          0.14100000000000001,
          0.152,
          0.145,
          0.144,
          0.144,
          0.141,
          0.14300000000000002,
          0.147,
          0.146,
          0.155,
          0.15699999999999997,
          0.144,
          0.14300000000000002,
          0.151,
          0.156,
          0.161,
          0.16899999999999998,
          0.16499999999999998,
          0.161,
          0.166,
          0.162,
          0.165,
          0.174,
          0.174,
          0.176,
          0.182,
          0.175,
          0.172,
          0.182,
          0.17,
          0.18,
          0.186,
          0.177,
          0.17099999999999999,
          0.174,
          0.167,
          0.17099999999999999,
          0.176,
          0.17200000000000001,
          0.175,
          0.16999999999999998,
          0.17,
          0.16799999999999998,
          0.169,
          0.171,
          0.172,
          0.171,
          0.165,
          0.155,
          0.157,
          0.152,
          0.148,
          0.161,
          0.16599999999999998,
          0.16399999999999998,
          0.17099999999999999,
          0.176,
          0.183,
          0.192,
          0.19,
          0.2,
          0.20600000000000002,
          0.198,
          0.191,
          0.195,
          0.183,
          0.173,
          0.17099999999999999,
          0.16899999999999998,
          0.167,
          0.15799999999999997,
          0.155,
          0.151,
          0.153,
          0.148,
          0.152,
          0.154,
          0.15,
          0.14500000000000002,
          0.145,
          0.15100000000000002,
          0.146,
          0.15300000000000002,
          0.144,
          0.136,
          0.13099999999999998,
          0.134,
          0.141,
          0.148,
          0.15100000000000002,
          0.156,
          0.165,
          0.16,
          0.17,
          0.16999999999999998,
          0.175,
          0.176,
          0.1723265306122449
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=random<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "random",
         "line": {
          "color": "cyan",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "random",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.1,
          0.101,
          0.101,
          0.10500000000000001,
          0.10700000000000001,
          0.10899999999999999,
          0.11299999999999999,
          0.10999999999999999,
          0.11000000000000001,
          0.10900000000000001,
          0.11200000000000002,
          0.11399999999999999,
          0.10900000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.10500000000000001,
          0.098,
          0.10200000000000001,
          0.10600000000000001,
          0.101,
          0.097,
          0.101,
          0.10900000000000001,
          0.11099999999999999,
          0.11199999999999999,
          0.10799999999999998,
          0.11199999999999999,
          0.11499999999999999,
          0.10900000000000001,
          0.10499999999999998,
          0.099,
          0.095,
          0.092,
          0.086,
          0.083,
          0.08399999999999999,
          0.08499999999999999,
          0.08299999999999999,
          0.086,
          0.09,
          0.092,
          0.09,
          0.09,
          0.09,
          0.089,
          0.092,
          0.092,
          0.091,
          0.088,
          0.09,
          0.089,
          0.095,
          0.096,
          0.1,
          0.10300000000000001,
          0.10400000000000001,
          0.10799999999999998,
          0.10800000000000001,
          0.10900000000000001,
          0.11499999999999999,
          0.12,
          0.119,
          0.119,
          0.119,
          0.118,
          0.122,
          0.12000000000000002,
          0.121,
          0.11699999999999999,
          0.11200000000000002,
          0.10899999999999999,
          0.10500000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.1,
          0.08900000000000001,
          0.09,
          0.094,
          0.098,
          0.1,
          0.10400000000000001,
          0.10600000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.101,
          0.11000000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.1,
          0.096,
          0.095,
          0.099,
          0.098,
          0.098,
          0.10500000000000001,
          0.10200000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11400000000000002,
          0.10999999999999999,
          0.11400000000000002,
          0.12,
          0.11699999999999999,
          0.11699999999999999,
          0.11400000000000002,
          0.11599999999999999,
          0.11699999999999999,
          0.122,
          0.123,
          0.123,
          0.126,
          0.123,
          0.125,
          0.12200000000000003,
          0.123,
          0.11800000000000002,
          0.11099999999999999,
          0.10400000000000001,
          0.11099999999999999,
          0.11199999999999999,
          0.11200000000000002,
          0.10700000000000001,
          0.11000000000000001,
          0.11299999999999999,
          0.10600000000000001,
          0.10600000000000001,
          0.11400000000000002,
          0.119,
          0.11600000000000002,
          0.10999999999999999,
          0.099,
          0.10500000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.11200000000000002,
          0.10600000000000001,
          0.11000000000000001,
          0.10600000000000001,
          0.10800000000000001,
          0.11499999999999999,
          0.119,
          0.119,
          0.11500000000000002,
          0.11499999999999999,
          0.11900000000000002,
          0.122,
          0.11600000000000002,
          0.11599999999999999,
          0.118,
          0.11400000000000002,
          0.10800000000000001,
          0.10600000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.1,
          0.10600000000000001,
          0.11000000000000001,
          0.10800000000000001,
          0.11400000000000002,
          0.11699999999999999,
          0.11300000000000002,
          0.10900000000000001,
          0.11599999999999999,
          0.11400000000000002,
          0.10999999999999999,
          0.10400000000000001,
          0.096,
          0.098,
          0.094,
          0.098,
          0.101,
          0.10300000000000001,
          0.099,
          0.10699999999999998,
          0.10700000000000001,
          0.11499999999999999,
          0.118,
          0.11400000000000002,
          0.11399999999999999,
          0.10700000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.1,
          0.101,
          0.08499999999999999,
          0.08399999999999999,
          0.083,
          0.08299999999999999,
          0.086,
          0.087,
          0.094,
          0.095,
          0.1,
          0.10300000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10200000000000001,
          0.098,
          0.093,
          0.093,
          0.082,
          0.079,
          0.079,
          0.077,
          0.086,
          0.087,
          0.099,
          0.10500000000000001,
          0.10600000000000001,
          0.10700000000000001,
          0.11599999999999999,
          0.12100000000000002,
          0.119,
          0.11499999999999999,
          0.11000000000000001,
          0.11399999999999999,
          0.10800000000000001,
          0.1,
          0.10200000000000001,
          0.10600000000000001,
          0.101,
          0.095,
          0.096,
          0.1,
          0.10800000000000001,
          0.10100000000000002,
          0.101,
          0.11300000000000002,
          0.11400000000000002,
          0.10900000000000001,
          0.11000000000000001,
          0.11599999999999999,
          0.11400000000000002,
          0.11200000000000002,
          0.10500000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10800000000000001,
          0.11200000000000002,
          0.10600000000000001,
          0.10500000000000001,
          0.098,
          0.10500000000000001,
          0.11100000000000002,
          0.11599999999999999,
          0.12100000000000002,
          0.118,
          0.10900000000000001,
          0.10500000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11900000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.11599999999999999,
          0.10900000000000001,
          0.11099999999999999,
          0.11100000000000002,
          0.11100000000000002,
          0.10900000000000001,
          0.10900000000000001,
          0.10799999999999998,
          0.11100000000000002,
          0.10700000000000001,
          0.101,
          0.10400000000000001,
          0.101,
          0.10600000000000001,
          0.10900000000000001,
          0.11100000000000002,
          0.11000000000000001,
          0.11200000000000002,
          0.10500000000000001,
          0.101,
          0.1,
          0.098,
          0.098,
          0.09,
          0.088,
          0.087,
          0.086,
          0.082,
          0.08399999999999999,
          0.087,
          0.088,
          0.09,
          0.091,
          0.099,
          0.1,
          0.094,
          0.09,
          0.093,
          0.095,
          0.097,
          0.095,
          0.097,
          0.098,
          0.095,
          0.098,
          0.10400000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.11300000000000002,
          0.11299999999999999,
          0.11800000000000002,
          0.121,
          0.11399999999999999,
          0.11500000000000002,
          0.11399999999999999,
          0.11700000000000002,
          0.11199999999999999,
          0.11000000000000001,
          0.11599999999999999,
          0.11800000000000002,
          0.11499999999999999,
          0.11300000000000002,
          0.11699999999999999,
          0.124,
          0.123,
          0.121,
          0.12,
          0.11699999999999999,
          0.11699999999999999,
          0.11099999999999999,
          0.11200000000000002,
          0.11399999999999999,
          0.11500000000000002,
          0.10500000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10800000000000001,
          0.10999999999999999,
          0.10400000000000001,
          0.101,
          0.10500000000000001,
          0.098,
          0.098,
          0.10300000000000001,
          0.10300000000000001,
          0.101,
          0.1,
          0.10800000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.1,
          0.096,
          0.087,
          0.08800000000000001,
          0.087,
          0.086,
          0.089,
          0.08700000000000001,
          0.09,
          0.092,
          0.094,
          0.096,
          0.098,
          0.10300000000000001,
          0.10200000000000001,
          0.1,
          0.10200000000000001,
          0.096,
          0.093,
          0.095,
          0.099,
          0.101,
          0.10899999999999999,
          0.11400000000000002,
          0.11299999999999999,
          0.118,
          0.11800000000000002,
          0.122,
          0.125,
          0.12,
          0.123,
          0.11699999999999999,
          0.10600000000000001,
          0.10700000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.10200000000000001,
          0.10300000000000001,
          0.09999999999999999,
          0.1,
          0.099,
          0.097,
          0.101,
          0.095,
          0.094,
          0.1,
          0.1,
          0.10200000000000001,
          0.10800000000000001,
          0.10600000000000001,
          0.10600000000000001,
          0.11699999999999999,
          0.11299999999999999,
          0.10600000000000001,
          0.10800000000000001,
          0.101,
          0.10200000000000001,
          0.101,
          0.101,
          0.10300000000000001,
          0.098,
          0.093,
          0.093,
          0.097,
          0.101,
          0.11099999999999999,
          0.11000000000000001,
          0.11099999999999999,
          0.10400000000000001,
          0.10900000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.11000000000000001,
          0.10899999999999999,
          0.10500000000000001,
          0.10200000000000001,
          0.1,
          0.101,
          0.10400000000000001,
          0.101,
          0.098,
          0.099,
          0.101,
          0.099,
          0.099,
          0.095,
          0.09518367346938776
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=FSDS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "line": {
          "color": "green",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FSDS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.097,
          0.093,
          0.096,
          0.1,
          0.095,
          0.093,
          0.095,
          0.091,
          0.091,
          0.08900000000000001,
          0.088,
          0.09,
          0.09,
          0.083,
          0.094,
          0.093,
          0.097,
          0.10200000000000001,
          0.099,
          0.098,
          0.097,
          0.10300000000000001,
          0.101,
          0.10400000000000001,
          0.092,
          0.096,
          0.098,
          0.10200000000000001,
          0.10699999999999998,
          0.10700000000000001,
          0.10300000000000001,
          0.097,
          0.099,
          0.099,
          0.098,
          0.093,
          0.087,
          0.08499999999999999,
          0.082,
          0.08299999999999999,
          0.085,
          0.08299999999999999,
          0.08099999999999999,
          0.086,
          0.08900000000000001,
          0.091,
          0.093,
          0.089,
          0.096,
          0.099,
          0.10499999999999998,
          0.11200000000000002,
          0.11199999999999999,
          0.10500000000000001,
          0.10899999999999999,
          0.11699999999999999,
          0.12300000000000003,
          0.125,
          0.12,
          0.122,
          0.121,
          0.119,
          0.122,
          0.123,
          0.11499999999999999,
          0.10800000000000001,
          0.1,
          0.1,
          0.1,
          0.098,
          0.095,
          0.094,
          0.096,
          0.10300000000000001,
          0.10800000000000001,
          0.10600000000000001,
          0.11500000000000002,
          0.118,
          0.11600000000000002,
          0.11200000000000002,
          0.11700000000000002,
          0.119,
          0.118,
          0.11200000000000002,
          0.10699999999999998,
          0.10800000000000001,
          0.10200000000000001,
          0.10600000000000001,
          0.10200000000000001,
          0.10600000000000001,
          0.098,
          0.099,
          0.097,
          0.1,
          0.099,
          0.10800000000000001,
          0.10300000000000001,
          0.093,
          0.095,
          0.096,
          0.095,
          0.093,
          0.093,
          0.094,
          0.098,
          0.094,
          0.098,
          0.10200000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.11099999999999999,
          0.11100000000000002,
          0.11499999999999999,
          0.11499999999999999,
          0.11199999999999999,
          0.11300000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11299999999999999,
          0.11100000000000002,
          0.11000000000000001,
          0.10400000000000001,
          0.10200000000000001,
          0.101,
          0.11199999999999999,
          0.10300000000000001,
          0.098,
          0.094,
          0.09,
          0.089,
          0.093,
          0.093,
          0.087,
          0.084,
          0.079,
          0.084,
          0.089,
          0.093,
          0.099,
          0.10500000000000001,
          0.10200000000000001,
          0.10200000000000001,
          0.11000000000000001,
          0.11099999999999999,
          0.11099999999999999,
          0.11499999999999999,
          0.11800000000000002,
          0.11499999999999999,
          0.11699999999999999,
          0.11400000000000002,
          0.11599999999999999,
          0.127,
          0.125,
          0.12100000000000002,
          0.121,
          0.11500000000000002,
          0.10999999999999999,
          0.11400000000000002,
          0.10900000000000001,
          0.11100000000000002,
          0.10500000000000001,
          0.097,
          0.094,
          0.097,
          0.09,
          0.094,
          0.094,
          0.095,
          0.092,
          0.08800000000000001,
          0.097,
          0.095,
          0.095,
          0.098,
          0.10400000000000001,
          0.096,
          0.097,
          0.097,
          0.101,
          0.1,
          0.097,
          0.1,
          0.101,
          0.10200000000000001,
          0.097,
          0.10500000000000001,
          0.101,
          0.101,
          0.11000000000000001,
          0.11099999999999999,
          0.11500000000000002,
          0.11600000000000002,
          0.11400000000000002,
          0.11600000000000002,
          0.119,
          0.12000000000000002,
          0.129,
          0.13399999999999998,
          0.125,
          0.127,
          0.122,
          0.12400000000000003,
          0.126,
          0.123,
          0.127,
          0.123,
          0.11599999999999999,
          0.11100000000000002,
          0.11599999999999999,
          0.11200000000000002,
          0.11499999999999999,
          0.11299999999999999,
          0.11399999999999999,
          0.11399999999999999,
          0.11299999999999999,
          0.11299999999999999,
          0.11300000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11699999999999999,
          0.11000000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.10500000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.10500000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.10900000000000001,
          0.10400000000000001,
          0.099,
          0.10400000000000001,
          0.10200000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.099,
          0.10400000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.11700000000000002,
          0.11300000000000002,
          0.10900000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.11099999999999999,
          0.11400000000000002,
          0.10800000000000001,
          0.11099999999999999,
          0.11600000000000002,
          0.10400000000000001,
          0.11000000000000001,
          0.10700000000000001,
          0.11099999999999999,
          0.10800000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.099,
          0.10200000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.11199999999999999,
          0.11099999999999999,
          0.10999999999999999,
          0.11299999999999999,
          0.11499999999999999,
          0.11599999999999999,
          0.11800000000000002,
          0.10999999999999999,
          0.10899999999999999,
          0.10600000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10200000000000001,
          0.10200000000000001,
          0.10300000000000001,
          0.098,
          0.101,
          0.096,
          0.099,
          0.096,
          0.094,
          0.087,
          0.08700000000000001,
          0.086,
          0.093,
          0.097,
          0.095,
          0.10200000000000001,
          0.096,
          0.099,
          0.10300000000000001,
          0.10600000000000001,
          0.10499999999999998,
          0.11099999999999999,
          0.101,
          0.10600000000000001,
          0.10500000000000001,
          0.101,
          0.10500000000000001,
          0.10699999999999998,
          0.10700000000000001,
          0.10500000000000001,
          0.11000000000000001,
          0.10600000000000001,
          0.11000000000000001,
          0.11000000000000001,
          0.11699999999999999,
          0.11800000000000002,
          0.123,
          0.12600000000000003,
          0.127,
          0.127,
          0.121,
          0.122,
          0.121,
          0.122,
          0.11600000000000002,
          0.11699999999999999,
          0.10500000000000001,
          0.099,
          0.093,
          0.094,
          0.096,
          0.094,
          0.095,
          0.08800000000000001,
          0.092,
          0.087,
          0.095,
          0.097,
          0.094,
          0.097,
          0.1,
          0.10500000000000001,
          0.10400000000000001,
          0.10600000000000001,
          0.10200000000000001,
          0.10900000000000001,
          0.11000000000000001,
          0.11400000000000002,
          0.121,
          0.12100000000000002,
          0.12,
          0.11500000000000002,
          0.11300000000000002,
          0.10799999999999998,
          0.11099999999999999,
          0.10800000000000001,
          0.10499999999999998,
          0.10300000000000001,
          0.10300000000000001,
          0.10200000000000001,
          0.095,
          0.094,
          0.1,
          0.10900000000000001,
          0.11200000000000002,
          0.11100000000000002,
          0.10500000000000001,
          0.1,
          0.095,
          0.091,
          0.095,
          0.10200000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.10200000000000001,
          0.10400000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.10899999999999999,
          0.11400000000000002,
          0.11400000000000002,
          0.11200000000000002,
          0.10400000000000001,
          0.1,
          0.098,
          0.097,
          0.1,
          0.10400000000000001,
          0.10500000000000001,
          0.101,
          0.10400000000000001,
          0.098,
          0.096,
          0.10400000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.101,
          0.10200000000000001,
          0.10200000000000001,
          0.11000000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.11200000000000002,
          0.11099999999999999,
          0.11000000000000001,
          0.11099999999999999,
          0.12100000000000002,
          0.123,
          0.12,
          0.11000000000000001,
          0.11299999999999999,
          0.10999999999999999,
          0.11100000000000002,
          0.11199999999999999,
          0.11300000000000002,
          0.10900000000000001,
          0.10500000000000001,
          0.098,
          0.098,
          0.10200000000000001,
          0.096,
          0.10699999999999998,
          0.10800000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.11300000000000002,
          0.11100000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.118,
          0.11699999999999999,
          0.11699999999999999,
          0.11699999999999999,
          0.11700000000000002,
          0.11599999999999999,
          0.11700000000000002,
          0.11099999999999999,
          0.10900000000000001,
          0.11100000000000002,
          0.1143061224489796
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Moving averages over accuracy while learning with window 10 on dataset syn_ds_4"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "batches"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "accuracy"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#moving averages\n",
    "title = \"Moving averages over accuracy while learning with window {} on dataset {}\".format(n_window, dataset_name)\n",
    "col_names = [\"Pure\",\"FIRES\", \"OFS\", \"OFSSGD\", \"random\",\"FSDS\"]# \n",
    "d = {\"Pure\":pure_moving_average, \"FIRES\":fires_moving_average, \"OFS\":ofs_moving_average, \n",
    "\"OFSSGD\":ofssgd_moving_average,  \"random\":random_moving_average,\"FSDS\":fsds_moving_average}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y=col_names, title=title, labels={\"index\":\"batches\", \"value\":\"accuracy\"}, color_discrete_map={\"Pure\":\"blue\",'FIRES': 'red', \n",
    "                                                    'OFS': 'purple','FSDS': 'green', \"OFSSGD\":\"yellow\", \"random\":\"cyan\"})\n",
    "fig.write_image(\"{}/accuracy.{}\".format(folder, export_type))\n",
    "accuracy_trace = fig['data']\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean values\n",
    "csv_name = \"{}/accuracy_avg.csv\".format(folder)\n",
    "df.mean().to_csv(csv_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Pure<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "Pure",
         "line": {
          "color": "blue",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Pure",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.044299991828063615,
          0.043379258175751015,
          0.043832303377135076,
          0.04248267745137675,
          0.043166686424859414,
          0.04448809183936828,
          0.0516967784442813,
          0.061069796388817134,
          0.06364421320007604,
          0.058778724698572496,
          0.050480702099702436,
          0.04891563032936751,
          0.04575255398771975,
          0.047600079632806366,
          0.048451049194302244,
          0.04960178572176454,
          0.044993853833832656,
          0.04188783240753027,
          0.04814314673469815,
          0.052716994383365856,
          0.062316957792152794,
          0.06320680034142019,
          0.061885894718188984,
          0.062292727924597745,
          0.06286719279174555,
          0.05850198983275745,
          0.06234777599627948,
          0.0626608447644566,
          0.05691942884342112,
          0.054887736495212766,
          0.05071319681523939,
          0.05334631082577066,
          0.05603257592612605,
          0.058074655436847554,
          0.060917261249928335,
          0.06345371297060994,
          0.06176652329831598,
          0.056727964334060424,
          0.05742897804956241,
          0.055146812529378975,
          0.05573720076637738,
          0.05332662573511269,
          0.05719035598063675,
          0.05395791408514974,
          0.055039937862167786,
          0.05548559171827938,
          0.05504341137795023,
          0.05847171868102032,
          0.06157840492839269,
          0.06492629794524855,
          0.06790802556009555,
          0.07386558820254782,
          0.07091099274767455,
          0.07125063297951077,
          0.06694744070077503,
          0.06837305713360094,
          0.06675974991783054,
          0.06520474578218124,
          0.060653905575404454,
          0.0635704088433783,
          0.06366823074827467,
          0.0595234859393299,
          0.06253291030427524,
          0.060206605651291836,
          0.06085784281992031,
          0.05980273616187247,
          0.06183426137308541,
          0.06288355882485964,
          0.06214345029655351,
          0.061100916359901926,
          0.05377070638949812,
          0.06049159911244003,
          0.05806983080502792,
          0.06266350617801364,
          0.06308459658186265,
          0.06311012383238991,
          0.06033285232341109,
          0.06076658071675948,
          0.058758235583052154,
          0.05998608151337487,
          0.06953933614052112,
          0.06585635550549129,
          0.06605837579116722,
          0.06131408149687293,
          0.06184817098565344,
          0.062234495219346084,
          0.07033141829626917,
          0.07603011079257914,
          0.08243434065421726,
          0.08547678157380133,
          0.07963288523542514,
          0.08016093119217291,
          0.07823355399587265,
          0.08461929712781377,
          0.08920809286739517,
          0.08874330699871914,
          0.09479716467761115,
          0.0967518515975838,
          0.09829168327590783,
          0.09620850337264679,
          0.09794376409408884,
          0.09529980046368344,
          0.09722982716624434,
          0.0927182558769533,
          0.09111603125235546,
          0.0952068838779907,
          0.08958465995433777,
          0.08332050205341515,
          0.08997232735635048,
          0.09954330377293527,
          0.09577773614612238,
          0.0975981419242681,
          0.09583135293058385,
          0.09276535914176398,
          0.09202479630767953,
          0.0908917412883849,
          0.08359334318638148,
          0.08529391876219646,
          0.0783511383996522,
          0.06460095675357927,
          0.06581192626882164,
          0.06355639316122667,
          0.0650661970827953,
          0.06571763441358046,
          0.06100742368366089,
          0.059606927628071814,
          0.0686554588921294,
          0.0727556251235268,
          0.07202385972907097,
          0.07607572403608616,
          0.07641557571615434,
          0.07732791811751513,
          0.0722354867637027,
          0.07745267093611943,
          0.08052935790357105,
          0.08159272867969262,
          0.0750052474766851,
          0.06627651694890088,
          0.06294629682973187,
          0.06883257232442666,
          0.06729696933898029,
          0.07078073569067733,
          0.07533283774203707,
          0.07451051481436638,
          0.08227672057105614,
          0.08213886860287993,
          0.08574769354986278,
          0.09281107533740662,
          0.09359687206387639,
          0.08613219806637631,
          0.09684708965755642,
          0.09475195516753473,
          0.10396633371404666,
          0.10364384089035325,
          0.0976873803157278,
          0.09848172289071554,
          0.0957327584535932,
          0.08832418562520614,
          0.08810155394653998,
          0.09173806854305458,
          0.08539032279502648,
          0.08734219436584542,
          0.07626805537012323,
          0.0733285503195595,
          0.07600733308480083,
          0.07241368229115004,
          0.06988371189117965,
          0.07065408689769923,
          0.07233240287996258,
          0.06302990537746508,
          0.05969249831749703,
          0.058821542657837914,
          0.06188442400309304,
          0.06573530482958362,
          0.05994229665545416,
          0.059785725876672434,
          0.06512805798900455,
          0.07304593275711918,
          0.08007551563427348,
          0.09757939952815739,
          0.10167608619740502,
          0.0987304869895031,
          0.09829688688702606,
          0.09754107440439404,
          0.09849650493877195,
          0.09874268882980829,
          0.09355813449525396,
          0.08945881408393934,
          0.08604984195167421,
          0.07603114271440356,
          0.08220959753230472,
          0.08491471699316722,
          0.08567846476541803,
          0.09268313611580437,
          0.09834395358696665,
          0.10946425042375241,
          0.1195289184475223,
          0.12314917578507019,
          0.12089909646654769,
          0.11992929642531906,
          0.11159513800676543,
          0.11025026597820922,
          0.1139538166415122,
          0.10406159819216301,
          0.11070716600238599,
          0.1009712339273235,
          0.09447580753105296,
          0.09147314981476504,
          0.09129369139758955,
          0.09462355211658072,
          0.09987971451769197,
          0.10505818436655656,
          0.10636287995946747,
          0.11005117201684926,
          0.10402712398871458,
          0.11137627021286081,
          0.11635442563275852,
          0.11742767128530648,
          0.1140783187388884,
          0.11589388113751757,
          0.10924461334986235,
          0.10197721021206449,
          0.09645818028199313,
          0.09690239199535042,
          0.08892957855162362,
          0.08688008550081479,
          0.07811123419707976,
          0.07710302830128837,
          0.07488317208143215,
          0.0682180908441537,
          0.07060433455438991,
          0.07280113502502057,
          0.07153552084322992,
          0.0767185212277783,
          0.08515810869913047,
          0.09153155764717108,
          0.10004125347690622,
          0.10812087991719999,
          0.11826202020052409,
          0.11900440559290948,
          0.11701290769976173,
          0.11579392940695328,
          0.11106384925040251,
          0.1012340831639275,
          0.09540822118277141,
          0.08703083815711252,
          0.08066524353210627,
          0.07206960042251775,
          0.06641691921588802,
          0.07315859632633502,
          0.0747165186520463,
          0.07649004036842517,
          0.08889996881207454,
          0.09579779172618372,
          0.09958985076419778,
          0.0974056457799928,
          0.1053648528216506,
          0.11215597123598553,
          0.12073895090596647,
          0.11664644725632975,
          0.12050353641167473,
          0.12736512119382945,
          0.11976304413150698,
          0.11822321534231757,
          0.120301846398523,
          0.12046303090438834,
          0.1109356693054174,
          0.1030139939219773,
          0.0941218912511898,
          0.0923355976307392,
          0.09033904182998259,
          0.080193587346101,
          0.07909583171697512,
          0.0798088385553551,
          0.07379126835883754,
          0.07231666932114333,
          0.07170141986742172,
          0.06997634501966885,
          0.07122971068401444,
          0.07582799122798586,
          0.07814211113130659,
          0.0817606272642964,
          0.07979157093861869,
          0.07711968039135501,
          0.07567886318867413,
          0.07651361587160231,
          0.07503999015809124,
          0.07486696065921035,
          0.07473833098576088,
          0.06791460014790937,
          0.06348635228466151,
          0.06916481232364788,
          0.07625016178601346,
          0.07661388139973306,
          0.07722398749522853,
          0.07540636277687489,
          0.08180622112847358,
          0.081046248511503,
          0.08686950798056987,
          0.09422181614735739,
          0.09954866466043247,
          0.1011096555214233,
          0.10689938301043571,
          0.11730799062241862,
          0.12078397033882,
          0.13172888248260686,
          0.1301696134410292,
          0.1362252061242081,
          0.1363175906433675,
          0.13299102521939205,
          0.14214139892853916,
          0.14041000089018463,
          0.13559416004885455,
          0.1286524608609995,
          0.12807316985609607,
          0.11724657176118854,
          0.1148649422376137,
          0.11283558879535704,
          0.10273050151568994,
          0.09859463613002092,
          0.08438689660047419,
          0.08491355423217466,
          0.08119970323132965,
          0.07984372897107717,
          0.07856855008914228,
          0.07903292445709047,
          0.08640595704440879,
          0.08593893824292478,
          0.09290821492795777,
          0.09533333077888549,
          0.09858184570950176,
          0.09157197057296887,
          0.09195267605952143,
          0.0924651040084429,
          0.09609776602061618,
          0.09408735533516974,
          0.08846885199584884,
          0.09099611834548361,
          0.08348044308406134,
          0.0871965541766162,
          0.09217097509969037,
          0.09160437378169543,
          0.08531098113315402,
          0.07957389940663762,
          0.07228422221500624,
          0.07105598743695363,
          0.06924750873826604,
          0.06269529550206404,
          0.07012947993204947,
          0.06995856435611925,
          0.0675138963172496,
          0.07933619585306684,
          0.08754754684912305,
          0.09490968120599425,
          0.11368941070847624,
          0.12240351888107519,
          0.13032444421302697,
          0.1313303836326063,
          0.12144301437375474,
          0.11797310173028534,
          0.11362265719164677,
          0.10750701446095734,
          0.11018581498005262,
          0.11020190998875257,
          0.10120325712871507,
          0.09980838674573185,
          0.09719547188281699,
          0.1076557028207497,
          0.11383342251605869,
          0.11678009512449601,
          0.1160092906571398,
          0.11661374852211985,
          0.11902578555915691,
          0.11745879676859623,
          0.11021677838986002,
          0.11052616879992139,
          0.11538635861011119,
          0.1098428377840086,
          0.11406747061985831,
          0.11998323753268406,
          0.12464139989672876,
          0.12299687749670765,
          0.1158787087087246,
          0.11216210682835284,
          0.11254309699568077,
          0.1098386117822346,
          0.10999578060499568,
          0.1059080774533129,
          0.10263472258818684,
          0.09120297194326485,
          0.08595543660729138,
          0.08681017663850199,
          0.09111981933928247,
          0.09028758490704804,
          0.09793042594400672,
          0.10708278054200826,
          0.10270444031261879,
          0.10764230087989028,
          0.11284206102887558,
          0.11791790217222245,
          0.13184792301416076,
          0.13321164558433496,
          0.1316218283281942,
          0.14342468128918667,
          0.1424341453465145,
          0.14295196451564945,
          0.1463318513809933,
          0.14916123658017605,
          0.1500241774602891,
          0.1445050415019389,
          0.13527399726531555,
          0.1253312429988683,
          0.12234944585689873,
          0.11803677336584281,
          0.11319385280183333,
          0.10268216548330392,
          0.10880162922742517,
          0.10680376731809268,
          0.10342998442967084,
          0.10996786491515939,
          0.10788338451821715,
          0.11815920553627952,
          0.12607555942543025,
          0.12474337513176677,
          0.12673515082234307,
          0.12125527433346202,
          0.109321017874548,
          0.10600778698778772,
          0.10434379214414191,
          0.10560101903942806,
          0.10582383092829335,
          0.10360245079521246,
          0.10685298186694266,
          0.1131623430856074,
          0.11494585357824834,
          0.13147608602695904,
          0.13734380552967856,
          0.14719249962518116,
          0.15301523186080784,
          0.15622329937355012
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=FIRES<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "line": {
          "color": "red",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FIRES",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.029966071580705446,
          0.03014993614137886,
          0.03396164895686526,
          0.03395418484203272,
          0.033180795602087046,
          0.03635611405429338,
          0.03627356688448206,
          0.035741406571676584,
          0.035671783170556075,
          0.03774744410305613,
          0.04063489254212679,
          0.045284232123826096,
          0.039483947879768264,
          0.03975295045613926,
          0.04092721563054087,
          0.03851121837243835,
          0.04361993484753414,
          0.04716941943648742,
          0.04851309027354702,
          0.045600239420992596,
          0.04924359266968565,
          0.047890062514056524,
          0.04855420997949432,
          0.05203119965648399,
          0.05634609450722485,
          0.0566179228967003,
          0.051179660967059074,
          0.05223430638788096,
          0.05042332096367643,
          0.05203174905732193,
          0.047664426905789245,
          0.04757730226572343,
          0.04939657158968182,
          0.0464393346237492,
          0.041408140433101204,
          0.042745818716290324,
          0.046886477746700905,
          0.04759632623154939,
          0.052211463207249745,
          0.050271336533169585,
          0.04730965005891944,
          0.04529839464766403,
          0.04522538217093632,
          0.044054697058946865,
          0.04621968384892079,
          0.04561307023585031,
          0.04917762008324923,
          0.04496152350377236,
          0.042380316366349674,
          0.04411698170644218,
          0.04865226678821683,
          0.05217434471029475,
          0.05055565370150454,
          0.048423776678850824,
          0.04590033419910149,
          0.04198143523554969,
          0.04096593162963724,
          0.04222127784836375,
          0.04310599269873076,
          0.04001083055093704,
          0.038745525564789926,
          0.03498270943355274,
          0.039312471891150245,
          0.04240964779931562,
          0.0426720286367025,
          0.04571293530912533,
          0.0423198289929539,
          0.042878381551506466,
          0.04036790972975024,
          0.04113496625996467,
          0.03730230869843386,
          0.03936401434595187,
          0.03625999578680396,
          0.03498319455387447,
          0.03450300540504421,
          0.03414831699502673,
          0.032409204670317146,
          0.02972542116410374,
          0.033798100778067754,
          0.034178193370660345,
          0.0416634002784479,
          0.038858260458163964,
          0.03866866039869325,
          0.038564702715945184,
          0.04071465462653398,
          0.04284350616715023,
          0.04860500943512408,
          0.04906498601540291,
          0.04853657069670626,
          0.04806977011049239,
          0.04192687418437509,
          0.04125106126857914,
          0.039606061268579136,
          0.04123658724055518,
          0.039543925533497185,
          0.034638379315009786,
          0.030244546710807056,
          0.030878943047331055,
          0.031807151308540026,
          0.03627370227877848,
          0.034476697298296576,
          0.03925564838632498,
          0.04225736881643251,
          0.041079742488148954,
          0.04098157459457101,
          0.046292436427676345,
          0.046783945799555846,
          0.046619998635608687,
          0.04537296556663062,
          0.04513186902875989,
          0.051056247080375795,
          0.051707336468253796,
          0.05051782383035407,
          0.05071348713541428,
          0.054204872535876955,
          0.05192904578102311,
          0.05239727282760835,
          0.05565920093218352,
          0.05111976322035853,
          0.051237207590832,
          0.04679737905522503,
          0.044758317208033103,
          0.048398789211631335,
          0.05143874294653598,
          0.05403196041850107,
          0.05399496825890959,
          0.05363040947388733,
          0.052789252656062845,
          0.05648428661192022,
          0.05322891350351801,
          0.060513055100317834,
          0.06290988904985592,
          0.05725586538053211,
          0.05505837950329638,
          0.04928184427381997,
          0.048244099838925955,
          0.054450555687487065,
          0.055011696545439234,
          0.06045914222160542,
          0.06963096480643872,
          0.06495680563227955,
          0.06689430387589719,
          0.0700551902330751,
          0.07828955420527875,
          0.07893844190294692,
          0.08232506808378363,
          0.07743835389706945,
          0.07756737741168936,
          0.07705854291607472,
          0.07074571310317537,
          0.0717696558271181,
          0.07096463656643459,
          0.07172913448681487,
          0.06263838741342555,
          0.061748407474665125,
          0.05657046284244236,
          0.054167254939234466,
          0.04977854150213393,
          0.0424918434429735,
          0.04523273717888571,
          0.0453385176729015,
          0.04789210195723178,
          0.046537041145028116,
          0.047128459530564146,
          0.046313676556258655,
          0.05023476655188993,
          0.05282018525505057,
          0.0564535185883839,
          0.057746298561621945,
          0.06225885516621889,
          0.06688656588356583,
          0.059284634124199376,
          0.05644386246669917,
          0.059574269777772915,
          0.06440119469099378,
          0.06444670521495259,
          0.060351635344246056,
          0.05904979710895193,
          0.06898047881294342,
          0.059019569935095974,
          0.0523648543464927,
          0.05894313309830086,
          0.06689079969878624,
          0.06623788156520168,
          0.06336426776481441,
          0.06736597387398775,
          0.06699465316056177,
          0.06951441458220012,
          0.06027450478218551,
          0.06768858931653823,
          0.07317013742801556,
          0.0664669607720992,
          0.06437428130566103,
          0.06318163895621168,
          0.06144484241941515,
          0.05880064776430499,
          0.06460223758942424,
          0.06316220913992211,
          0.0619931854740056,
          0.05489189061643993,
          0.05231463127794831,
          0.05317380310828092,
          0.05247778764185938,
          0.058942469063347804,
          0.06609824106911981,
          0.0693261596759858,
          0.06778820325485083,
          0.07746989667759688,
          0.07824032103062703,
          0.0804957413596782,
          0.08422726394876393,
          0.08330476436372565,
          0.08804684289112677,
          0.07829016770048931,
          0.06924685360717522,
          0.062230331011705255,
          0.060760848901872264,
          0.05101454395030416,
          0.05243336300811753,
          0.04897776119802324,
          0.046048277121979474,
          0.047519985492007526,
          0.03928048617526015,
          0.04247519047207322,
          0.046659702256585,
          0.05109522692575452,
          0.049348206253686425,
          0.050054731274820394,
          0.04554024086327115,
          0.04980356030074909,
          0.04922142739370504,
          0.05219481706289266,
          0.05223201795723642,
          0.05775814025521222,
          0.05878346199760713,
          0.05989557349401494,
          0.06303567737916627,
          0.07295443336357646,
          0.08331666482580792,
          0.08324492618213465,
          0.0812136865906541,
          0.0805435510244659,
          0.08221915268137599,
          0.07627057502809244,
          0.07505088024674245,
          0.07801748909541012,
          0.07400720512361672,
          0.06005382609523768,
          0.0509736459150575,
          0.050050535032699885,
          0.04859140683503957,
          0.044916329207342,
          0.042157621054481405,
          0.04040180546659751,
          0.040738770958667,
          0.03590298246054495,
          0.03650371283181701,
          0.044994870911210384,
          0.05125745707057074,
          0.05917546671216469,
          0.061339059867283274,
          0.0706754215548843,
          0.07357144601971609,
          0.0730285510497189,
          0.07192903803968395,
          0.06606539633837578,
          0.06722207836602556,
          0.06041716367287557,
          0.0575374017970748,
          0.05779238050723725,
          0.06347614184947317,
          0.05587849397278795,
          0.06261073053061858,
          0.06842835687212132,
          0.07099561794762982,
          0.07835756798016809,
          0.0825804569333202,
          0.0846679028207661,
          0.08316126901339699,
          0.07808365211066362,
          0.07790865342102446,
          0.07985120943029496,
          0.07760371280124095,
          0.0788251278451986,
          0.07636771479130282,
          0.07256942445806783,
          0.06763254464541402,
          0.06361597787884724,
          0.06404479327597384,
          0.059970376710018494,
          0.05497972914115425,
          0.04959302316420438,
          0.05157767759023811,
          0.04743909212387234,
          0.04476831954133505,
          0.04261406925144119,
          0.041894197677080455,
          0.050860465952120085,
          0.051669766863463786,
          0.05261749833990813,
          0.04955357918001116,
          0.05013702377280155,
          0.04166338927222238,
          0.03991159652067067,
          0.04317085577992993,
          0.047474872990197134,
          0.05387957046163526,
          0.054050539948833395,
          0.05783189408888952,
          0.06586999191960616,
          0.07530254467020543,
          0.08215988955109925,
          0.08597259303485197,
          0.08780350050868714,
          0.09271619892138555,
          0.09481020925012296,
          0.0925638019146626,
          0.08554215119695925,
          0.0835370298140014,
          0.07795609937729428,
          0.06940008174206505,
          0.064888036919548,
          0.06152068367921089,
          0.06385932437992056,
          0.058321368436673696,
          0.05888733216166035,
          0.05812275049226308,
          0.06042383011439532,
          0.05937743730309879,
          0.055574342590793545,
          0.056945726470072164,
          0.058716528304165794,
          0.06023170634911808,
          0.06020971417424455,
          0.05990614557442643,
          0.05618878300867677,
          0.058563593060614795,
          0.06320239538148234,
          0.05981512510789627,
          0.07260578202974514,
          0.0749675229204334,
          0.07152911709169198,
          0.07134262769852158,
          0.0747757516078964,
          0.07667385815475135,
          0.07416596819524848,
          0.06993845496773526,
          0.060357344954560035,
          0.06472622607344115,
          0.05300990369484696,
          0.04694800494656483,
          0.05060780984428265,
          0.05129932271824815,
          0.045631928710028385,
          0.0469172234569387,
          0.05133644379329459,
          0.056669025074354805,
          0.0630648935872446,
          0.06259786617021718,
          0.06502111345466607,
          0.06668098791145025,
          0.06772769550542887,
          0.06433909879878633,
          0.07143653662764425,
          0.07433130550708358,
          0.07694344806071127,
          0.07353922175800603,
          0.07058544886879083,
          0.0699808558258999,
          0.06772721104669993,
          0.06842020887293009,
          0.06344532245165822,
          0.0694121905468402,
          0.06669095297077185,
          0.0660262264125513,
          0.06645705425581108,
          0.07371619927745612,
          0.07914833589213141,
          0.07912979885078601,
          0.08486919840060203,
          0.09029547930512535,
          0.09910421777589593,
          0.10195484946842648,
          0.09814969522849952,
          0.09141110948991378,
          0.08790663545857316,
          0.08621357990301762,
          0.08622308364783926,
          0.09028280784171315,
          0.08089399441028512,
          0.07736171574674951,
          0.07460782959665405,
          0.0695369185028986,
          0.06962025925187895,
          0.07472364271052558,
          0.07482863227924988,
          0.07129847354909116,
          0.06610590698839745,
          0.06099636527678002,
          0.06128908345275537,
          0.062038375729300134,
          0.07093912760899938,
          0.08438100315196113,
          0.08627758285422886,
          0.08776998694136978,
          0.08534715235021836,
          0.0858616906574396,
          0.09135544453985983,
          0.09330803883922832,
          0.09430611066245419,
          0.08961649561800045,
          0.07536370853478085,
          0.06319054644211147,
          0.058825633406510425,
          0.05437314111968079,
          0.059136299743235456,
          0.06317177745415167,
          0.05898069651378564,
          0.056587933692754555,
          0.06243150239041204,
          0.06931956069226344,
          0.07719183399102189,
          0.08311851482353796,
          0.08565286139094905,
          0.08630405091619608,
          0.07776394896207545,
          0.06887728631117483,
          0.06526376379861216,
          0.0685730157308904,
          0.06540825564919996,
          0.06226600843689968,
          0.05941364971752058,
          0.053076048938078366,
          0.05766670237066729,
          0.06732108515082287,
          0.08102379367256292,
          0.08959494322930267,
          0.0966319288361022,
          0.09658824655291223,
          0.10303169520793413
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "line": {
          "color": "purple",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.029334042681082157,
          0.03249141906198795,
          0.032769785278178476,
          0.03575719100970186,
          0.04247093804697831,
          0.04696291302249349,
          0.04927858424511097,
          0.05185597861923856,
          0.04630205073143044,
          0.042686008157652014,
          0.04285305189822517,
          0.0390154953371392,
          0.03766914666480832,
          0.036807258552920205,
          0.03311327436149356,
          0.032209652928460356,
          0.03227051954363731,
          0.029763089057254905,
          0.030264500385868524,
          0.0356665422571531,
          0.03792863016924101,
          0.04269328797744438,
          0.04170697391218295,
          0.04255305005825909,
          0.04687506634830607,
          0.047177422906476585,
          0.045173383582650835,
          0.04975852852961102,
          0.053589704110942805,
          0.04936916687825356,
          0.04896280671555172,
          0.04958203169123113,
          0.05029689790609735,
          0.05224086921256865,
          0.04768883366641546,
          0.04746926377462295,
          0.050752535533365103,
          0.04594705075881013,
          0.043792174611854764,
          0.04553955241157584,
          0.04640305543142053,
          0.0419046930095287,
          0.04326105534048268,
          0.04214479224311494,
          0.042072009479888775,
          0.04422964677362914,
          0.043949838100511396,
          0.0457922026325311,
          0.041846712479120154,
          0.038017975178684736,
          0.03549722046170361,
          0.03816086235720825,
          0.037493121632958065,
          0.03710780739207344,
          0.0372866137613232,
          0.039329012481370974,
          0.041346361539374245,
          0.043699235102592625,
          0.04465470068963716,
          0.04957557981051629,
          0.05654111251373882,
          0.05943626520055818,
          0.06319880354501432,
          0.06095100332811885,
          0.06062666470378022,
          0.05616852755480117,
          0.0545597322282639,
          0.055334467580523204,
          0.05541173521770125,
          0.05350892918300667,
          0.048140013265730794,
          0.04330030939661516,
          0.03663352722983299,
          0.0346802893448654,
          0.034434035598611655,
          0.03468859089550262,
          0.03424897352362718,
          0.03258002913181986,
          0.042746198965323855,
          0.0403363214219143,
          0.040727126019615444,
          0.042110153478090474,
          0.04261506364153723,
          0.043630372131845715,
          0.04309482434629793,
          0.04710488033251671,
          0.05001213973977612,
          0.04611648308945845,
          0.04051654115005743,
          0.04202082136681703,
          0.04574096086115007,
          0.04680651381683744,
          0.04945394971427333,
          0.052005055365378985,
          0.05501402972435334,
          0.050750140835464454,
          0.04523811952344314,
          0.04579263422549883,
          0.04427507170857186,
          0.04494061792705926,
          0.04329806751031529,
          0.045214011823422724,
          0.04811762384461756,
          0.04899731108849521,
          0.04504653577685034,
          0.04699091946333929,
          0.04953800941042923,
          0.05008514003774165,
          0.051600187543427455,
          0.05499066373390364,
          0.053092411888283376,
          0.05071301967555784,
          0.0456951571104491,
          0.04510418167283363,
          0.04836901528390266,
          0.04462554902860637,
          0.044887061232054055,
          0.047394176423211185,
          0.04428468086557732,
          0.03969102165122845,
          0.039707403073693893,
          0.038316933794545364,
          0.03861412981470301,
          0.03366857858618085,
          0.029555918888155307,
          0.030834488636449824,
          0.03796634172959324,
          0.03681642379662347,
          0.04052924198841632,
          0.044285478233577515,
          0.045804646310534845,
          0.04904447456404235,
          0.04950279216789351,
          0.05663407876460067,
          0.05765172582342419,
          0.06219547090643057,
          0.06382453947227333,
          0.06349926380089348,
          0.05935499708629528,
          0.062238474950113566,
          0.06156420446522058,
          0.056039179263197916,
          0.060881212670653606,
          0.05667734429321656,
          0.05846180391301249,
          0.05814517825712554,
          0.053313028184975464,
          0.05535925572309689,
          0.05570439472209272,
          0.05448108672297719,
          0.054438472474480595,
          0.05531010939811498,
          0.05232080024601513,
          0.05261442835168665,
          0.05137753906437155,
          0.049132086344230635,
          0.045156105641682764,
          0.04538502945324686,
          0.04386188130509871,
          0.04427722964767886,
          0.045251846697295914,
          0.05431537610906062,
          0.052509845948879294,
          0.051926378774305795,
          0.052239651085518604,
          0.04969667901723472,
          0.058975161285420484,
          0.05968984867336339,
          0.06365011803363277,
          0.06169883317186196,
          0.06294243034045913,
          0.056460319510113,
          0.05941795567240034,
          0.064001060871295,
          0.06601577629698298,
          0.06587819648549012,
          0.05727378382281918,
          0.05237357719221416,
          0.054056405475042445,
          0.05741907853173085,
          0.058561195648847965,
          0.056102108758726586,
          0.05305075513722372,
          0.050741847336586585,
          0.053144315800156994,
          0.052072624684557145,
          0.05797391467630377,
          0.06222129854512544,
          0.06176631209013898,
          0.056577368117665595,
          0.05243992792627804,
          0.05635393716726036,
          0.059293151331796204,
          0.057594519190767746,
          0.05401477713289608,
          0.0544521855139327,
          0.0466909680500411,
          0.04092282946423831,
          0.03811031740466742,
          0.03949501603936605,
          0.04409292134703269,
          0.04516560297114413,
          0.04494487682628005,
          0.04243122918360016,
          0.04384813394919924,
          0.04588570061871807,
          0.04906148820184511,
          0.05919400681936386,
          0.06261805959837022,
          0.06464901197932257,
          0.05949764297288333,
          0.05598809131596325,
          0.05236984466371182,
          0.05944710074096791,
          0.06002843464562907,
          0.05825363961307541,
          0.06243193678311572,
          0.05283922050162569,
          0.05398696835276466,
          0.05010374627888838,
          0.052826531460266904,
          0.05398299160704963,
          0.057520669020111125,
          0.05171114521058732,
          0.053386242952407535,
          0.058932055760289315,
          0.049615014455278474,
          0.05028275928906104,
          0.04865104847106438,
          0.048044274913660624,
          0.04447363215455239,
          0.0428572408138762,
          0.04276800055222215,
          0.04297446815154689,
          0.040777164491276816,
          0.0354229392003557,
          0.04068544149015236,
          0.04617322555816471,
          0.04257345033338948,
          0.04513981583375855,
          0.04542280807087922,
          0.04691696852841371,
          0.05007008763153281,
          0.05178294841139547,
          0.05002047130516837,
          0.05295758764249296,
          0.05357055333027304,
          0.05591995369487037,
          0.05531566477990184,
          0.054591128517818846,
          0.05751078663747696,
          0.05379891935846206,
          0.0511288394158669,
          0.049584792086379156,
          0.05305001931439411,
          0.04709766144422183,
          0.04146747648551301,
          0.03193704798716992,
          0.033725399965511854,
          0.03201233584860276,
          0.029958062344329257,
          0.03704127322228533,
          0.03632180382533114,
          0.033371098200206915,
          0.030176179919106417,
          0.0355118363979393,
          0.04002601777347187,
          0.045794733537318486,
          0.04779839079959644,
          0.047798390799596434,
          0.05596083161480263,
          0.04950340690036858,
          0.04809925549621717,
          0.05540458784502779,
          0.052887034709280356,
          0.04898083495426486,
          0.045788242361672275,
          0.04577061252378424,
          0.041533645148885835,
          0.04073761665762747,
          0.03923823487641054,
          0.04228303774379405,
          0.04342758191498619,
          0.04400647645040246,
          0.04780432713656324,
          0.05264825704895373,
          0.05840213996412698,
          0.05505208069627956,
          0.05776766481403086,
          0.06440456500733349,
          0.06066810416798572,
          0.06296133893501081,
          0.06221451116153507,
          0.05776862371564763,
          0.056517101467404074,
          0.05067416578845959,
          0.045157825919178544,
          0.04324249615698946,
          0.04267051473284085,
          0.04255451822934435,
          0.04072624582655805,
          0.03949246912729274,
          0.036903983498807115,
          0.0388955176289282,
          0.03957377849849341,
          0.043533392656058253,
          0.04788823519913609,
          0.0548360537096216,
          0.05866381666639149,
          0.05825779680905584,
          0.05892566371339333,
          0.060542037698884964,
          0.0624109352529438,
          0.061638956421325386,
          0.06419995021014527,
          0.06385430863703687,
          0.06304227655147536,
          0.057798243061001287,
          0.05366703080124082,
          0.050110042079556646,
          0.05555547905803711,
          0.058519533947752556,
          0.061754610459292494,
          0.05909378531951999,
          0.056004390605112475,
          0.05925401734967593,
          0.06477847268736656,
          0.06872485414904214,
          0.07656884853496912,
          0.07446289029649271,
          0.06673247535303428,
          0.06322164697811618,
          0.05899726395976802,
          0.06317165440323062,
          0.06774877858623715,
          0.0704414202582906,
          0.061485088926959273,
          0.06238973199630822,
          0.05329604006022498,
          0.052740484504669415,
          0.057915980084420324,
          0.0576812720881415,
          0.06309341103928753,
          0.06070373237527356,
          0.0609926328886902,
          0.05653265195928987,
          0.05958987922704345,
          0.05283659362375785,
          0.05382165435250279,
          0.06084263421543312,
          0.06289595408392311,
          0.06520024347644779,
          0.062392323001860664,
          0.06286588827096562,
          0.06092588185070537,
          0.060533616969500756,
          0.06074692115757274,
          0.06905597479314811,
          0.07239872131462421,
          0.0641433810408629,
          0.05812243980984201,
          0.062356022131659625,
          0.06812404982890694,
          0.06781797681986387,
          0.06602867868630345,
          0.0687634055744458,
          0.06620737043311653,
          0.06143091655072915,
          0.058155721782365874,
          0.060657489816312124,
          0.059922020777379646,
          0.05281939004666543,
          0.04614949899538086,
          0.046167836694833105,
          0.044176494703491116,
          0.04487978774780903,
          0.053450740698367236,
          0.054905092399522015,
          0.05354175117272497,
          0.05190619629070616,
          0.051889389568017086,
          0.049213193343433756,
          0.048635403017817345,
          0.0594094914713571,
          0.06055988484609829,
          0.05384932080827659,
          0.043188324567675095,
          0.040120603882563104,
          0.040842358268528015,
          0.04433398201654275,
          0.045114486218223414,
          0.0500038892109408,
          0.05203592384297543,
          0.042964309523488765,
          0.042419976754808165,
          0.048721070867666985,
          0.05700916610576223,
          0.06512709500522099,
          0.06627156386968984,
          0.06915878191480263,
          0.07337819808260755,
          0.06685200040046389,
          0.061298694806381594,
          0.06081373999511099,
          0.06367750254834724,
          0.059851707646081755,
          0.055603068190299434,
          0.05618037738607877,
          0.06658856138631862,
          0.06767337213112937,
          0.06811333351731501,
          0.06683084157316893,
          0.06923103361413767,
          0.06945060956946339,
          0.0701895515663001,
          0.07094475353233451,
          0.0724195834643073,
          0.06671370111136612,
          0.05588681505846196,
          0.05264910623134137,
          0.04936733519963452,
          0.050759476266587625,
          0.053322443299554656,
          0.05947733622199571,
          0.056128215159373496,
          0.052219729885881215,
          0.05363503470756174,
          0.05589763974957855,
          0.06042152340665722,
          0.062355425414703736,
          0.06744361046932476,
          0.07082596304888687,
          0.06942605354662443,
          0.061195125338714115,
          0.06277234262943256,
          0.06807430092203601,
          0.0638987689974121,
          0.06782278756161872,
          0.06518276672236513,
          0.06536663447232534
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFSSGD<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "line": {
          "color": "yellow",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFSSGD",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.03419450775889746,
          0.03800316293799645,
          0.04046684305312754,
          0.04484505670437592,
          0.04688849974551717,
          0.041521175892899206,
          0.04421529740357244,
          0.04905191971368381,
          0.04848810982539631,
          0.0510802474175339,
          0.05230769014778168,
          0.05152623294464727,
          0.054039696884502775,
          0.05514358949681245,
          0.05340576108481524,
          0.054522424205759826,
          0.053422163654104335,
          0.05227784961796722,
          0.054675047619642834,
          0.0544579036613224,
          0.0615642161570696,
          0.061390663562937174,
          0.06268193423777307,
          0.059190902135276904,
          0.057956126303726874,
          0.060927116705729936,
          0.06243974925320569,
          0.06852013647508683,
          0.07404657228046999,
          0.07758833978025606,
          0.07516771491722168,
          0.0799363888932402,
          0.07820968820203791,
          0.08204355003136152,
          0.08312014404472973,
          0.08390400716347242,
          0.0868082279426932,
          0.07979531546062721,
          0.06975474972601976,
          0.06213091788534582,
          0.05804643629296948,
          0.05412605922741458,
          0.05141870563069377,
          0.04531499783209891,
          0.04458602188051426,
          0.04538443503857117,
          0.047013997548551636,
          0.046958382552874295,
          0.053612147489380625,
          0.06054944593972256,
          0.0633508905477461,
          0.06802778021834303,
          0.07075537707480868,
          0.07638436572414048,
          0.0797097690708622,
          0.07843059557363595,
          0.0732000194221246,
          0.07411618258032096,
          0.06985805046128338,
          0.06311235880048638,
          0.06855252258407121,
          0.06331213261628185,
          0.05684506964938687,
          0.0544253043254169,
          0.05386841905482196,
          0.060595645945578244,
          0.06519386890444041,
          0.07214445426679048,
          0.07586978312098147,
          0.07847815413141433,
          0.07873626823952844,
          0.082790911520642,
          0.08776773863594212,
          0.08604124233932182,
          0.08526158140885443,
          0.07707828529795725,
          0.07754434624694503,
          0.0714010794778718,
          0.0700351113606478,
          0.07764979667533312,
          0.07575690727809589,
          0.07102187653099115,
          0.07103064690963448,
          0.07296774653209216,
          0.07017335553409584,
          0.073836657584999,
          0.06946274410617105,
          0.06877614629537969,
          0.07005670480243943,
          0.06670751634964929,
          0.06075033359681435,
          0.05950154987279843,
          0.05612927839642479,
          0.058919598969098305,
          0.06335449429622994,
          0.0644580973787804,
          0.06619006962457483,
          0.07060338574108245,
          0.06982716282004821,
          0.0675479255319126,
          0.06913421635779153,
          0.07265718770849397,
          0.0736883581089288,
          0.07121629874552751,
          0.0735334606656046,
          0.07134856005792099,
          0.06936297649385549,
          0.067109416686954,
          0.07285920442333557,
          0.07690468664753472,
          0.08595887019560775,
          0.09115863884999825,
          0.09128199496020448,
          0.08586821554364935,
          0.07899037824528973,
          0.07881572071104316,
          0.07617176722177299,
          0.07098401924091677,
          0.06846123833485912,
          0.06579700472638535,
          0.06206150777611051,
          0.05507841537199344,
          0.05381276289581464,
          0.05610989364000422,
          0.05810752486338579,
          0.05706888295974748,
          0.06586302171572835,
          0.07113536408459001,
          0.06605648543635653,
          0.06950358705035106,
          0.07047302594262345,
          0.08154290215117138,
          0.07902775063601987,
          0.08069957711432614,
          0.07969509288887416,
          0.0771943047231737,
          0.07185102572725245,
          0.06925164554931729,
          0.06623490941189149,
          0.06373099561800485,
          0.061701900647376705,
          0.049882465180882414,
          0.05227543839124693,
          0.055083307263868876,
          0.053128911659473275,
          0.05615730672120167,
          0.05406161265314987,
          0.051932987282577246,
          0.05481142114257033,
          0.05196075921654099,
          0.050758439967162915,
          0.058844482820078835,
          0.059151004559209276,
          0.056854551391294396,
          0.060984015381223514,
          0.06030409986663058,
          0.06598390870772973,
          0.06945248052755325,
          0.07504029736809276,
          0.07527057297483895,
          0.07013194798327278,
          0.0588863225745479,
          0.0570410844793098,
          0.05178511242356658,
          0.04511375046905909,
          0.044303766993753046,
          0.04372793121662694,
          0.052665828603009016,
          0.05455021947040077,
          0.05195523798130164,
          0.05173284586441411,
          0.061227095387676934,
          0.062187198347779894,
          0.0658009035925531,
          0.06822138262518622,
          0.07637100305306753,
          0.07546655086357786,
          0.06872947206900407,
          0.06971236148912388,
          0.07718547724705496,
          0.09458106051174664,
          0.09171857329690732,
          0.09785003942345541,
          0.10332652041709696,
          0.11376435079425688,
          0.10590484835992531,
          0.10374830230600587,
          0.10427912696355465,
          0.09532514621954198,
          0.09238179453852173,
          0.08308555008184731,
          0.08445026740344622,
          0.08210613137397066,
          0.08087705624666702,
          0.08100591977819184,
          0.082410681617453,
          0.09009893255920416,
          0.08771888772639654,
          0.08682119515227481,
          0.08910035890181371,
          0.08201156723877706,
          0.08030083385594472,
          0.085252217583008,
          0.08906056609545487,
          0.08283380029624093,
          0.08824847757298718,
          0.09022731890080278,
          0.0929259619604845,
          0.10244597606531007,
          0.1027380413633829,
          0.11519498509086043,
          0.12277087970222415,
          0.1229239124750779,
          0.11970092032739917,
          0.1303924815748047,
          0.13607176016398317,
          0.1361125511826053,
          0.13628746937578434,
          0.1307990592352003,
          0.1275813629529879,
          0.12492847325197924,
          0.11736540800673342,
          0.10996097486301477,
          0.10156009143271957,
          0.09320594456674416,
          0.08343822713027729,
          0.0715912533937015,
          0.07275092181949731,
          0.06909310702447322,
          0.07650121258451668,
          0.07140097670451215,
          0.07343080288903764,
          0.07584891987437795,
          0.08467944490490299,
          0.0877790983665928,
          0.08890695283701776,
          0.097943721370711,
          0.10063234796494933,
          0.10753919292292535,
          0.10624179391140179,
          0.11230928407773626,
          0.11997189533088237,
          0.1210781085584092,
          0.11393270214758222,
          0.10425681540365668,
          0.10676907723079572,
          0.10409521124171235,
          0.09715064244714355,
          0.09446332834590768,
          0.09314237998354066,
          0.08338605787453335,
          0.07405230980446452,
          0.07546514633700022,
          0.07906256538468603,
          0.0910112527987251,
          0.09605646713548911,
          0.09901016918057046,
          0.10398412855452983,
          0.11129935721551773,
          0.10808417196259452,
          0.114660802810482,
          0.1212667241966349,
          0.12536079939775388,
          0.12343263712655723,
          0.1188379479694867,
          0.11383400530622816,
          0.11267689157479392,
          0.11341771473855826,
          0.10608140602767677,
          0.11004941507213344,
          0.10680274484421322,
          0.10000200150581902,
          0.09270499728126166,
          0.09460874154319408,
          0.09532382090827345,
          0.08912867398229463,
          0.08793101809215619,
          0.08888484916304609,
          0.08874280785154247,
          0.09141758262631725,
          0.09449372408476134,
          0.1004237196447569,
          0.10394742913635083,
          0.10296040604124261,
          0.10139635740331339,
          0.10327531854242489,
          0.10467432902568263,
          0.10481737247271586,
          0.1041895414464061,
          0.09742215631691573,
          0.10011483272136557,
          0.09860695066970192,
          0.10032671235605288,
          0.10704363813655157,
          0.10360201762093932,
          0.10201560155811074,
          0.09547692781355464,
          0.0929816602507679,
          0.08963630750216971,
          0.09160023179377304,
          0.08507415475486993,
          0.08570670176146168,
          0.08732261156445298,
          0.08761651840287202,
          0.09797793197539323,
          0.10151785505618442,
          0.10521078283016483,
          0.1020156137835252,
          0.11157274674065816,
          0.11605057412881829,
          0.11465871541282166,
          0.10724014436398743,
          0.09903977474123396,
          0.09666411549904247,
          0.09733932346101513,
          0.10028384321551516,
          0.10300159538955245,
          0.10210724381913705,
          0.09560241529313204,
          0.08596693763174786,
          0.08316423127978494,
          0.0864165360613467,
          0.08850753296483459,
          0.0885381215164259,
          0.07300089207919648,
          0.07259687548071796,
          0.07759922210875791,
          0.08428905597465561,
          0.0927342491120282,
          0.1008130962882438,
          0.11253481043261715,
          0.11148387161089593,
          0.11560454290170455,
          0.10967377436195544,
          0.12197275150566941,
          0.11692605130708018,
          0.10868503262508926,
          0.10264251281895051,
          0.09224718524653301,
          0.09288667052041458,
          0.09175938033510969,
          0.08914248926111389,
          0.08638136436450514,
          0.09284231712775033,
          0.08703827544073652,
          0.08675009956432533,
          0.08194198268120845,
          0.08158952482907166,
          0.08316981889511368,
          0.08490795640479532,
          0.07917417521976414,
          0.08560129859363794,
          0.0843117141994024,
          0.07630351426882684,
          0.07766997943681844,
          0.08346211128158186,
          0.08844623826570885,
          0.08999141099035592,
          0.09645193020188561,
          0.08969860033872519,
          0.09177775614309838,
          0.10075302657024851,
          0.09934612267016969,
          0.10254603446467472,
          0.10935890721153893,
          0.11142985481606187,
          0.11659026170182085,
          0.1250334732288559,
          0.11847140813611931,
          0.11739369261492553,
          0.12457108819107432,
          0.11724373713402358,
          0.12744729118205686,
          0.13191153847947487,
          0.12072843989058306,
          0.11390302277895906,
          0.110067789364715,
          0.10264609161801723,
          0.10828496611020241,
          0.11110215126422969,
          0.10821475948933792,
          0.10843185304663046,
          0.10161690106149593,
          0.10079173036023359,
          0.09867473140174526,
          0.10202040976878586,
          0.10646049413884455,
          0.10550173372118003,
          0.10455639895987634,
          0.09884342772058932,
          0.09000745780814882,
          0.08798397302679631,
          0.0864325635831268,
          0.08419582920615543,
          0.10012226719602624,
          0.10423685151965711,
          0.10492670534006313,
          0.1127658419033212,
          0.12041146070097204,
          0.13030070819299241,
          0.13816204872799026,
          0.1406735629343928,
          0.15078135340969687,
          0.15731487719599052,
          0.1504576875696153,
          0.14582642920794817,
          0.15051071572948432,
          0.14095321027661484,
          0.1284927431767739,
          0.12513306942485355,
          0.1239918593041038,
          0.12344886681330873,
          0.116337862227509,
          0.11056064091067572,
          0.10741348189574004,
          0.10925828246554063,
          0.10226490166333628,
          0.1003670441294964,
          0.10139278109094765,
          0.09631978629821601,
          0.09514228651540205,
          0.09049375347340163,
          0.09285208587608167,
          0.09066937461597316,
          0.09121037380276471,
          0.08141195004455834,
          0.07481649955667088,
          0.07503680513134078,
          0.0784754123116021,
          0.08639069789952147,
          0.09064204643073961,
          0.0967596732891753,
          0.10513071782453147,
          0.11590881800944068,
          0.11464971635408225,
          0.12270578207122369,
          0.12318182737038157,
          0.12738615898647787,
          0.13249760972412056,
          0.13152628946595873
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=FSDS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "line": {
          "color": "green",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FSDS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.03680022418928036,
          0.0331823658885977,
          0.039124486923058,
          0.03681131358636856,
          0.03898017764033418,
          0.034345390646246324,
          0.03860078032569475,
          0.03455503697175092,
          0.0368113169950046,
          0.037832389199109015,
          0.03604137561499198,
          0.04090599576810089,
          0.039565181923183076,
          0.03761046036407065,
          0.045216972369391636,
          0.04810961206733945,
          0.05009559463571489,
          0.05387246490503367,
          0.048995249307225104,
          0.04707188313540616,
          0.047148438159329606,
          0.045388356506985604,
          0.04183364374468771,
          0.04319449475808109,
          0.031247848940239686,
          0.0337308581265449,
          0.032553287659595996,
          0.03673624847483793,
          0.0405963004739947,
          0.042365048742125794,
          0.04266975010226772,
          0.04007115150366912,
          0.04156306389564272,
          0.04415745763749408,
          0.04509681407313765,
          0.04158761170757279,
          0.037124532835683594,
          0.03099928821728829,
          0.028961443605759463,
          0.02746199267234627,
          0.02618708277198587,
          0.025681142869819557,
          0.02729474864389044,
          0.027527959877101677,
          0.028890834810257844,
          0.02997481145841636,
          0.029904771525985134,
          0.031139582691830786,
          0.035496629154140404,
          0.03968858138262514,
          0.04436071974740502,
          0.046672624906864024,
          0.04607556060154687,
          0.04075697983590728,
          0.043553795145968986,
          0.046300039429918186,
          0.049794746557652834,
          0.05254158937001289,
          0.04770812991259869,
          0.04928337345130972,
          0.04635337345130972,
          0.04636012657277314,
          0.04909410777256533,
          0.05062685313309241,
          0.04520429994627681,
          0.041555047809524674,
          0.042266892950210674,
          0.03931067490225613,
          0.0403980710002793,
          0.03661200583737203,
          0.03738073414927242,
          0.03980740815829579,
          0.037459520761500165,
          0.04013522185647837,
          0.0414115851179978,
          0.04016032972445517,
          0.04060845573207384,
          0.04156714678594966,
          0.04124766346051216,
          0.03900587597292527,
          0.04642569198360219,
          0.04786460647412958,
          0.049706092284896516,
          0.04802832047212969,
          0.04648738226891003,
          0.048783438904187855,
          0.04466272411624047,
          0.052931999869726756,
          0.050378595330340906,
          0.05276175933614642,
          0.044940769945780425,
          0.042120318493187356,
          0.03915648707556283,
          0.04335759222166299,
          0.044305797919036286,
          0.05042555254981731,
          0.052155350529615285,
          0.04390298885620098,
          0.04629904928840599,
          0.04833224368022107,
          0.04669346721591866,
          0.047793283747876815,
          0.04722132092546027,
          0.046537528752720735,
          0.04698025321092507,
          0.04177303448324598,
          0.041184838196773835,
          0.03885310930188704,
          0.0400284774411106,
          0.03958554992527668,
          0.041986758587354914,
          0.041944756145352466,
          0.042219239267252295,
          0.04217962621593241,
          0.04269183064003614,
          0.04737426622247172,
          0.04917936657262213,
          0.04813488751412438,
          0.04723960889203725,
          0.046491074995720104,
          0.04627336856748736,
          0.042462836447277816,
          0.041398616263791585,
          0.03872419422739217,
          0.04480189341607534,
          0.035307712125667634,
          0.03125669591245667,
          0.031530097151562,
          0.029057002009048944,
          0.02752390325230487,
          0.029723844772772706,
          0.028909712668318023,
          0.027265915300946658,
          0.027729544523256166,
          0.02582404422645152,
          0.029914913885961392,
          0.03625144279167025,
          0.03716180760957298,
          0.04188732423131601,
          0.04858825878745639,
          0.04588588902834994,
          0.045925162469685234,
          0.05087918349838657,
          0.052537748650903014,
          0.04904527515948216,
          0.049332685827670524,
          0.050704358707348705,
          0.05063450466536814,
          0.05231932746726411,
          0.046773105984471895,
          0.05080195444032019,
          0.05745982385612776,
          0.05380130109599125,
          0.049837398851843184,
          0.05403711441572351,
          0.05482198982671778,
          0.05024387720235768,
          0.049433703505087204,
          0.04718006082741484,
          0.04966412326427077,
          0.04481809633798069,
          0.04139476300464735,
          0.040238474947490575,
          0.04124430177408048,
          0.035499312630210576,
          0.039271769868518755,
          0.03960100800332399,
          0.04206720518642258,
          0.04247671770289162,
          0.04103177357927547,
          0.0472998055684235,
          0.04611843301940389,
          0.04929352538521401,
          0.04840609815726954,
          0.05061022734198188,
          0.041485565160393714,
          0.04699184349410308,
          0.04693397964433783,
          0.04422920094368928,
          0.043203989263048255,
          0.041385304016589096,
          0.04466447187806567,
          0.046958510177736015,
          0.0496239237115706,
          0.05003192178797146,
          0.05255958285239724,
          0.04487490286817094,
          0.04760221167047975,
          0.05500495930293855,
          0.05303819488456123,
          0.056560742913767115,
          0.05254780998663124,
          0.05008918215037276,
          0.0567515140736954,
          0.05748986282172157,
          0.062188437417333084,
          0.07085903790457392,
          0.07317638722192324,
          0.06738547621109495,
          0.06956461880762885,
          0.06430415750152596,
          0.07101995682009238,
          0.07057735022623897,
          0.0614210333405103,
          0.059344876090680496,
          0.05364679297606504,
          0.04596456417822683,
          0.04053472486788708,
          0.04833459779383596,
          0.04570870195054881,
          0.048138094909793865,
          0.042446852137490235,
          0.040615522088229154,
          0.045952786257751385,
          0.048849077190990034,
          0.05448330209654859,
          0.05491872297196946,
          0.05438672127179563,
          0.05030892141732911,
          0.05943381842048697,
          0.056281922699449226,
          0.05672626720872557,
          0.05746392954638789,
          0.051603991720247044,
          0.05532490456341107,
          0.0495071934193204,
          0.04862277274195855,
          0.05038058348322446,
          0.043877426516734166,
          0.03905526639933205,
          0.037817521351781666,
          0.03667750060097993,
          0.03692777042248263,
          0.03624287092935942,
          0.029307269519467643,
          0.033562150723890134,
          0.037659294883372385,
          0.03980507054173386,
          0.041157257435300056,
          0.03730127379629755,
          0.04214829896792227,
          0.043690303404300565,
          0.04207538711815141,
          0.054604419580762745,
          0.05242186285020535,
          0.0485728600012025,
          0.046323927621596615,
          0.04600265515295572,
          0.047071293209087706,
          0.04973005892667696,
          0.04467178411195716,
          0.04513192483598767,
          0.04783973264379547,
          0.03573297586976644,
          0.04140571079557934,
          0.044623308996822715,
          0.04460484589963621,
          0.04025156501241037,
          0.039258012789984906,
          0.037944272417421,
          0.03912894140696804,
          0.03736893590944193,
          0.038363055633836886,
          0.0420059345486305,
          0.0416256783164227,
          0.047370495940095146,
          0.050289421564370204,
          0.05061582192906335,
          0.05048378729702872,
          0.05293414550642308,
          0.055236133348017954,
          0.05553700929977323,
          0.050937366295088646,
          0.048951125229461614,
          0.04742926550444708,
          0.04471630501722189,
          0.044289918716368504,
          0.043923515045617,
          0.044415055366425614,
          0.04465959810193221,
          0.040819957545654664,
          0.03964150112775067,
          0.04226310382411972,
          0.03895958590490601,
          0.04002954571168524,
          0.03656576379286475,
          0.0392066524449763,
          0.04083416457248844,
          0.04182114055738059,
          0.038130659479131045,
          0.04096835667935553,
          0.045372318607179836,
          0.049092760327621554,
          0.052870211490669006,
          0.052879149555528124,
          0.05500597493039701,
          0.050918857786888885,
          0.05377174813977923,
          0.05372990277973529,
          0.05633560908321006,
          0.057602423028994064,
          0.06128676483098292,
          0.05637129752421126,
          0.06093957700592358,
          0.05684258253386524,
          0.05526521871561206,
          0.05457943516271888,
          0.051558852502136224,
          0.05164599108028891,
          0.04825727313157097,
          0.04752363737691119,
          0.04080298730213947,
          0.04162517236345496,
          0.03595991254952259,
          0.041691977119575584,
          0.04338838770917567,
          0.050066976869160174,
          0.053589025061931264,
          0.05241640601431221,
          0.054785413818102625,
          0.051284875835041197,
          0.05193379850475218,
          0.049823492546620135,
          0.05408724406492658,
          0.04882674676255734,
          0.05041336456631971,
          0.04013689620680559,
          0.03479302983221632,
          0.03356869009632196,
          0.032643955130870914,
          0.03216218716034598,
          0.034209914167917195,
          0.035509265065206234,
          0.029580678893895606,
          0.03547833613861168,
          0.03002522068481129,
          0.03254929416463184,
          0.03781483633330655,
          0.03781549882052365,
          0.04031424336084523,
          0.044349357334862186,
          0.042195348606974166,
          0.042916952875377126,
          0.0451695844543245,
          0.03995540059896417,
          0.04552111833328656,
          0.047006782795197814,
          0.04437523272138478,
          0.04643894756404699,
          0.0472818393117207,
          0.045524475564995254,
          0.04671266005977147,
          0.04468043275237254,
          0.042322986774127574,
          0.043631110023427296,
          0.03926715512073044,
          0.03623359693822415,
          0.037310311914069555,
          0.03609241717722746,
          0.033435639963157245,
          0.029799217826735103,
          0.027964151455230242,
          0.03200932312450758,
          0.03776368098146733,
          0.04186251243323996,
          0.039435141126005956,
          0.03855779857608276,
          0.03596058670582741,
          0.036708381740681265,
          0.03531004427986702,
          0.037289527562541794,
          0.038410856426303236,
          0.04111097016215785,
          0.03563511091502201,
          0.03178188225882305,
          0.034019479856420655,
          0.03377724568676713,
          0.03269556866813359,
          0.03372205934756544,
          0.03562483132968169,
          0.03678697499435675,
          0.040248411611164214,
          0.0359112608483885,
          0.034916311353439006,
          0.0343180044994978,
          0.036453443095989024,
          0.03744843809098401,
          0.041417205597986825,
          0.043212113129479715,
          0.04050005376027749,
          0.040190746975035045,
          0.03742889314259298,
          0.03524490370918566,
          0.040433970851193976,
          0.04092142216803204,
          0.03629128271683997,
          0.03961217780547699,
          0.03605509254146484,
          0.03568476631102384,
          0.04252969312699767,
          0.045319705185449734,
          0.04371503648250517,
          0.04675983537293512,
          0.04702969744261,
          0.04536924801137847,
          0.04838966695170587,
          0.04895581857364497,
          0.05323364018723135,
          0.0506850957525389,
          0.045996501274178196,
          0.04934944916566355,
          0.04704052073219545,
          0.0440839021214484,
          0.044535506820299116,
          0.05054727803759997,
          0.04708825422388509,
          0.046496653156580706,
          0.04063639458302254,
          0.040375667017953705,
          0.04197812095347052,
          0.0356073803373973,
          0.04640031249737792,
          0.0523077075056405,
          0.0486330137783152,
          0.04647024667968137,
          0.04842437112122001,
          0.05005588815491095,
          0.0542926092584467,
          0.056935788956740986,
          0.05890202666774043,
          0.05848395333718235,
          0.05686386054760308,
          0.05436200189900531,
          0.05797678886642386,
          0.05688965666752347,
          0.05826469653993177,
          0.052726784452019684,
          0.05033645909110608,
          0.05284015496547077,
          0.05438973455214265
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=random<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "random",
         "line": {
          "color": "cyan",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "random",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.03919169014024721,
          0.037521718934708695,
          0.035176635446768065,
          0.035735851133042576,
          0.037642009490813845,
          0.037529166902207145,
          0.038878148636580484,
          0.03837392622606216,
          0.039153273327994204,
          0.039861375436762235,
          0.04167839462023494,
          0.046103051093459343,
          0.045351535941944195,
          0.04693153594194419,
          0.047346454356862605,
          0.04509982272762228,
          0.041382856803525624,
          0.04143598825134308,
          0.04166397197647871,
          0.03986317685081595,
          0.03836848776443064,
          0.03778949031496357,
          0.04237340182828685,
          0.04647500562989065,
          0.044344476494110205,
          0.04041977156940528,
          0.043533186889717156,
          0.04390606779481008,
          0.04464376620750849,
          0.043394305234012956,
          0.039548165613116054,
          0.0370388422605781,
          0.033206445898769976,
          0.028254744631279232,
          0.029821304403090314,
          0.0314026471883166,
          0.02980663500150693,
          0.03070781424678995,
          0.03269825830565506,
          0.032776261352649085,
          0.0332159587269259,
          0.034470597161246994,
          0.038816463351794034,
          0.03949114492922161,
          0.03635594745343007,
          0.04117550006909919,
          0.040773870051370106,
          0.03821060474524766,
          0.032992907017619436,
          0.03478670095028684,
          0.03736777050347067,
          0.03783006807432088,
          0.03881998973552957,
          0.03902347579942753,
          0.0405869521470623,
          0.040571195580113587,
          0.04238202179093979,
          0.04644013547119451,
          0.04676368543625391,
          0.0477292427117957,
          0.04643228530814459,
          0.04960055076817475,
          0.04855527675041112,
          0.04826357021133615,
          0.04856638219985208,
          0.04720467062091159,
          0.04939721532078387,
          0.047749554541665296,
          0.04757573068737887,
          0.049537287171646245,
          0.049740315709794175,
          0.04409017186989424,
          0.04270555648527885,
          0.04229477683111767,
          0.042399605606678145,
          0.03687023844950563,
          0.038596338030586624,
          0.04346710254855981,
          0.04512158229093246,
          0.04493553997782354,
          0.04735069325785743,
          0.0480562779359889,
          0.046812472110968964,
          0.04760954259100909,
          0.047475217439036876,
          0.05477228312575003,
          0.04886068786832175,
          0.043211762304007445,
          0.041123340585574736,
          0.039408877562370735,
          0.03691761882111199,
          0.04028769080339328,
          0.03944203174547008,
          0.039314244411003264,
          0.04141980848278583,
          0.036739123455738563,
          0.04162062662076575,
          0.04263544850932036,
          0.04438251293029286,
          0.046656891265136315,
          0.04882506622742892,
          0.046036429863792555,
          0.05160931923762909,
          0.05373943495130838,
          0.049230742286123494,
          0.053948529549201964,
          0.05112016710704642,
          0.05319477410327468,
          0.053672650209469375,
          0.054829027165846325,
          0.056459211612506346,
          0.05484102979432452,
          0.052085251603878245,
          0.05178423018112146,
          0.057125568930380996,
          0.05393513193704632,
          0.051636463003497925,
          0.04677537599109512,
          0.04425780575310216,
          0.0415404296426226,
          0.04129312963938054,
          0.04420075103692771,
          0.04607621340901423,
          0.042303708300995585,
          0.03987156705043328,
          0.03884172584944639,
          0.03665057540696852,
          0.03749539579126258,
          0.04142160938349559,
          0.042574436222108804,
          0.045522291060049326,
          0.041339966105189904,
          0.034401126679660846,
          0.036726399928729656,
          0.03857560439635518,
          0.04198603385163589,
          0.0435830590232606,
          0.047664469221649894,
          0.04556520840964636,
          0.04709210837429818,
          0.04514014402507245,
          0.04675024034496193,
          0.05007027792717302,
          0.05099354836742459,
          0.053761290214578206,
          0.048071744439444626,
          0.048100360293460945,
          0.04842466044938881,
          0.04939117633641441,
          0.045140624548088384,
          0.04008493339492178,
          0.040164194635058256,
          0.037371695388751354,
          0.03588598110303707,
          0.03124250790956387,
          0.03064437706844238,
          0.03114593910793545,
          0.029525344463856084,
          0.03377164755609683,
          0.038698141373408365,
          0.040198141373408366,
          0.045876660377383506,
          0.046795634912237316,
          0.04582412994661471,
          0.042253386781039216,
          0.049102893667414035,
          0.04809569060227993,
          0.046055955659979296,
          0.04087553840061467,
          0.034503104430683745,
          0.03318492261250193,
          0.0277180122320757,
          0.029321746337982672,
          0.029049265923023686,
          0.030487119569155036,
          0.026497414055370573,
          0.027650141328097844,
          0.02925938786917396,
          0.036765562704296165,
          0.04102038716437527,
          0.039706101450089556,
          0.03944183718582529,
          0.03800999745135398,
          0.03693969711764987,
          0.03832520966559195,
          0.03769637358938745,
          0.035302891599679045,
          0.034082597449477704,
          0.024073304111236992,
          0.020440399787096712,
          0.02064357439027132,
          0.021879598427627208,
          0.023364905162933942,
          0.027129190877219655,
          0.03186533530807741,
          0.030898662341404447,
          0.03509885800578769,
          0.03952746424675727,
          0.04224151106949974,
          0.04528887546980532,
          0.04666149973881116,
          0.044161183371742393,
          0.04115455677288278,
          0.041073265458832844,
          0.03419575058131796,
          0.03501669273559345,
          0.033217953542577304,
          0.027333008823687627,
          0.030059748395078405,
          0.029401933100285788,
          0.03409790421912061,
          0.041013472837880684,
          0.043926212236470114,
          0.0452311119093743,
          0.04899192396366463,
          0.05364818833434178,
          0.0537686770561463,
          0.05246438142037505,
          0.05233188727453405,
          0.05411945046848633,
          0.050498762728553304,
          0.04504230625932594,
          0.04288684841413457,
          0.04831836954567296,
          0.046646808396423024,
          0.044551731721685334,
          0.04622808749671199,
          0.04749237982642489,
          0.04886026623818226,
          0.0457449721205352,
          0.04521213597977827,
          0.050227750196479445,
          0.053285972188748976,
          0.045971049654925364,
          0.04424469946572688,
          0.04167353987780962,
          0.038115581255458456,
          0.03973260387248108,
          0.03586275159632793,
          0.033916084929661264,
          0.03601194370179526,
          0.03790520045283602,
          0.041335392770097304,
          0.03746574858409104,
          0.03877142195061632,
          0.03740212943163572,
          0.041562933959632495,
          0.04435069279925834,
          0.050549115851519465,
          0.05481895712136074,
          0.05255550158955078,
          0.04608104508793972,
          0.042332796822397496,
          0.04844964435842311,
          0.05239838814337379,
          0.05537817857152488,
          0.052568942419151464,
          0.05259121820509423,
          0.050927921624247384,
          0.04804419146551723,
          0.04909838726971304,
          0.04856249927710862,
          0.04782359552488086,
          0.04573311236521961,
          0.045838441403996934,
          0.04519709081909796,
          0.0465585435102608,
          0.04382525566732133,
          0.037676110504318246,
          0.03654185124505899,
          0.03722664194455557,
          0.039166256496670125,
          0.03849370432973594,
          0.0402522982318081,
          0.037072243918305506,
          0.03692058812686477,
          0.033567224714231465,
          0.03256319383358652,
          0.0366637671732903,
          0.0392638691526163,
          0.03638851901256028,
          0.03265614721768849,
          0.03518366601468097,
          0.03115039501577182,
          0.030121029936406744,
          0.027039660688370826,
          0.02840708207201863,
          0.02946308929875756,
          0.0277657417655054,
          0.02516563978617939,
          0.026490135678636444,
          0.03137990729942073,
          0.03274612283826785,
          0.031711690633762515,
          0.02953391285598474,
          0.03498238120554202,
          0.035939377542538356,
          0.03729526979843061,
          0.035840573403743706,
          0.0377385051016754,
          0.04226984189876696,
          0.03871748286539527,
          0.039646484853000714,
          0.04387075491950379,
          0.05019428433126849,
          0.04771332682824537,
          0.048618754733673275,
          0.05044937436280037,
          0.05081165576184647,
          0.052039432391581486,
          0.04674445162901056,
          0.04934356427528992,
          0.04672194840002415,
          0.044258618251911394,
          0.04370365166134109,
          0.042812009962841034,
          0.04456783659497951,
          0.045540832957703704,
          0.04660274941962017,
          0.04725654132721594,
          0.04873882665514022,
          0.05530813774199046,
          0.05313018331697722,
          0.057042225585856456,
          0.051525514616513904,
          0.050588756622437205,
          0.05295039030775904,
          0.04755245613408957,
          0.0455145912466834,
          0.05031787035905956,
          0.053095502528890136,
          0.04563728019163206,
          0.04719322323144607,
          0.04485485246015136,
          0.04790776251306142,
          0.04841076638693334,
          0.04459098877892044,
          0.04478405558053987,
          0.04851029982965337,
          0.0394215805798484,
          0.03629886310316781,
          0.03747524179387636,
          0.03589613273089633,
          0.03536054557459979,
          0.035664385820375524,
          0.039886091182682396,
          0.03636503184985835,
          0.04022767629500178,
          0.040612956606954125,
          0.04228175053962153,
          0.043503698591569585,
          0.04450220466066389,
          0.04700177176023099,
          0.043721142024973306,
          0.04057726479352952,
          0.03640140591946406,
          0.03663157948421707,
          0.032800648939208595,
          0.03207983744039198,
          0.03427745039861875,
          0.034968391278215,
          0.032553013631853076,
          0.03451524055221954,
          0.03641617103935692,
          0.03987922389804084,
          0.04065355009425784,
          0.046324920931049236,
          0.044597825414480034,
          0.04055743515209489,
          0.040020671867070735,
          0.03760124237463804,
          0.03675993324372495,
          0.03319573720103539,
          0.03348625858646618,
          0.03447873464525025,
          0.03950991494643055,
          0.041365444053901405,
          0.0427285734754578,
          0.044534538732750484,
          0.04686771502814427,
          0.04858818225060637,
          0.05147487009934822,
          0.05464421484122086,
          0.05666189451399113,
          0.05408705856089472,
          0.046782205670621274,
          0.04900215372494834,
          0.047639024303391946,
          0.04613411239302416,
          0.04309012413181842,
          0.04283166364586013,
          0.04175142138297562,
          0.04012364791851737,
          0.040745226018356354,
          0.04164147480155757,
          0.045743919403055736,
          0.04010138157380111,
          0.040472932631500175,
          0.04497894216140559,
          0.04737551764474578,
          0.04755374986029143,
          0.049537176279823326,
          0.04595082087797879,
          0.044464253938431876,
          0.0517051824543604,
          0.047898388463933406,
          0.04443873975748973,
          0.046176807626858885,
          0.04136974475002857,
          0.03824652091504003,
          0.036873500734557155,
          0.03685866915420834,
          0.037302351258267794,
          0.035344767525403165,
          0.029244129712112744,
          0.03050253660576554,
          0.032053098403518346,
          0.03496169854658409,
          0.04287178059926101,
          0.04387582372594564,
          0.043097273747395665,
          0.03784594915547701,
          0.04072363866226284,
          0.04114277208139626,
          0.03889040972766782,
          0.03761672605471956,
          0.0421268314464039,
          0.03803296327355897,
          0.03478055317855402,
          0.0342907957661551,
          0.03600347272883206,
          0.04033987897069166,
          0.042414716063423494,
          0.03985441343770031,
          0.04289577080307636,
          0.047890737191008816,
          0.04102741542505547,
          0.04208671051141241,
          0.0384640368547938,
          0.039800091276562505
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Moving averages over f1 while learning with window 10 on dataset syn_ds_4"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "batches"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "accuracy"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#moving averages\n",
    "title = \"Moving averages over f1 while learning with window {} on dataset {}\".format(n_window, dataset_name)\n",
    "col_names = [\"Pure\",\"FIRES\", \"OFS\", \"OFSSGD\", \"FSDS\", \"random\"]\n",
    "d = {\"Pure\":pure_f1, \"FIRES\":fires_f1, \"OFS\":ofs_f1, \n",
    "\"OFSSGD\":ofssgd_f1, \"FSDS\":fsds_f1, \"random\":random_f1}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y=col_names, title=title, labels={\"index\":\"batches\", \"value\":\"accuracy\"}, color_discrete_map={\"Pure\":\"blue\",'FIRES': 'red', \n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\", \"random\":\"cyan\"})\n",
    "fig.write_image(\"{}/f1.{}\".format(folder, export_type))\n",
    "f1_trace = fig['data']\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean values\n",
    "csv_name = \"{}/f1_avg.csv\".format(folder)\n",
    "df.mean().to_csv(csv_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=FIRES<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "line": {
          "color": "red",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FIRES",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.48232804232804255,
          0.5424338624338627,
          0.593650793650794,
          0.6478306878306882,
          0.6884656084656088,
          0.7092063492063495,
          0.7108994708994714,
          0.7121693121693126,
          0.7164021164021168,
          0.6998941798941802,
          0.7024338624338629,
          0.7108994708994714,
          0.7227513227513229,
          0.7274074074074077,
          0.7405291005291008,
          0.7583068783068786,
          0.7714285714285717,
          0.7845502645502649,
          0.8082539682539687,
          0.8179894179894184,
          0.8268783068783073,
          0.826455026455027,
          0.8112169312169316,
          0.8061375661375665,
          0.8116402116402122,
          0.8179894179894184,
          0.8150264550264554,
          0.8179894179894185,
          0.8226455026455032,
          0.8289947089947095,
          0.8374603174603179,
          0.8404232804232808,
          0.8412698412698417,
          0.8438095238095242,
          0.8438095238095242,
          0.8433862433862438,
          0.8391534391534397,
          0.8463492063492067,
          0.8467724867724872,
          0.8518518518518523,
          0.8565079365079369,
          0.8670899470899475,
          0.8755555555555559,
          0.8797883597883601,
          0.8764021164021167,
          0.8823280423280426,
          0.888677248677249,
          0.893756613756614,
          0.8920634920634923,
          0.8844444444444447,
          0.8861375661375664,
          0.8869841269841272,
          0.8848677248677251,
          0.8797883597883601,
          0.8704761904761908,
          0.8704761904761908,
          0.8632804232804236,
          0.8603174603174607,
          0.8535449735449739,
          0.8526984126984131,
          0.855661375661376,
          0.8552380952380956,
          0.8560846560846564,
          0.8552380952380956,
          0.8497354497354501,
          0.8526984126984131,
          0.8611640211640216,
          0.8713227513227516,
          0.8742857142857146,
          0.8768253968253972,
          0.8780952380952384,
          0.8780952380952384,
          0.8751322751322754,
          0.8793650793650797,
          0.8844444444444447,
          0.8946031746031748,
          0.9030687830687835,
          0.9051851851851854,
          0.913650793650794,
          0.8975661375661378,
          0.8924867724867728,
          0.8831746031746036,
          0.8734391534391538,
          0.8700529100529104,
          0.8662433862433866,
          0.8692063492063495,
          0.8789417989417992,
          0.8810582010582013,
          0.8874074074074076,
          0.8979894179894182,
          0.8984126984126987,
          0.8958730158730163,
          0.897566137566138,
          0.893756613756614,
          0.8886772486772491,
          0.8831746031746035,
          0.8802116402116406,
          0.8725925925925929,
          0.8730158730158734,
          0.874708994708995,
          0.8759788359788363,
          0.8814814814814818,
          0.8861375661375664,
          0.8823280423280426,
          0.8734391534391538,
          0.8679365079365082,
          0.8679365079365082,
          0.8768253968253972,
          0.8764021164021167,
          0.8793650793650797,
          0.8810582010582013,
          0.888677248677249,
          0.8967195767195769,
          0.9013756613756617,
          0.9064550264550266,
          0.9047619047619051,
          0.9056084656084659,
          0.9064550264550266,
          0.9022222222222225,
          0.9001058201058203,
          0.8992592592592595,
          0.9026455026455029,
          0.8958730158730162,
          0.8929100529100532,
          0.8882539682539685,
          0.893756613756614,
          0.8992592592592595,
          0.9034920634920637,
          0.900529100529101,
          0.9077248677248679,
          0.913650793650794,
          0.9183068783068786,
          0.9144973544973548,
          0.9119576719576723,
          0.9060317460317462,
          0.9115343915343918,
          0.9187301587301591,
          0.9200000000000004,
          0.9263492063492067,
          0.9284656084656085,
          0.9178835978835982,
          0.916613756613757,
          0.9195767195767199,
          0.9200000000000004,
          0.9259259259259263,
          0.9242328042328045,
          0.9250793650793652,
          0.9284656084656088,
          0.9255026455026456,
          0.9276190476190479,
          0.9305820105820108,
          0.9369312169312172,
          0.9441269841269844,
          0.9483597883597886,
          0.9492063492063494,
          0.9449735449735452,
          0.9398941798941801,
          0.9276190476190479,
          0.9255026455026458,
          0.9208465608465611,
          0.9081481481481485,
          0.9009523809523814,
          0.8979894179894183,
          0.8916402116402119,
          0.8933333333333335,
          0.8984126984126987,
          0.8992592592592596,
          0.9001058201058205,
          0.9001058201058205,
          0.9039153439153441,
          0.9128042328042332,
          0.9140740740740744,
          0.9115343915343919,
          0.9123809523809525,
          0.9098412698412702,
          0.9106878306878309,
          0.9106878306878309,
          0.9022222222222225,
          0.8941798941798946,
          0.8891005291005294,
          0.8869841269841272,
          0.8878306878306881,
          0.8874074074074076,
          0.8933333333333335,
          0.8975661375661378,
          0.9039153439153441,
          0.9111111111111114,
          0.9132275132275136,
          0.9204232804232807,
          0.9238095238095241,
          0.926772486772487,
          0.9238095238095241,
          0.9280423280423283,
          0.9288888888888892,
          0.920846560846561,
          0.9195767195767199,
          0.9119576719576722,
          0.907724867724868,
          0.8979894179894182,
          0.8967195767195769,
          0.8946031746031751,
          0.8929100529100533,
          0.8869841269841272,
          0.8823280423280426,
          0.8810582010582013,
          0.8780952380952384,
          0.8814814814814818,
          0.8865608465608469,
          0.893756613756614,
          0.8996825396825399,
          0.8984126984126987,
          0.8988359788359792,
          0.8992592592592595,
          0.9051851851851854,
          0.905608465608466,
          0.9030687830687832,
          0.9013756613756616,
          0.9022222222222225,
          0.9030687830687835,
          0.9001058201058203,
          0.9043386243386247,
          0.9030687830687832,
          0.9102645502645507,
          0.9064550264550266,
          0.9111111111111113,
          0.9132275132275136,
          0.9128042328042332,
          0.9170370370370372,
          0.9221164021164022,
          0.9229629629629631,
          0.9255026455026456,
          0.9348148148148151,
          0.9335449735449738,
          0.92973544973545,
          0.9322751322751326,
          0.9259259259259263,
          0.9225396825396829,
          0.9178835978835982,
          0.9170370370370373,
          0.9174603174603178,
          0.9233862433862435,
          0.9259259259259263,
          0.9305820105820107,
          0.9394708994708997,
          0.9369312169312172,
          0.940740740740741,
          0.9437037037037039,
          0.9360846560846563,
          0.935661375661376,
          0.9343915343915347,
          0.9322751322751326,
          0.9280423280423283,
          0.9276190476190479,
          0.9280423280423283,
          0.9339682539682541,
          0.9348148148148151,
          0.9293121693121696,
          0.9208465608465611,
          0.9115343915343919,
          0.9098412698412702,
          0.9043386243386247,
          0.9060317460317462,
          0.9081481481481484,
          0.9060317460317462,
          0.9081481481481484,
          0.912804232804233,
          0.9183068783068785,
          0.9271957671957675,
          0.9314285714285715,
          0.9390476190476194,
          0.9424338624338626,
          0.9386243386243389,
          0.9314285714285717,
          0.9276190476190479,
          0.9233862433862436,
          0.9225396825396829,
          0.9255026455026458,
          0.925925925925926,
          0.9314285714285717,
          0.9318518518518522,
          0.9348148148148151,
          0.9310052910052913,
          0.9255026455026456,
          0.9233862433862436,
          0.9233862433862436,
          0.9314285714285715,
          0.9386243386243389,
          0.9386243386243389,
          0.9420105820105821,
          0.9462433862433864,
          0.9453968253968257,
          0.9513227513227516,
          0.9525925925925928,
          0.9513227513227516,
          0.9513227513227516,
          0.9504761904761907,
          0.9496296296296298,
          0.9462433862433864,
          0.9441269841269844,
          0.9475132275132278,
          0.9530158730158732,
          0.956825396825397,
          0.9593650793650795,
          0.9576719576719579,
          0.9525925925925928,
          0.9534391534391536,
          0.9530158730158732,
          0.951746031746032,
          0.9521693121693123,
          0.9559788359788362,
          0.9564021164021166,
          0.9602116402116404,
          0.9576719576719579,
          0.9589417989417991,
          0.9610582010582013,
          0.9602116402116404,
          0.9564021164021166,
          0.956825396825397,
          0.9559788359788362,
          0.954708994708995,
          0.9496296296296298,
          0.9437037037037039,
          0.9403174603174606,
          0.9331216931216934,
          0.9301587301587304,
          0.9238095238095241,
          0.9187301587301591,
          0.9191534391534395,
          0.9128042328042332,
          0.916613756613757,
          0.9170370370370373,
          0.9212698412698416,
          0.9229629629629633,
          0.9216931216931219,
          0.9225396825396827,
          0.9276190476190478,
          0.9322751322751324,
          0.9352380952380955,
          0.9352380952380955,
          0.9365079365079367,
          0.9335449735449738,
          0.937777777777778,
          0.9424338624338626,
          0.945820105820106,
          0.9513227513227516,
          0.9580952380952383,
          0.9644444444444447,
          0.9737566137566139,
          0.9614814814814816,
          0.9589417989417991,
          0.9525925925925928,
          0.9492063492063494,
          0.9492063492063494,
          0.9513227513227516,
          0.9513227513227516,
          0.9492063492063493,
          0.947936507936508,
          0.9475132275132278,
          0.9445502645502648,
          0.9466666666666669,
          0.9504761904761907,
          0.9538624338624341,
          0.9513227513227516,
          0.9479365079365082,
          0.9420105820105823,
          0.9411640211640214,
          0.9441269841269844,
          0.9441269841269844,
          0.9445502645502648,
          0.9466666666666669,
          0.9500529100529103,
          0.9525925925925928,
          0.9559788359788362,
          0.9572486772486775,
          0.9572486772486775,
          0.95978835978836,
          0.9682539682539684,
          0.9733333333333335,
          0.9771428571428573,
          0.9779894179894181,
          0.9805291005291006,
          0.9775661375661376,
          0.9674074074074076,
          0.9593650793650795,
          0.9525925925925928,
          0.9470899470899473,
          0.9453968253968257,
          0.9441269841269844,
          0.9462433862433864,
          0.9483597883597886,
          0.9576719576719579,
          0.9564021164021166,
          0.9534391534391536,
          0.9466666666666669,
          0.9432804232804235,
          0.9420105820105823,
          0.9403174603174606,
          0.9382010582010585,
          0.9386243386243389,
          0.93989417989418,
          0.9386243386243389,
          0.9310052910052913,
          0.9305820105820108,
          0.9238095238095241,
          0.9263492063492067,
          0.932698412698413,
          0.9386243386243389,
          0.9441269841269843,
          0.9479365079365082,
          0.9441269841269844,
          0.9508994708994711,
          0.9525925925925928,
          0.9475132275132278,
          0.9398941798941801,
          0.9382010582010585,
          0.935661375661376,
          0.9335449735449738,
          0.9310052910052913,
          0.9288888888888892,
          0.9271957671957675,
          0.9276190476190479,
          0.9280423280423283,
          0.9365079365079367,
          0.9369312169312172,
          0.9365079365079367,
          0.9365079365079367,
          0.9339682539682542,
          0.9314285714285717,
          0.9331216931216934,
          0.9339682539682542,
          0.9352380952380955,
          0.9437037037037039,
          0.9492063492063494,
          0.9483597883597886,
          0.948783068783069,
          0.9500529100529103,
          0.954708994708995,
          0.9593650793650795,
          0.9576719576719579,
          0.9504761904761907
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFS<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "line": {
          "color": "purple",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFS",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.44841557813255944,
          0.5131833575229803,
          0.5487421383647798,
          0.5809143686502178,
          0.6071601354620224,
          0.6342525399129173,
          0.6384857281083697,
          0.6418722786647314,
          0.63933236574746,
          0.6414489598451862,
          0.6389090469279148,
          0.6346758587324626,
          0.6414489598451864,
          0.6469521044992743,
          0.6465287856797293,
          0.6533018867924529,
          0.660498306724722,
          0.6706579583938077,
          0.6897073052733433,
          0.6858974358974361,
          0.6922472181906145,
          0.6918238993710693,
          0.6918238993710694,
          0.6901306240928884,
          0.6897073052733432,
          0.6939404934687955,
          0.6956337687469765,
          0.6985970004837929,
          0.7079100145137881,
          0.7167997097242381,
          0.7201862602806,
          0.7214562167392355,
          0.7163763909046927,
          0.7134131591678762,
          0.7180696661828737,
          0.7070633768746976,
          0.6998669569424285,
          0.7066400580551523,
          0.7041001451378809,
          0.7100266086115143,
          0.7155297532656025,
          0.7303459119496857,
          0.7396589259796807,
          0.7502418964683117,
          0.7510885341074021,
          0.7481253023705854,
          0.750665215287857,
          0.750665215287857,
          0.750241896468312,
          0.765058055152395,
          0.7714078374455735,
          0.7735244315432995,
          0.7862239961296565,
          0.7917271407837447,
          0.7879172714078376,
          0.787070633768747,
          0.7891872278664732,
          0.776064344460571,
          0.7629414610546686,
          0.7396589259796804,
          0.7299225931301403,
          0.7142597968069666,
          0.7079100145137882,
          0.7193396226415096,
          0.7316158684083214,
          0.7396589259796807,
          0.736272375423319,
          0.7379656507014998,
          0.7350024189646833,
          0.7417755200774071,
          0.7544750846637641,
          0.7675979680696663,
          0.7671746492501211,
          0.7532051282051285,
          0.7612481857764877,
          0.7570149975810354,
          0.7608248669569426,
          0.7544750846637641,
          0.7523584905660378,
          0.7515118529269473,
          0.7464320270924047,
          0.7570149975810354,
          0.7544750846637639,
          0.7578616352201258,
          0.7629414610546686,
          0.7709845186260279,
          0.7752177068214806,
          0.773947750362845,
          0.7718311562651186,
          0.7709845186260281,
          0.7663280116110306,
          0.7527818093855831,
          0.740082244799226,
          0.731615868408321,
          0.7333091436865021,
          0.7426221577164974,
          0.7455853894533142,
          0.7574383164005808,
          0.7718311562651189,
          0.7824141267537496,
          0.7866473149492016,
          0.7790275761973873,
          0.7680212868892113,
          0.7430454765360427,
          0.7362723754233189,
          0.7333091436865024,
          0.7223028543783263,
          0.7197629414610551,
          0.7112965650701503,
          0.6981736816642479,
          0.7053701015965167,
          0.7066400580551524,
          0.7066400580551525,
          0.7062167392356072,
          0.7028301886792453,
          0.7091799709724238,
          0.7074866956942429,
          0.71129656507015,
          0.7100266086115143,
          0.714683115626512,
          0.7239961296565071,
          0.7239961296565072,
          0.7193396226415094,
          0.712566521528786,
          0.7117198838896951,
          0.7163763909046929,
          0.7252660861151428,
          0.7294992743105951,
          0.7455853894533142,
          0.7591315916787614,
          0.7697145621673924,
          0.7862239961296567,
          0.7841074020319307,
          0.7828374455732948,
          0.7731011127237545,
          0.757861635220126,
          0.7519351717464926,
          0.7379656507014998,
          0.7294992743105952,
          0.7269593613933237,
          0.7400822447992261,
          0.7477019835510403,
          0.7595549104983069,
          0.7540517658442188,
          0.750665215287857,
          0.7527818093855831,
          0.7443154329946786,
          0.7409288824383166,
          0.7396589259796807,
          0.7375423318819548,
          0.7468553459119499,
          0.7464320270924044,
          0.7426221577164974,
          0.7282293178519593,
          0.718916303821964,
          0.7218795355587809,
          0.7142597968069667,
          0.7176463473633284,
          0.7155297532656023,
          0.7079100145137881,
          0.7045234639574263,
          0.7074866956942429,
          0.7125665215287859,
          0.7091799709724239,
          0.7223028543783261,
          0.7341557813255928,
          0.743892114175133,
          0.7553217223028544,
          0.7629414610546688,
          0.7595549104983066,
          0.7684446057087565,
          0.7519351717464924,
          0.7375423318819546,
          0.7303459119496857,
          0.7278059990324142,
          0.718492985002419,
          0.7227261731978714,
          0.7189163038219643,
          0.715106434446057,
          0.7096032897919692,
          0.7024068698597001,
          0.6939404934687954,
          0.7108732462506049,
          0.7299225931301406,
          0.7472786647314951,
          0.7591315916787619,
          0.7646347363328497,
          0.7637880986937592,
          0.7570149975810353,
          0.7455853894533139,
          0.7316158684083213,
          0.7341557813255928,
          0.7341557813255928,
          0.7299225931301402,
          0.7299225931301403,
          0.7235728108369619,
          0.7189163038219643,
          0.7197629414610546,
          0.7201862602806,
          0.7282293178519595,
          0.7350024189646831,
          0.747278664731495,
          0.7629414610546688,
          0.7599782293178521,
          0.7625181422351235,
          0.7527818093855831,
          0.7464320270924045,
          0.7447387518142236,
          0.7451620706337688,
          0.7548984034833093,
          0.7553217223028547,
          0.7587082728592164,
          0.7540517658442188,
          0.7544750846637636,
          0.7506652152878568,
          0.7392356071601357,
          0.7379656507015,
          0.743468795355588,
          0.7413522012578617,
          0.7472786647314947,
          0.7460087082728591,
          0.7578616352201256,
          0.7561683599419449,
          0.7527818093855831,
          0.7434687953555879,
          0.7265360425737784,
          0.7104499274310594,
          0.6981736816642478,
          0.6825108853410741,
          0.664731494920174,
          0.6672714078374454,
          0.6757377842283502,
          0.6858974358974358,
          0.6918238993710691,
          0.7057934204160621,
          0.7172230285437834,
          0.7248427672955976,
          0.7311925495887762,
          0.7515118529269472,
          0.7544750846637641,
          0.7582849540396712,
          0.7548984034833092,
          0.7455853894533142,
          0.7299225931301403,
          0.7299225931301402,
          0.7358490566037735,
          0.7375423318819546,
          0.7358490566037739,
          0.7417755200774071,
          0.7574383164005809,
          0.7671746492501212,
          0.7794508950169329,
          0.7841074020319304,
          0.7891872278664733,
          0.7836840832123851,
          0.7671746492501211,
          0.7620948234155784,
          0.7595549104983069,
          0.7561683599419452,
          0.7625181422351236,
          0.7731011127237544,
          0.7790275761973877,
          0.7786042573778426,
          0.7743710691823901,
          0.7781809385582972,
          0.7794508950169331,
          0.7794508950169332,
          0.7913038219641998,
          0.8078132559264639,
          0.8137397194000972,
          0.8128930817610065,
          0.8141630382196422,
          0.7959603289791971,
          0.7925737784228353,
          0.7896105466860186,
          0.7798742138364779,
          0.7752177068214805,
          0.7637880986937591,
          0.7527818093855831,
          0.7434687953555879,
          0.7354257377842285,
          0.7282293178519593,
          0.7371190130624095,
          0.7481253023705855,
          0.7460087082728594,
          0.7320391872278664,
          0.7333091436865021,
          0.7519351717464926,
          0.7684446057087567,
          0.7849540396710211,
          0.7904571843251091,
          0.7862239961296569,
          0.7845307208514758,
          0.7841074020319305,
          0.7777576197387519,
          0.776064344460571,
          0.7743710691823902,
          0.768444605708757,
          0.7625181422351235,
          0.7608248669569426,
          0.7701378809869378,
          0.7671746492501212,
          0.7553217223028547,
          0.7574383164005809,
          0.7523584905660381,
          0.7464320270924047,
          0.7481253023705856,
          0.7307692307692308,
          0.7235728108369619,
          0.7146831156265118,
          0.6994436381228835,
          0.6791243347847121,
          0.6816642477019835,
          0.6816642477019834,
          0.6816642477019835,
          0.6867440735365264,
          0.6943638122883407,
          0.701983551040155,
          0.6956337687469764,
          0.698597000483793,
          0.7091799709724238,
          0.7163763909046929,
          0.7231494920174166,
          0.7358490566037735,
          0.7350024189646833,
          0.7460087082728594,
          0.7477019835510403,
          0.7451620706337686,
          0.7481253023705855,
          0.7455853894533142,
          0.7328858248669572,
          0.7303459119496857,
          0.7278059990324142,
          0.7375423318819546,
          0.7362723754233189,
          0.747278664731495,
          0.7540517658442191,
          0.7548984034833094,
          0.7663280116110306,
          0.7557450411223998,
          0.7502418964683116,
          0.7506652152878567,
          0.7548984034833092,
          0.7591315916787615,
          0.7396589259796807,
          0.7299225931301404,
          0.7290759554910499,
          0.7345791001451379,
          0.7426221577164974,
          0.7515118529269472,
          0.7468553459119498,
          0.7515118529269472,
          0.748971940009676,
          0.7455853894533142,
          0.7409288824383166,
          0.7193396226415096,
          0.7045234639574263,
          0.7032535074987906,
          0.7070633768746979,
          0.6985970004837929,
          0.701983551040155,
          0.7151064344460575,
          0.7248427672955978,
          0.7167997097242382,
          0.7011369134010647,
          0.6918238993710693,
          0.6854741170778907,
          0.6875907111756169,
          0.7108732462506048,
          0.7261127237542334,
          0.7421988388969524,
          0.7620948234155784,
          0.7794508950169329,
          0.7807208514755687,
          0.7794508950169328,
          0.7646347363328496,
          0.7646347363328494,
          0.7625181422351235,
          0.7591315916787618,
          0.7493952588292212,
          0.7392356071601356,
          0.7417755200774071,
          0.7366956942428642,
          0.7337324625060477,
          0.7388122883405905,
          0.7413522012578617,
          0.7464320270924045,
          0.7493952588292212,
          0.748971940009676,
          0.7481253023705855,
          0.7519351717464926,
          0.7570149975810356,
          0.7523584905660378,
          0.7523584905660377,
          0.743892114175133,
          0.7286526366715047,
          0.7248427672955975,
          0.736272375423319,
          0.7498185776487666,
          0.7642114175133047,
          0.7701378809869381,
          0.7743710691823901,
          0.7794508950169328,
          0.7701378809869376,
          0.7587082728592165,
          0.7532051282051283,
          0.7502418964683116,
          0.7472786647314947,
          0.7362723754233187,
          0.7066400580551522,
          0.7011369134010644,
          0.7011369134010643,
          0.691400580551524,
          0.6888606676342525,
          0.6909772617319787,
          0.6892839864537977,
          0.6880140299951621,
          0.688014029995162,
          0.7087566521528786,
          0.7286526366715048,
          0.7438921141751332,
          0.7510885341074024,
          0.7472786647314951,
          0.7417755200774069,
          0.7426221577164976,
          0.7328858248669572,
          0.7184929850024192,
          0.7303459119496857,
          0.7417755200774071,
          0.7591315916787614,
          0.7604015481373974,
          0.7781809385582973,
          0.7925737784228353,
          0.7980769230769234,
          0.7993468795355589,
          0.80104015481374,
          0.7989235607160137,
          0.7807208514755684,
          0.7671746492501209,
          0.7540517658442185
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=OFSSGD<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "line": {
          "color": "yellow",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFSSGD",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.007543677550793836,
          0.008921569637373285,
          0.014962697481999267,
          0.0284691792488242,
          0.027047583279579977,
          0.016286007415581213,
          0.032466628646429595,
          0.032466628646429595,
          0.032780930462005094,
          0.05624316538843177,
          0.04499789164153296,
          0.02220267690313817,
          0.026687373860396695,
          0.024625279522711145,
          0.00834504484855294,
          0.005859494414990436,
          0.002794785355606238,
          -0.006526676824025313,
          -0.00522289193436653,
          -0.00522289193436653,
          -0.008124324938001729,
          0.00205382876174628,
          0.005655301964193858,
          0.0064560530003441,
          0.006456053000344101,
          0.0012974089181681796,
          0.0017391749730272857,
          0.003063237125025467,
          0.015345309789083566,
          0.03070006718461832,
          0.02877631255192217,
          0.028290324558585194,
          0.004212214656727281,
          -0.0012255135592902915,
          -0.003917626394628213,
          0.010036613116126102,
          0.004588490879473519,
          0.0045884908794735215,
          0.002993883043710691,
          0.011935622982899432,
          0.04294296104115345,
          0.04493706952464569,
          0.024116824709950937,
          0.013457596104240828,
          0.039933822091198216,
          0.009449825872575809,
          0.009449825872575805,
          0.01057429330104202,
          0.03381465652961456,
          0.017988080347811748,
          0.03817637161172094,
          0.0640834138681645,
          0.07953943134631847,
          0.08641196251250262,
          0.08612089306566094,
          0.08612089306566094,
          0.0576276562428032,
          0.058761291405698086,
          0.09312142229508868,
          0.09255320712299916,
          0.041196496051772884,
          0.049363131202027864,
          0.01623950189792099,
          0.016239501897920994,
          0.009202013488953019,
          0.010725006569713112,
          0.010725006569713109,
          0.023674613616406274,
          0.04407407664699166,
          0.03997659110955894,
          0.04875272902018252,
          0.07868658651148411,
          0.07897211835839021,
          0.0789721183583902,
          0.07897211835839021,
          0.03330096381084797,
          0.07974336128435189,
          0.03298628657535649,
          0.013088399184568526,
          0.014059684976225886,
          0.014059684976225886,
          -0.01136444801616361,
          -0.010273708199982821,
          -0.010273708199982825,
          0.013973961694150765,
          0.013973961694150765,
          -0.006813878348254935,
          -0.005961039109716197,
          0.0075020927198217,
          0.01988097676523245,
          0.01925138491369819,
          0.019880976765232452,
          0.026436471366286057,
          0.027395737903182,
          0.0037715801108724302,
          0.029678622367315995,
          0.02877825385522386,
          0.03485545896179866,
          0.048204221098575736,
          0.048204221098575736,
          0.04914033018353473,
          0.02947158205409401,
          0.029882056769689132,
          0.029431093042512336,
          0.029431093042512336,
          0.028598683102106073,
          0.023302663129201703,
          0.02531456248078094,
          0.0009690691389328817,
          -0.0010227310174760486,
          0.0036460312203420923,
          0.0036460312203420923,
          -0.001731914336196595,
          -0.0011221829719328237,
          -0.001731914336196595,
          0.007449599976440069,
          0.009229864957874962,
          0.01126480053247525,
          0.0025612539190730615,
          0.002083286219838591,
          -0.0006763050290073315,
          0.009946245086501257,
          0.005874875106588918,
          0.018828396234810692,
          0.011668012604775905,
          -0.0008850300299621,
          -0.0074359237311273745,
          -0.007818645230125815,
          -0.007818645230125815,
          -0.007818645230125815,
          -0.008346667807390042,
          -0.008346667807390042,
          -0.00781864523012581,
          -0.00781864523012581,
          -0.009761791619848905,
          -0.009189366167731024,
          -0.008772323663870398,
          -0.006583466664943537,
          0.0022407373550978613,
          0.009908010394840232,
          0.012587203673409684,
          0.01869671889992457,
          0.018696718899924566,
          0.01731492964485682,
          0.017910227995484248,
          0.04210902287060486,
          0.0259418337181607,
          0.0259418337181607,
          0.04521503327910098,
          0.02862983417746544,
          0.029375857548573164,
          0.01642233642035139,
          0.015616542032021345,
          0.02543028268441903,
          0.024613191682417164,
          0.02461319168241716,
          0.024613191682417157,
          0.006318754460420361,
          0.013369844317001804,
          0.012723706159871737,
          0.028428971451281843,
          0.028917322624842944,
          0.022393571646069494,
          0.013212057333432833,
          0.006603878589166959,
          0.014769371419055117,
          0.039379878907816385,
          0.07963351267067692,
          0.07963351267067692,
          0.13854667760681572,
          0.22886667582004058,
          0.22432482309315546,
          0.3367414534338458,
          0.3367414534338458,
          0.2245669558072475,
          0.23252509128121854,
          0.14276966731139445,
          0.07440983434422116,
          0.07440983434422116,
          0.027950162407643624,
          0.0043849780787068365,
          -0.007818645230125817,
          -0.010913428648833259,
          -0.008843644199545544,
          -0.008296858751987438,
          -0.009359605896511039,
          -0.00935960589651104,
          -0.009359605896511039,
          0.014782417704182631,
          0.015648093192123992,
          0.028601614320345792,
          0.015648093192123992,
          0.016183823278142054,
          -0.0019733943303950076,
          -0.003644210506710245,
          0.01379995217505904,
          0.028730381986060222,
          0.044211015882344905,
          0.028454246137096264,
          0.017208972390197454,
          0.025749176784075997,
          0.01767925883653434,
          0.012208817212777081,
          0.02421154593004563,
          0.008463818903339845,
          0.01751683625374586,
          0.012781964271774866,
          0.01028216027558904,
          0.013400894806508608,
          0.011555818831039837,
          0.024416201570925836,
          0.022903098088970626,
          0.03152638087490493,
          0.04027641260887244,
          0.035439469400346896,
          0.03699574108319062,
          0.024042219954968837,
          0.024900041101778278,
          0.0001296224582492169,
          -0.00972141561328505,
          -0.00972141561328505,
          -0.008634181421253653,
          -0.0014876026832172846,
          0.005007209290406813,
          0.0035935089191103864,
          0.0035935089191103864,
          0.028291666204130483,
          0.028291666204130483,
          0.029012979810002747,
          0.03910055380514653,
          0.014111595717212853,
          0.0075140711510704086,
          -0.008312505030732402,
          -0.007320247628976623,
          -0.007320247628976624,
          -0.008227549432699398,
          -0.009638024026592877,
          -0.009638024026592877,
          -0.0035552260412358653,
          -0.0041585857413368645,
          -0.0010982503376985682,
          0.022373108913744697,
          0.022373108913744697,
          0.02201855492453797,
          0.01613304816814429,
          0.016467115900456894,
          0.021895860875496904,
          0.02853161142049261,
          0.015372109896723435,
          0.015849357934971237,
          -0.007622001316472026,
          0.003976056360412823,
          0.004523567106515925,
          -0.00628519758998303,
          -0.006285197589983027,
          0.017470321057758875,
          0.06366217547114021,
          0.06366217547114021,
          0.06334433937649063,
          0.07192947179340209,
          0.0719294717934021,
          0.13948035050190313,
          0.13948035050190313,
          0.07103242942069964,
          0.061850915108062995,
          0.015849357934971237,
          0.000634654327170615,
          0.0015595129961646363,
          0.001559512996164637,
          0.0024260846550798326,
          0.0181831242822813,
          0.0181831242822813,
          0.017217535468479702,
          0.017567029515435154,
          0.014127728939659067,
          0.00755443978869369,
          0.01286315061600401,
          0.011376623299572777,
          0.01092409384772122,
          0.03462697551974663,
          0.03566928731489294,
          0.022692655651944987,
          0.018802599534612534,
          0.02455042636181841,
          0.014520396414796247,
          0.014520396414796246,
          0.015707792807290705,
          0.004489844089341982,
          0.004842229432428202,
          0.014845084612568104,
          0.0148450846125681,
          0.0148450846125681,
          -0.007645462881229515,
          -0.007645462881229515,
          0.014683085763108596,
          0.004388173914764404,
          0.003836452888632934,
          0.0027264701633515544,
          0.0022711844081114638,
          -0.010682336720110324,
          -0.010682336720110321,
          -0.0064668712054904084,
          -0.00607083484581414,
          0.011603910078275548,
          0.0071627919552381255,
          0.02385906740582433,
          0.05344004474904637,
          0.05634319561981679,
          0.05746335218868431,
          0.05634319561981679,
          0.06335852713962571,
          0.053369226987061,
          0.054356204682533174,
          0.0288832933074678,
          0.008483830276882426,
          -0.0006976840357542354,
          0.006412198714037814,
          0.023302663129201706,
          0.029967457461473737,
          0.02245269632352418,
          0.022823253706819487,
          -0.0012400393748421108,
          -0.002234481667586775,
          0.011294270603398531,
          0.03540621745174597,
          0.03455793806327404,
          0.02743909506680945,
          0.0032644238577331625,
          0.00673593693953455,
          -0.005182527466834721,
          0.011209311936891996,
          -0.005398708198000109,
          0.019152711216876322,
          0.018240550792087126,
          0.0005493988266383683,
          0.012941897194357448,
          0.002961448715672468,
          0.0021246313685945968,
          0.002459384317132646,
          0.007884429634015398,
          0.0187157936921491,
          0.02560917624419497,
          0.006821417791370996,
          0.03643086574737137,
          0.03710995206405202,
          0.02406245010650511,
          0.01907898988201875,
          0.019920854180447648,
          0.009100141712799555,
          0.01003911497452493,
          0.006935738380205079,
          0.0008734266517421934,
          0.0017337472098036797,
          -0.0025437891513940734,
          -0.002543789151394073,
          0.006637725161242586,
          0.008003796880282405,
          -0.0006701794526345704,
          0.022767385191657927,
          0.021946271864923476,
          0.022831813910140497,
          0.03451724961158309,
          0.016748224885910826,
          0.01567892592436471,
          0.01481867654235518,
          0.015678925924364706,
          -0.008341108856434801,
          -0.008341108856434801,
          -0.011544737279606206,
          -0.010453434189681754,
          0.0007645145282669682,
          -0.000730814033154582,
          -0.00032678856165748333,
          0.02297150943373584,
          0.02401582212725328,
          0.023426795188975922,
          0.0015799246913558453,
          0.0029903992852493245,
          0.0039737439509660915,
          0.02590232323558572,
          0.02630229259530421,
          0.026963030697343307,
          0.027309262545359043,
          0.01653925203549959,
          0.016539252035499583,
          0.02852731884689834,
          0.00619877020256022,
          0.014841617196034178,
          0.014404138883492942,
          0.007864264497417683,
          0.02309197635507595,
          0.035582607964353336,
          0.035582607964353336,
          0.031178861020948006,
          0.01339372619928019,
          0.010656149945935124,
          -0.0016458754285197696,
          -0.0008113299075811234,
          -0.008983082989068712,
          0.0032779288097016493,
          0.012459443122338307,
          0.01345790773981556,
          0.014002531803239255,
          0.01452861282481094,
          0.010867017571839818,
          0.009634680875072375,
          0.001307299287312298,
          -0.005090975522776172,
          -0.00550978874482231,
          0.018604899113173964,
          0.018934262279001555,
          0.018604899113173964,
          0.018256992905494363,
          0.017366766483291128,
          0.01736676648329112,
          0.016955270052394625,
          0.03189809877100856,
          0.037241157834452095,
          0.012233067340012603,
          0.010360203867406388,
          0.024574466532170675,
          0.024574466532170675,
          0.025182036512300037,
          0.019462316655098778,
          0.01805071555339722,
          0.027232229866033873,
          0.0002997370100980111,
          0.000841867845433333,
          0.0028556615276239964,
          -0.00783199588872467,
          0.013607740325384435,
          0.017055490511403794,
          0.02910170983590281,
          0.015334633381401752,
          0.01650322367070742,
          0.016503223670707418,
          0.016503223670707418,
          0.016965714469062206,
          0.03532150227326514,
          0.009414460016821544
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=FSDS<br>batches=%{x}<br>stability=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "line": {
          "color": "green",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FSDS",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x",
         "y": [
          0.06243386243386243,
          0.06455026455026457,
          0.04804232804232804,
          0.0471957671957672,
          0.050158730158730166,
          0.05354497354497356,
          0.06031746031746034,
          0.06412698412698416,
          0.064973544973545,
          0.048888888888888885,
          0.053121693121693125,
          0.056507936507936514,
          0.058201058201058205,
          0.05608465608465608,
          0.059047619047619036,
          0.05650793650793651,
          0.06793650793650793,
          0.06582010582010585,
          0.06455026455026457,
          0.07470899470899471,
          0.08825396825396827,
          0.08317460317460316,
          0.07978835978835977,
          0.07513227513227512,
          0.08021164021164022,
          0.08444444444444445,
          0.07047619047619048,
          0.06666666666666667,
          0.06582010582010582,
          0.06285714285714285,
          0.06666666666666668,
          0.06751322751322754,
          0.06751322751322753,
          0.07597883597883597,
          0.07809523809523809,
          0.08148148148148147,
          0.08486772486772486,
          0.07724867724867725,
          0.06455026455026457,
          0.06920634920634923,
          0.07513227513227515,
          0.07978835978835981,
          0.07724867724867727,
          0.09333333333333334,
          0.08994708994708997,
          0.08529100529100529,
          0.07682539682539684,
          0.07894179894179895,
          0.08063492063492063,
          0.07724867724867725,
          0.07005291005291005,
          0.058624338624338614,
          0.06116402116402118,
          0.06285714285714286,
          0.060740740740740734,
          0.05439153439153441,
          0.056084656084656105,
          0.055661375661375675,
          0.048465608465608476,
          0.05947089947089948,
          0.0670899470899471,
          0.06962962962962964,
          0.07428571428571432,
          0.07005291005291008,
          0.06751322751322754,
          0.0632804232804233,
          0.06243386243386245,
          0.06751322751322754,
          0.06835978835978838,
          0.07809523809523812,
          0.07682539682539685,
          0.08063492063492064,
          0.08105820105820107,
          0.08571428571428574,
          0.10264550264550266,
          0.09544973544973549,
          0.10687830687830689,
          0.10306878306878309,
          0.10010582010582011,
          0.09206349206349207,
          0.10476190476190476,
          0.08952380952380956,
          0.08317460317460319,
          0.09714285714285716,
          0.08275132275132276,
          0.08571428571428572,
          0.08994708994708997,
          0.07851851851851854,
          0.08571428571428574,
          0.08740740740740742,
          0.08148148148148149,
          0.08825396825396827,
          0.09291005291005291,
          0.08486772486772487,
          0.08698412698412697,
          0.06962962962962964,
          0.07682539682539681,
          0.07259259259259261,
          0.0738624338624339,
          0.0797883597883598,
          0.09333333333333334,
          0.0865608465608466,
          0.08613756613756617,
          0.08698412698412702,
          0.09121693121693124,
          0.08656084656084659,
          0.08444444444444445,
          0.07428571428571427,
          0.07132275132275134,
          0.0764021164021164,
          0.07343915343915347,
          0.07851851851851852,
          0.06497354497354499,
          0.058624338624338614,
          0.057777777777777775,
          0.05058201058201056,
          0.057777777777777775,
          0.06962962962962964,
          0.07894179894179895,
          0.06624338624338624,
          0.06455026455026457,
          0.05862433862433865,
          0.0670899470899471,
          0.06708994708994712,
          0.06412698412698416,
          0.060317460317460325,
          0.05947089947089948,
          0.05989417989417989,
          0.051005291005291005,
          0.06455026455026455,
          0.07767195767195767,
          0.07682539682539684,
          0.07132275132275132,
          0.06624338624338623,
          0.07851851851851852,
          0.06962962962962964,
          0.08571428571428572,
          0.07682539682539684,
          0.07174603174603177,
          0.07851851851851853,
          0.06285714285714286,
          0.06074074074074074,
          0.06835978835978837,
          0.07005291005291008,
          0.057777777777777775,
          0.05269841269841271,
          0.06285714285714288,
          0.056507936507936514,
          0.05777777777777779,
          0.05439153439153439,
          0.06243386243386245,
          0.06835978835978837,
          0.07640211640211642,
          0.06328042328042328,
          0.05523809523809523,
          0.051428571428571435,
          0.03322751322751323,
          0.0471957671957672,
          0.04719576719576721,
          0.04973544973544974,
          0.041269841269841276,
          0.04169312169312169,
          0.05015873015873016,
          0.059470899470899466,
          0.06920634920634922,
          0.07132275132275134,
          0.07513227513227515,
          0.07851851851851854,
          0.08190476190476194,
          0.07343915343915346,
          0.07809523809523809,
          0.08275132275132277,
          0.08867724867724869,
          0.08783068783068787,
          0.08656084656084659,
          0.08613756613756617,
          0.07597883597883599,
          0.0797883597883598,
          0.0725925925925926,
          0.07047619047619047,
          0.06243386243386244,
          0.06878306878306881,
          0.06539682539682541,
          0.06708994708994709,
          0.058201058201058205,
          0.06370370370370372,
          0.06835978835978837,
          0.06243386243386243,
          0.05185185185185185,
          0.05142857142857143,
          0.05058201058201059,
          0.06074074074074074,
          0.05354497354497356,
          0.04507936507936508,
          0.042116402116402114,
          0.04423280423280423,
          0.0455026455026455,
          0.056084656084656084,
          0.06412698412698413,
          0.06666666666666667,
          0.06285714285714285,
          0.06751322751322753,
          0.07089947089947092,
          0.07089947089947092,
          0.07809523809523812,
          0.0742857142857143,
          0.08021164021164022,
          0.07343915343915343,
          0.07936507936507937,
          0.07597883597883598,
          0.08275132275132276,
          0.0891005291005291,
          0.07005291005291006,
          0.07343915343915344,
          0.07343915343915343,
          0.06920634920634922,
          0.08063492063492063,
          0.07767195767195767,
          0.07682539682539684,
          0.07386243386243388,
          0.07724867724867725,
          0.06328042328042328,
          0.07682539682539685,
          0.06708994708994709,
          0.06624338624338624,
          0.04973544973544974,
          0.05015873015873016,
          0.05777777777777778,
          0.0526984126984127,
          0.05735449735449735,
          0.07386243386243388,
          0.06624338624338627,
          0.06201058201058202,
          0.06370370370370372,
          0.05566137566137568,
          0.06751322751322754,
          0.05904761904761905,
          0.05777777777777776,
          0.06455026455026452,
          0.062010582010582,
          0.06835978835978836,
          0.05566137566137566,
          0.05227513227513228,
          0.06116402116402118,
          0.07174603174603175,
          0.0738624338624339,
          0.0810582010582011,
          0.09333333333333337,
          0.09925925925925924,
          0.10391534391534395,
          0.09883597883597885,
          0.09587301587301585,
          0.09968253968253966,
          0.08698412698412698,
          0.08825396825396827,
          0.08021164021164022,
          0.08105820105820107,
          0.06708994708994707,
          0.07640211640211639,
          0.07428571428571427,
          0.06878306878306878,
          0.0675132275132275,
          0.07005291005291006,
          0.07132275132275134,
          0.07301587301587303,
          0.06031746031746034,
          0.06285714285714286,
          0.06455026455026457,
          0.05989417989417989,
          0.06116402116402116,
          0.0598941798941799,
          0.057777777777777775,
          0.059470899470899466,
          0.058201058201058205,
          0.07005291005291003,
          0.07216931216931217,
          0.07089947089947092,
          0.06708994708994709,
          0.06962962962962962,
          0.08825396825396827,
          0.09714285714285714,
          0.10645502645502646,
          0.10560846560846564,
          0.11153439153439154,
          0.09671957671957673,
          0.10603174603174607,
          0.11322751322751322,
          0.09502645502645504,
          0.08063492063492066,
          0.07343915343915346,
          0.0687830687830688,
          0.06285714285714286,
          0.06920634920634923,
          0.07089947089947092,
          0.07174603174603177,
          0.05523809523809524,
          0.048888888888888885,
          0.06328042328042328,
          0.07174603174603175,
          0.06455026455026455,
          0.07343915343915344,
          0.06835978835978837,
          0.0670899470899471,
          0.06624338624338626,
          0.07301587301587302,
          0.08825396825396828,
          0.08317460317460319,
          0.07767195767195767,
          0.0687830687830688,
          0.0780952380952381,
          0.07132275132275133,
          0.07470899470899472,
          0.08952380952380955,
          0.07851851851851854,
          0.07470899470899474,
          0.0666666666666667,
          0.06835978835978837,
          0.06497354497354496,
          0.06201058201058199,
          0.0675132275132275,
          0.06708994708994707,
          0.06497354497354499,
          0.06793650793650795,
          0.053968253968253985,
          0.05142857142857145,
          0.05693121693121694,
          0.060317460317460325,
          0.05354497354497356,
          0.05989417989417991,
          0.06666666666666668,
          0.07174603174603177,
          0.08317460317460319,
          0.08656084656084659,
          0.08571428571428574,
          0.0721693121693122,
          0.06878306878306882,
          0.06285714285714288,
          0.06666666666666668,
          0.05820105820105821,
          0.05185185185185185,
          0.05989417989417989,
          0.05354497354497354,
          0.05693121693121693,
          0.06285714285714286,
          0.0598941798941799,
          0.06455026455026455,
          0.060317460317460325,
          0.05904761904761905,
          0.057777777777777775,
          0.05777777777777778,
          0.04804232804232804,
          0.061164021164021164,
          0.06582010582010582,
          0.06624338624338624,
          0.07894179894179897,
          0.0776719576719577,
          0.07894179894179897,
          0.08317460317460319,
          0.0835978835978836,
          0.08402116402116404,
          0.0946031746031746,
          0.08021164021164022,
          0.09164021164021167,
          0.08529100529100529,
          0.09121693121693121,
          0.10349206349206351,
          0.09714285714285716,
          0.09714285714285716,
          0.08190476190476194,
          0.07640211640211644,
          0.08656084656084659,
          0.09629629629629631,
          0.09164021164021163,
          0.0857142857142857,
          0.07513227513227515,
          0.07682539682539684,
          0.07301587301587305,
          0.06285714285714288,
          0.06920634920634924,
          0.07005291005291008,
          0.06962962962962964,
          0.0704761904761905,
          0.07640211640211643,
          0.08317460317460319,
          0.07216931216931219,
          0.07343915343915346,
          0.07047619047619048,
          0.0742857142857143,
          0.06878306878306881,
          0.061164021164021184,
          0.06201058201058202,
          0.07174603174603177,
          0.0742857142857143,
          0.07470899470899472,
          0.07597883597883599,
          0.07301587301587302,
          0.07259259259259258,
          0.07767195767195767,
          0.08317460317460318,
          0.08190476190476191,
          0.08105820105820107,
          0.08402116402116402,
          0.06920634920634922,
          0.08275132275132277,
          0.09079365079365082,
          0.08275132275132276,
          0.07047619047619047,
          0.07132275132275132,
          0.06455026455026455,
          0.06751322751322751,
          0.07597883597883599,
          0.0725925925925926,
          0.08656084656084656,
          0.08444444444444446,
          0.0852910052910053,
          0.08698412698412698,
          0.09502645502645504,
          0.09079365079365079,
          0.08275132275132274,
          0.08825396825396824,
          0.08275132275132274,
          0.08317460317460319,
          0.09756613756613758,
          0.08867724867724872,
          0.08910052910052912,
          0.08740740740740742,
          0.08910052910052912,
          0.08952380952380952,
          0.08740740740740742,
          0.0819047619047619,
          0.07597883597883599,
          0.06582010582010582,
          0.05693121693121693,
          0.06708994708994707,
          0.08105820105820107,
          0.07767195767195768,
          0.08105820105820108,
          0.08021164021164022,
          0.08656084656084656,
          0.08740740740740742
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=Pure<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "Pure",
         "line": {
          "color": "blue",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Pure",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x2",
         "y": [
          0.10600000000000001,
          0.10700000000000001,
          0.10900000000000001,
          0.10300000000000001,
          0.097,
          0.09000000000000001,
          0.095,
          0.1,
          0.10200000000000001,
          0.097,
          0.087,
          0.08600000000000001,
          0.08700000000000001,
          0.092,
          0.098,
          0.101,
          0.096,
          0.094,
          0.097,
          0.098,
          0.10800000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10300000000000001,
          0.099,
          0.10500000000000001,
          0.11000000000000001,
          0.10800000000000001,
          0.10800000000000001,
          0.10600000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.10800000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.11400000000000002,
          0.11000000000000001,
          0.11100000000000002,
          0.11099999999999999,
          0.11000000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.11000000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.097,
          0.097,
          0.097,
          0.097,
          0.101,
          0.10799999999999998,
          0.10600000000000001,
          0.10799999999999998,
          0.10600000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11699999999999999,
          0.11299999999999999,
          0.118,
          0.11699999999999999,
          0.10700000000000001,
          0.11100000000000002,
          0.10600000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.10600000000000001,
          0.10700000000000001,
          0.101,
          0.11299999999999999,
          0.10900000000000001,
          0.11699999999999999,
          0.118,
          0.11800000000000002,
          0.11699999999999999,
          0.11600000000000002,
          0.11200000000000002,
          0.11100000000000002,
          0.118,
          0.11299999999999999,
          0.11699999999999999,
          0.11299999999999999,
          0.11499999999999999,
          0.11699999999999999,
          0.125,
          0.127,
          0.137,
          0.141,
          0.135,
          0.13599999999999998,
          0.129,
          0.135,
          0.136,
          0.13199999999999998,
          0.134,
          0.136,
          0.135,
          0.131,
          0.135,
          0.132,
          0.138,
          0.131,
          0.13,
          0.137,
          0.13199999999999998,
          0.129,
          0.135,
          0.14100000000000001,
          0.134,
          0.136,
          0.13399999999999998,
          0.133,
          0.13399999999999998,
          0.134,
          0.12599999999999997,
          0.126,
          0.121,
          0.11500000000000002,
          0.12000000000000002,
          0.119,
          0.123,
          0.123,
          0.12000000000000002,
          0.118,
          0.127,
          0.13,
          0.12800000000000003,
          0.13,
          0.13099999999999998,
          0.134,
          0.12400000000000003,
          0.127,
          0.128,
          0.127,
          0.122,
          0.11599999999999999,
          0.11400000000000002,
          0.121,
          0.11600000000000002,
          0.11499999999999999,
          0.119,
          0.11900000000000002,
          0.127,
          0.128,
          0.13,
          0.135,
          0.13,
          0.11900000000000002,
          0.126,
          0.122,
          0.13,
          0.129,
          0.126,
          0.12600000000000003,
          0.124,
          0.11900000000000002,
          0.123,
          0.12999999999999998,
          0.13,
          0.133,
          0.128,
          0.126,
          0.121,
          0.12,
          0.121,
          0.122,
          0.129,
          0.118,
          0.11400000000000002,
          0.11699999999999999,
          0.119,
          0.127,
          0.126,
          0.127,
          0.132,
          0.13999999999999999,
          0.14200000000000002,
          0.159,
          0.16199999999999998,
          0.157,
          0.156,
          0.152,
          0.15100000000000002,
          0.149,
          0.14100000000000001,
          0.135,
          0.133,
          0.123,
          0.129,
          0.129,
          0.127,
          0.132,
          0.13599999999999998,
          0.143,
          0.151,
          0.153,
          0.14700000000000002,
          0.146,
          0.137,
          0.13999999999999999,
          0.14700000000000002,
          0.13699999999999998,
          0.144,
          0.135,
          0.127,
          0.123,
          0.121,
          0.121,
          0.122,
          0.12400000000000003,
          0.124,
          0.131,
          0.12899999999999998,
          0.135,
          0.142,
          0.148,
          0.151,
          0.15899999999999997,
          0.158,
          0.155,
          0.149,
          0.146,
          0.137,
          0.142,
          0.135,
          0.134,
          0.132,
          0.127,
          0.131,
          0.133,
          0.129,
          0.133,
          0.138,
          0.137,
          0.144,
          0.152,
          0.162,
          0.16,
          0.16099999999999998,
          0.164,
          0.16599999999999998,
          0.164,
          0.16499999999999998,
          0.16399999999999998,
          0.161,
          0.151,
          0.144,
          0.15,
          0.14800000000000002,
          0.144,
          0.152,
          0.154,
          0.155,
          0.14700000000000002,
          0.153,
          0.16,
          0.16599999999999998,
          0.161,
          0.16399999999999998,
          0.17099999999999999,
          0.163,
          0.16299999999999998,
          0.162,
          0.16499999999999998,
          0.155,
          0.146,
          0.14500000000000002,
          0.147,
          0.152,
          0.14400000000000002,
          0.147,
          0.15,
          0.149,
          0.152,
          0.153,
          0.15,
          0.146,
          0.147,
          0.146,
          0.146,
          0.144,
          0.14100000000000001,
          0.13999999999999999,
          0.138,
          0.13599999999999998,
          0.138,
          0.13799999999999998,
          0.13,
          0.12200000000000003,
          0.134,
          0.139,
          0.13799999999999998,
          0.139,
          0.13799999999999998,
          0.14700000000000002,
          0.146,
          0.156,
          0.166,
          0.172,
          0.16799999999999998,
          0.173,
          0.181,
          0.179,
          0.188,
          0.182,
          0.188,
          0.182,
          0.177,
          0.184,
          0.181,
          0.17600000000000002,
          0.17200000000000001,
          0.177,
          0.168,
          0.16899999999999998,
          0.166,
          0.16,
          0.157,
          0.148,
          0.149,
          0.143,
          0.13599999999999998,
          0.129,
          0.12599999999999997,
          0.131,
          0.13199999999999998,
          0.14,
          0.141,
          0.145,
          0.14,
          0.143,
          0.14700000000000002,
          0.155,
          0.15699999999999997,
          0.151,
          0.15300000000000002,
          0.13899999999999998,
          0.14500000000000002,
          0.14600000000000002,
          0.146,
          0.14400000000000002,
          0.143,
          0.13799999999999998,
          0.139,
          0.14100000000000001,
          0.13299999999999998,
          0.144,
          0.14300000000000002,
          0.142,
          0.154,
          0.15899999999999997,
          0.16,
          0.17200000000000001,
          0.179,
          0.186,
          0.191,
          0.178,
          0.176,
          0.16999999999999998,
          0.16699999999999998,
          0.167,
          0.16799999999999998,
          0.162,
          0.157,
          0.15,
          0.158,
          0.166,
          0.166,
          0.167,
          0.167,
          0.172,
          0.17200000000000001,
          0.165,
          0.16599999999999998,
          0.171,
          0.16699999999999998,
          0.17,
          0.176,
          0.18,
          0.175,
          0.169,
          0.16599999999999998,
          0.165,
          0.163,
          0.16599999999999998,
          0.163,
          0.163,
          0.151,
          0.145,
          0.146,
          0.146,
          0.14100000000000001,
          0.148,
          0.155,
          0.147,
          0.148,
          0.152,
          0.15799999999999997,
          0.17200000000000001,
          0.176,
          0.177,
          0.194,
          0.191,
          0.192,
          0.195,
          0.195,
          0.193,
          0.187,
          0.17700000000000002,
          0.16299999999999998,
          0.157,
          0.152,
          0.14900000000000002,
          0.14,
          0.149,
          0.152,
          0.15,
          0.158,
          0.15699999999999997,
          0.17099999999999999,
          0.185,
          0.182,
          0.188,
          0.183,
          0.172,
          0.165,
          0.16699999999999998,
          0.16699999999999998,
          0.164,
          0.15799999999999997,
          0.157,
          0.16099999999999998,
          0.16099999999999998,
          0.16999999999999998,
          0.176,
          0.185,
          0.188,
          0.1893877551020408
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=FIRES<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "line": {
          "color": "red",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FIRES",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x2",
         "y": [
          0.10200000000000001,
          0.10200000000000001,
          0.10699999999999998,
          0.10800000000000001,
          0.10600000000000001,
          0.101,
          0.095,
          0.091,
          0.087,
          0.086,
          0.096,
          0.1,
          0.095,
          0.093,
          0.097,
          0.095,
          0.10600000000000001,
          0.10900000000000001,
          0.10700000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.101,
          0.099,
          0.10400000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.098,
          0.101,
          0.10300000000000001,
          0.10600000000000001,
          0.094,
          0.098,
          0.10400000000000001,
          0.097,
          0.093,
          0.092,
          0.101,
          0.101,
          0.10500000000000001,
          0.10200000000000001,
          0.10400000000000001,
          0.101,
          0.098,
          0.1,
          0.10300000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.101,
          0.099,
          0.097,
          0.099,
          0.10700000000000001,
          0.10700000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.098,
          0.097,
          0.096,
          0.097,
          0.094,
          0.099,
          0.092,
          0.093,
          0.095,
          0.091,
          0.096,
          0.094,
          0.1,
          0.1,
          0.10699999999999998,
          0.101,
          0.101,
          0.101,
          0.1,
          0.10300000000000001,
          0.10300000000000001,
          0.10200000000000001,
          0.1,
          0.096,
          0.093,
          0.10300000000000001,
          0.1,
          0.1,
          0.1,
          0.097,
          0.096,
          0.101,
          0.095,
          0.10200000000000001,
          0.101,
          0.092,
          0.095,
          0.091,
          0.094,
          0.095,
          0.091,
          0.085,
          0.091,
          0.09,
          0.096,
          0.092,
          0.098,
          0.10300000000000001,
          0.101,
          0.097,
          0.10200000000000001,
          0.101,
          0.10300000000000001,
          0.10300000000000001,
          0.10400000000000001,
          0.11399999999999999,
          0.11300000000000002,
          0.11000000000000001,
          0.11300000000000002,
          0.11900000000000002,
          0.121,
          0.12300000000000003,
          0.121,
          0.11499999999999999,
          0.11599999999999999,
          0.11000000000000001,
          0.10799999999999998,
          0.11000000000000001,
          0.11099999999999999,
          0.11499999999999999,
          0.11099999999999999,
          0.11299999999999999,
          0.11699999999999999,
          0.11800000000000002,
          0.10999999999999999,
          0.11600000000000002,
          0.118,
          0.11499999999999999,
          0.11299999999999999,
          0.11099999999999999,
          0.10899999999999999,
          0.11100000000000002,
          0.11000000000000001,
          0.11399999999999999,
          0.12300000000000003,
          0.119,
          0.11900000000000002,
          0.12,
          0.126,
          0.126,
          0.128,
          0.127,
          0.125,
          0.12600000000000003,
          0.121,
          0.12100000000000002,
          0.12,
          0.12200000000000003,
          0.11599999999999999,
          0.11600000000000002,
          0.11599999999999999,
          0.11200000000000002,
          0.10900000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10300000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.096,
          0.099,
          0.1,
          0.10400000000000001,
          0.10300000000000001,
          0.10900000000000001,
          0.11599999999999999,
          0.11300000000000002,
          0.10600000000000001,
          0.10900000000000001,
          0.11300000000000002,
          0.11299999999999999,
          0.10900000000000001,
          0.10800000000000001,
          0.122,
          0.11000000000000001,
          0.10200000000000001,
          0.10699999999999998,
          0.12,
          0.121,
          0.122,
          0.124,
          0.123,
          0.124,
          0.11199999999999999,
          0.123,
          0.132,
          0.12300000000000003,
          0.119,
          0.11900000000000002,
          0.121,
          0.11800000000000002,
          0.126,
          0.124,
          0.126,
          0.11600000000000002,
          0.11300000000000002,
          0.119,
          0.11700000000000002,
          0.12,
          0.119,
          0.124,
          0.122,
          0.132,
          0.134,
          0.137,
          0.13299999999999998,
          0.131,
          0.135,
          0.128,
          0.12400000000000003,
          0.12,
          0.12100000000000002,
          0.11399999999999999,
          0.11300000000000002,
          0.10800000000000001,
          0.11200000000000002,
          0.11099999999999999,
          0.10500000000000001,
          0.10600000000000001,
          0.11299999999999999,
          0.119,
          0.11299999999999999,
          0.11300000000000002,
          0.10899999999999999,
          0.11699999999999999,
          0.11600000000000002,
          0.12,
          0.12000000000000002,
          0.124,
          0.12000000000000002,
          0.11200000000000002,
          0.11900000000000002,
          0.124,
          0.14,
          0.137,
          0.14,
          0.14100000000000001,
          0.144,
          0.14300000000000002,
          0.143,
          0.154,
          0.15,
          0.14100000000000001,
          0.129,
          0.135,
          0.131,
          0.131,
          0.129,
          0.123,
          0.126,
          0.11900000000000002,
          0.119,
          0.122,
          0.123,
          0.12300000000000003,
          0.123,
          0.129,
          0.133,
          0.129,
          0.128,
          0.121,
          0.121,
          0.119,
          0.11800000000000002,
          0.119,
          0.125,
          0.11700000000000002,
          0.119,
          0.13099999999999998,
          0.131,
          0.13599999999999998,
          0.14100000000000001,
          0.146,
          0.145,
          0.142,
          0.138,
          0.13599999999999998,
          0.131,
          0.126,
          0.123,
          0.12100000000000002,
          0.11499999999999999,
          0.10800000000000001,
          0.10600000000000001,
          0.10400000000000001,
          0.10700000000000001,
          0.10500000000000001,
          0.11200000000000002,
          0.11300000000000002,
          0.11300000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.121,
          0.129,
          0.13,
          0.123,
          0.12600000000000003,
          0.118,
          0.11600000000000002,
          0.118,
          0.12000000000000002,
          0.123,
          0.12700000000000003,
          0.125,
          0.126,
          0.131,
          0.13399999999999998,
          0.134,
          0.13599999999999998,
          0.14,
          0.144,
          0.14300000000000002,
          0.13399999999999998,
          0.133,
          0.131,
          0.126,
          0.124,
          0.124,
          0.12400000000000003,
          0.11599999999999999,
          0.11299999999999999,
          0.11599999999999999,
          0.121,
          0.122,
          0.121,
          0.122,
          0.124,
          0.123,
          0.12199999999999997,
          0.124,
          0.121,
          0.11699999999999999,
          0.123,
          0.11499999999999999,
          0.124,
          0.128,
          0.124,
          0.126,
          0.132,
          0.135,
          0.13299999999999998,
          0.133,
          0.11900000000000002,
          0.128,
          0.11700000000000002,
          0.11199999999999999,
          0.11500000000000002,
          0.11399999999999999,
          0.10600000000000001,
          0.11000000000000001,
          0.11299999999999999,
          0.11900000000000002,
          0.128,
          0.12200000000000003,
          0.122,
          0.122,
          0.126,
          0.122,
          0.129,
          0.129,
          0.134,
          0.129,
          0.124,
          0.126,
          0.127,
          0.127,
          0.12000000000000002,
          0.129,
          0.13099999999999998,
          0.127,
          0.122,
          0.129,
          0.135,
          0.137,
          0.14100000000000001,
          0.147,
          0.154,
          0.153,
          0.15,
          0.147,
          0.14700000000000002,
          0.14300000000000002,
          0.142,
          0.142,
          0.135,
          0.13,
          0.131,
          0.132,
          0.132,
          0.139,
          0.14200000000000002,
          0.146,
          0.14500000000000002,
          0.142,
          0.143,
          0.147,
          0.15199999999999997,
          0.15999999999999998,
          0.158,
          0.15099999999999997,
          0.147,
          0.138,
          0.13799999999999998,
          0.14300000000000002,
          0.144,
          0.134,
          0.12100000000000002,
          0.11299999999999999,
          0.10800000000000001,
          0.11000000000000001,
          0.11100000000000002,
          0.119,
          0.11800000000000002,
          0.11199999999999999,
          0.119,
          0.126,
          0.13199999999999998,
          0.136,
          0.141,
          0.144,
          0.13899999999999998,
          0.13,
          0.124,
          0.129,
          0.12600000000000003,
          0.129,
          0.127,
          0.122,
          0.124,
          0.12799999999999997,
          0.14,
          0.147,
          0.15499999999999997,
          0.152,
          0.1553469387755102
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=OFS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "line": {
          "color": "purple",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x2",
         "y": [
          0.094,
          0.096,
          0.096,
          0.095,
          0.1,
          0.101,
          0.10900000000000001,
          0.11300000000000002,
          0.10600000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.101,
          0.10500000000000001,
          0.11100000000000002,
          0.10900000000000001,
          0.11100000000000002,
          0.10600000000000001,
          0.10200000000000001,
          0.1,
          0.10700000000000001,
          0.11399999999999999,
          0.11600000000000002,
          0.11099999999999999,
          0.10900000000000001,
          0.11299999999999999,
          0.11400000000000002,
          0.11299999999999999,
          0.11499999999999999,
          0.11700000000000002,
          0.10899999999999999,
          0.10300000000000001,
          0.10200000000000001,
          0.099,
          0.1,
          0.092,
          0.09200000000000001,
          0.101,
          0.10200000000000001,
          0.10400000000000001,
          0.10900000000000001,
          0.11099999999999999,
          0.10800000000000001,
          0.11000000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.11200000000000002,
          0.10800000000000001,
          0.11200000000000002,
          0.10400000000000001,
          0.096,
          0.094,
          0.099,
          0.099,
          0.093,
          0.09,
          0.092,
          0.09,
          0.086,
          0.088,
          0.096,
          0.10500000000000001,
          0.10600000000000001,
          0.10899999999999999,
          0.10899999999999999,
          0.10800000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.101,
          0.095,
          0.089,
          0.084,
          0.084,
          0.088,
          0.089,
          0.08900000000000001,
          0.087,
          0.094,
          0.094,
          0.097,
          0.101,
          0.10200000000000001,
          0.10400000000000001,
          0.098,
          0.101,
          0.101,
          0.093,
          0.093,
          0.092,
          0.091,
          0.095,
          0.098,
          0.10300000000000001,
          0.10899999999999999,
          0.10500000000000001,
          0.10300000000000001,
          0.10700000000000001,
          0.101,
          0.10500000000000001,
          0.10300000000000001,
          0.10300000000000001,
          0.10700000000000001,
          0.10300000000000001,
          0.099,
          0.101,
          0.10200000000000001,
          0.10300000000000001,
          0.10899999999999999,
          0.10900000000000001,
          0.10599999999999998,
          0.10700000000000001,
          0.1,
          0.10200000000000001,
          0.11000000000000001,
          0.11200000000000002,
          0.11699999999999999,
          0.12,
          0.11599999999999999,
          0.11299999999999999,
          0.11900000000000002,
          0.11499999999999999,
          0.11900000000000002,
          0.11299999999999999,
          0.10700000000000001,
          0.10600000000000001,
          0.10800000000000001,
          0.11099999999999999,
          0.11100000000000002,
          0.11500000000000002,
          0.11699999999999999,
          0.12000000000000002,
          0.11699999999999999,
          0.12300000000000003,
          0.122,
          0.124,
          0.126,
          0.12300000000000003,
          0.11700000000000002,
          0.12,
          0.11400000000000002,
          0.10300000000000001,
          0.10600000000000001,
          0.101,
          0.10400000000000001,
          0.10500000000000001,
          0.099,
          0.101,
          0.10500000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.101,
          0.094,
          0.092,
          0.091,
          0.09100000000000001,
          0.096,
          0.098,
          0.10899999999999999,
          0.10999999999999999,
          0.10800000000000001,
          0.10599999999999998,
          0.11200000000000002,
          0.121,
          0.12,
          0.125,
          0.118,
          0.12,
          0.11499999999999999,
          0.11500000000000002,
          0.119,
          0.123,
          0.12,
          0.11299999999999999,
          0.11200000000000002,
          0.11099999999999999,
          0.11299999999999999,
          0.11200000000000002,
          0.10600000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.11000000000000001,
          0.10700000000000001,
          0.10800000000000001,
          0.11099999999999999,
          0.11000000000000001,
          0.10600000000000001,
          0.10600000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11299999999999999,
          0.11400000000000002,
          0.11399999999999999,
          0.10699999999999998,
          0.10700000000000001,
          0.10800000000000001,
          0.11299999999999999,
          0.11300000000000002,
          0.10899999999999999,
          0.10400000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10900000000000001,
          0.10800000000000001,
          0.11399999999999999,
          0.10500000000000001,
          0.10200000000000001,
          0.10600000000000001,
          0.11200000000000002,
          0.11499999999999999,
          0.11700000000000002,
          0.128,
          0.124,
          0.128,
          0.12300000000000003,
          0.129,
          0.13,
          0.129,
          0.126,
          0.122,
          0.124,
          0.10899999999999999,
          0.11100000000000002,
          0.10900000000000001,
          0.11000000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.10900000000000001,
          0.10499999999999998,
          0.10500000000000001,
          0.10200000000000001,
          0.10899999999999999,
          0.11299999999999999,
          0.10799999999999998,
          0.10700000000000001,
          0.10500000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10800000000000001,
          0.10900000000000001,
          0.10800000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.10800000000000001,
          0.10700000000000001,
          0.11399999999999999,
          0.11200000000000002,
          0.11499999999999999,
          0.11200000000000002,
          0.11699999999999999,
          0.11100000000000002,
          0.10300000000000001,
          0.093,
          0.096,
          0.099,
          0.093,
          0.10400000000000001,
          0.10600000000000001,
          0.10200000000000001,
          0.097,
          0.10400000000000001,
          0.11099999999999999,
          0.124,
          0.129,
          0.129,
          0.139,
          0.128,
          0.121,
          0.133,
          0.12999999999999998,
          0.127,
          0.121,
          0.11699999999999999,
          0.11300000000000002,
          0.10899999999999999,
          0.10200000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.099,
          0.10400000000000001,
          0.10900000000000001,
          0.11399999999999999,
          0.10900000000000001,
          0.10600000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.12000000000000002,
          0.124,
          0.12500000000000003,
          0.121,
          0.11400000000000002,
          0.10800000000000001,
          0.10700000000000003,
          0.10800000000000001,
          0.11099999999999999,
          0.10700000000000001,
          0.10300000000000001,
          0.097,
          0.097,
          0.099,
          0.10500000000000001,
          0.11299999999999999,
          0.121,
          0.127,
          0.12600000000000003,
          0.122,
          0.121,
          0.121,
          0.121,
          0.126,
          0.123,
          0.11500000000000002,
          0.10800000000000001,
          0.10500000000000001,
          0.1,
          0.11099999999999999,
          0.11599999999999999,
          0.12100000000000002,
          0.12,
          0.11400000000000002,
          0.11699999999999999,
          0.124,
          0.124,
          0.129,
          0.128,
          0.11699999999999999,
          0.11300000000000002,
          0.10900000000000001,
          0.11100000000000002,
          0.11299999999999999,
          0.11300000000000002,
          0.11100000000000002,
          0.118,
          0.10900000000000001,
          0.10700000000000001,
          0.11200000000000002,
          0.11600000000000002,
          0.12,
          0.12000000000000002,
          0.124,
          0.122,
          0.123,
          0.11400000000000002,
          0.119,
          0.125,
          0.128,
          0.12900000000000003,
          0.13,
          0.124,
          0.123,
          0.12300000000000003,
          0.122,
          0.129,
          0.132,
          0.124,
          0.12100000000000002,
          0.123,
          0.125,
          0.129,
          0.126,
          0.13,
          0.131,
          0.131,
          0.127,
          0.13,
          0.12899999999999998,
          0.126,
          0.121,
          0.12,
          0.11800000000000002,
          0.119,
          0.126,
          0.128,
          0.126,
          0.123,
          0.125,
          0.123,
          0.12600000000000003,
          0.137,
          0.138,
          0.128,
          0.11600000000000002,
          0.11299999999999999,
          0.11200000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11400000000000002,
          0.11199999999999999,
          0.10300000000000001,
          0.101,
          0.10900000000000001,
          0.118,
          0.123,
          0.127,
          0.129,
          0.138,
          0.13199999999999998,
          0.127,
          0.129,
          0.133,
          0.131,
          0.13,
          0.131,
          0.139,
          0.139,
          0.133,
          0.129,
          0.133,
          0.129,
          0.126,
          0.127,
          0.126,
          0.121,
          0.11199999999999999,
          0.11199999999999999,
          0.11099999999999999,
          0.11199999999999999,
          0.11300000000000002,
          0.118,
          0.11599999999999999,
          0.10899999999999999,
          0.10600000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10899999999999999,
          0.11499999999999999,
          0.119,
          0.11700000000000002,
          0.11299999999999999,
          0.11700000000000002,
          0.126,
          0.12600000000000003,
          0.131,
          0.13199999999999998,
          0.1343061224489796
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=OFSSGD<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "line": {
          "color": "yellow",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFSSGD",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x2",
         "y": [
          0.095,
          0.10200000000000001,
          0.10300000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.097,
          0.10200000000000001,
          0.10700000000000001,
          0.10200000000000001,
          0.10300000000000001,
          0.10600000000000001,
          0.101,
          0.099,
          0.10300000000000001,
          0.099,
          0.10200000000000001,
          0.095,
          0.094,
          0.1,
          0.096,
          0.101,
          0.10200000000000001,
          0.10300000000000001,
          0.095,
          0.095,
          0.099,
          0.10200000000000001,
          0.10700000000000001,
          0.11099999999999999,
          0.11599999999999999,
          0.11500000000000002,
          0.11699999999999999,
          0.11400000000000002,
          0.12,
          0.119,
          0.11800000000000002,
          0.123,
          0.11800000000000002,
          0.11299999999999999,
          0.10700000000000001,
          0.10200000000000001,
          0.101,
          0.10300000000000001,
          0.099,
          0.1,
          0.1,
          0.096,
          0.094,
          0.098,
          0.10200000000000001,
          0.10600000000000001,
          0.11000000000000001,
          0.11099999999999999,
          0.11500000000000002,
          0.12,
          0.123,
          0.123,
          0.128,
          0.12200000000000003,
          0.118,
          0.125,
          0.119,
          0.11500000000000002,
          0.11000000000000001,
          0.10800000000000001,
          0.11499999999999999,
          0.119,
          0.122,
          0.128,
          0.12500000000000003,
          0.126,
          0.13000000000000003,
          0.13,
          0.131,
          0.13,
          0.11900000000000002,
          0.119,
          0.11300000000000002,
          0.10700000000000001,
          0.11599999999999999,
          0.11100000000000002,
          0.10800000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11200000000000002,
          0.118,
          0.11600000000000002,
          0.11499999999999999,
          0.12,
          0.12,
          0.11699999999999999,
          0.11800000000000002,
          0.11499999999999999,
          0.11400000000000002,
          0.119,
          0.11900000000000002,
          0.122,
          0.125,
          0.123,
          0.12000000000000002,
          0.11599999999999999,
          0.11599999999999999,
          0.11500000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.11399999999999999,
          0.10700000000000001,
          0.10500000000000001,
          0.11000000000000001,
          0.11500000000000002,
          0.13,
          0.14,
          0.14400000000000002,
          0.142,
          0.138,
          0.13999999999999999,
          0.139,
          0.136,
          0.134,
          0.131,
          0.126,
          0.11700000000000002,
          0.11299999999999999,
          0.11000000000000001,
          0.10900000000000001,
          0.10300000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.10900000000000001,
          0.10900000000000001,
          0.10600000000000001,
          0.11400000000000002,
          0.10999999999999999,
          0.11400000000000002,
          0.11400000000000002,
          0.11499999999999999,
          0.11200000000000002,
          0.11199999999999999,
          0.10700000000000001,
          0.10899999999999999,
          0.11000000000000001,
          0.099,
          0.10300000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.11000000000000001,
          0.11299999999999999,
          0.10900000000000001,
          0.11399999999999999,
          0.11199999999999999,
          0.122,
          0.126,
          0.134,
          0.13799999999999998,
          0.138,
          0.129,
          0.129,
          0.125,
          0.11700000000000002,
          0.12,
          0.11600000000000002,
          0.126,
          0.124,
          0.11800000000000002,
          0.11700000000000002,
          0.127,
          0.129,
          0.133,
          0.137,
          0.14100000000000001,
          0.139,
          0.13,
          0.13000000000000003,
          0.134,
          0.143,
          0.138,
          0.14,
          0.14400000000000002,
          0.153,
          0.14300000000000002,
          0.141,
          0.14200000000000002,
          0.13399999999999998,
          0.133,
          0.129,
          0.132,
          0.131,
          0.13199999999999998,
          0.132,
          0.13699999999999998,
          0.14500000000000002,
          0.143,
          0.14700000000000002,
          0.15,
          0.14300000000000002,
          0.142,
          0.14500000000000002,
          0.14900000000000002,
          0.142,
          0.14700000000000002,
          0.145,
          0.148,
          0.154,
          0.155,
          0.16599999999999998,
          0.16899999999999998,
          0.17099999999999999,
          0.15999999999999998,
          0.17099999999999999,
          0.175,
          0.175,
          0.173,
          0.164,
          0.156,
          0.154,
          0.15,
          0.13999999999999999,
          0.138,
          0.13399999999999998,
          0.13199999999999998,
          0.12,
          0.12600000000000003,
          0.124,
          0.135,
          0.133,
          0.13499999999999998,
          0.136,
          0.14100000000000001,
          0.139,
          0.13399999999999998,
          0.14500000000000002,
          0.142,
          0.14800000000000002,
          0.14400000000000002,
          0.147,
          0.156,
          0.16,
          0.159,
          0.156,
          0.162,
          0.15899999999999997,
          0.156,
          0.15799999999999997,
          0.16099999999999998,
          0.152,
          0.14500000000000002,
          0.149,
          0.149,
          0.156,
          0.156,
          0.159,
          0.16299999999999998,
          0.167,
          0.15999999999999998,
          0.168,
          0.16999999999999998,
          0.16799999999999998,
          0.163,
          0.15999999999999998,
          0.158,
          0.159,
          0.16,
          0.153,
          0.161,
          0.15999999999999998,
          0.157,
          0.157,
          0.162,
          0.163,
          0.15699999999999997,
          0.155,
          0.155,
          0.15699999999999997,
          0.156,
          0.155,
          0.154,
          0.153,
          0.15300000000000002,
          0.151,
          0.15,
          0.148,
          0.15,
          0.14700000000000002,
          0.144,
          0.149,
          0.15599999999999997,
          0.162,
          0.16799999999999998,
          0.16599999999999998,
          0.168,
          0.16599999999999998,
          0.162,
          0.16599999999999998,
          0.166,
          0.158,
          0.155,
          0.15000000000000002,
          0.148,
          0.155,
          0.154,
          0.154,
          0.154,
          0.154,
          0.15899999999999997,
          0.157,
          0.152,
          0.15,
          0.145,
          0.144,
          0.153,
          0.157,
          0.153,
          0.15,
          0.14,
          0.141,
          0.14200000000000002,
          0.13899999999999998,
          0.14500000000000002,
          0.13,
          0.125,
          0.128,
          0.13399999999999998,
          0.14100000000000001,
          0.148,
          0.154,
          0.15,
          0.154,
          0.147,
          0.163,
          0.161,
          0.153,
          0.14900000000000002,
          0.13999999999999999,
          0.138,
          0.14,
          0.142,
          0.14100000000000001,
          0.152,
          0.145,
          0.144,
          0.144,
          0.141,
          0.14300000000000002,
          0.147,
          0.146,
          0.155,
          0.15699999999999997,
          0.144,
          0.14300000000000002,
          0.151,
          0.156,
          0.161,
          0.16899999999999998,
          0.16499999999999998,
          0.161,
          0.166,
          0.162,
          0.165,
          0.174,
          0.174,
          0.176,
          0.182,
          0.175,
          0.172,
          0.182,
          0.17,
          0.18,
          0.186,
          0.177,
          0.17099999999999999,
          0.174,
          0.167,
          0.17099999999999999,
          0.176,
          0.17200000000000001,
          0.175,
          0.16999999999999998,
          0.17,
          0.16799999999999998,
          0.169,
          0.171,
          0.172,
          0.171,
          0.165,
          0.155,
          0.157,
          0.152,
          0.148,
          0.161,
          0.16599999999999998,
          0.16399999999999998,
          0.17099999999999999,
          0.176,
          0.183,
          0.192,
          0.19,
          0.2,
          0.20600000000000002,
          0.198,
          0.191,
          0.195,
          0.183,
          0.173,
          0.17099999999999999,
          0.16899999999999998,
          0.167,
          0.15799999999999997,
          0.155,
          0.151,
          0.153,
          0.148,
          0.152,
          0.154,
          0.15,
          0.14500000000000002,
          0.145,
          0.15100000000000002,
          0.146,
          0.15300000000000002,
          0.144,
          0.136,
          0.13099999999999998,
          0.134,
          0.141,
          0.148,
          0.15100000000000002,
          0.156,
          0.165,
          0.16,
          0.17,
          0.16999999999999998,
          0.175,
          0.176,
          0.1723265306122449
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=random<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "random",
         "line": {
          "color": "cyan",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "random",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x2",
         "y": [
          0.1,
          0.101,
          0.101,
          0.10500000000000001,
          0.10700000000000001,
          0.10899999999999999,
          0.11299999999999999,
          0.10999999999999999,
          0.11000000000000001,
          0.10900000000000001,
          0.11200000000000002,
          0.11399999999999999,
          0.10900000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.10500000000000001,
          0.098,
          0.10200000000000001,
          0.10600000000000001,
          0.101,
          0.097,
          0.101,
          0.10900000000000001,
          0.11099999999999999,
          0.11199999999999999,
          0.10799999999999998,
          0.11199999999999999,
          0.11499999999999999,
          0.10900000000000001,
          0.10499999999999998,
          0.099,
          0.095,
          0.092,
          0.086,
          0.083,
          0.08399999999999999,
          0.08499999999999999,
          0.08299999999999999,
          0.086,
          0.09,
          0.092,
          0.09,
          0.09,
          0.09,
          0.089,
          0.092,
          0.092,
          0.091,
          0.088,
          0.09,
          0.089,
          0.095,
          0.096,
          0.1,
          0.10300000000000001,
          0.10400000000000001,
          0.10799999999999998,
          0.10800000000000001,
          0.10900000000000001,
          0.11499999999999999,
          0.12,
          0.119,
          0.119,
          0.119,
          0.118,
          0.122,
          0.12000000000000002,
          0.121,
          0.11699999999999999,
          0.11200000000000002,
          0.10899999999999999,
          0.10500000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.1,
          0.08900000000000001,
          0.09,
          0.094,
          0.098,
          0.1,
          0.10400000000000001,
          0.10600000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.101,
          0.11000000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.1,
          0.096,
          0.095,
          0.099,
          0.098,
          0.098,
          0.10500000000000001,
          0.10200000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11400000000000002,
          0.10999999999999999,
          0.11400000000000002,
          0.12,
          0.11699999999999999,
          0.11699999999999999,
          0.11400000000000002,
          0.11599999999999999,
          0.11699999999999999,
          0.122,
          0.123,
          0.123,
          0.126,
          0.123,
          0.125,
          0.12200000000000003,
          0.123,
          0.11800000000000002,
          0.11099999999999999,
          0.10400000000000001,
          0.11099999999999999,
          0.11199999999999999,
          0.11200000000000002,
          0.10700000000000001,
          0.11000000000000001,
          0.11299999999999999,
          0.10600000000000001,
          0.10600000000000001,
          0.11400000000000002,
          0.119,
          0.11600000000000002,
          0.10999999999999999,
          0.099,
          0.10500000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.11200000000000002,
          0.10600000000000001,
          0.11000000000000001,
          0.10600000000000001,
          0.10800000000000001,
          0.11499999999999999,
          0.119,
          0.119,
          0.11500000000000002,
          0.11499999999999999,
          0.11900000000000002,
          0.122,
          0.11600000000000002,
          0.11599999999999999,
          0.118,
          0.11400000000000002,
          0.10800000000000001,
          0.10600000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.1,
          0.10600000000000001,
          0.11000000000000001,
          0.10800000000000001,
          0.11400000000000002,
          0.11699999999999999,
          0.11300000000000002,
          0.10900000000000001,
          0.11599999999999999,
          0.11400000000000002,
          0.10999999999999999,
          0.10400000000000001,
          0.096,
          0.098,
          0.094,
          0.098,
          0.101,
          0.10300000000000001,
          0.099,
          0.10699999999999998,
          0.10700000000000001,
          0.11499999999999999,
          0.118,
          0.11400000000000002,
          0.11399999999999999,
          0.10700000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.1,
          0.101,
          0.08499999999999999,
          0.08399999999999999,
          0.083,
          0.08299999999999999,
          0.086,
          0.087,
          0.094,
          0.095,
          0.1,
          0.10300000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.10200000000000001,
          0.098,
          0.093,
          0.093,
          0.082,
          0.079,
          0.079,
          0.077,
          0.086,
          0.087,
          0.099,
          0.10500000000000001,
          0.10600000000000001,
          0.10700000000000001,
          0.11599999999999999,
          0.12100000000000002,
          0.119,
          0.11499999999999999,
          0.11000000000000001,
          0.11399999999999999,
          0.10800000000000001,
          0.1,
          0.10200000000000001,
          0.10600000000000001,
          0.101,
          0.095,
          0.096,
          0.1,
          0.10800000000000001,
          0.10100000000000002,
          0.101,
          0.11300000000000002,
          0.11400000000000002,
          0.10900000000000001,
          0.11000000000000001,
          0.11599999999999999,
          0.11400000000000002,
          0.11200000000000002,
          0.10500000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10800000000000001,
          0.11200000000000002,
          0.10600000000000001,
          0.10500000000000001,
          0.098,
          0.10500000000000001,
          0.11100000000000002,
          0.11599999999999999,
          0.12100000000000002,
          0.118,
          0.10900000000000001,
          0.10500000000000001,
          0.11200000000000002,
          0.11599999999999999,
          0.11900000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.11599999999999999,
          0.10900000000000001,
          0.11099999999999999,
          0.11100000000000002,
          0.11100000000000002,
          0.10900000000000001,
          0.10900000000000001,
          0.10799999999999998,
          0.11100000000000002,
          0.10700000000000001,
          0.101,
          0.10400000000000001,
          0.101,
          0.10600000000000001,
          0.10900000000000001,
          0.11100000000000002,
          0.11000000000000001,
          0.11200000000000002,
          0.10500000000000001,
          0.101,
          0.1,
          0.098,
          0.098,
          0.09,
          0.088,
          0.087,
          0.086,
          0.082,
          0.08399999999999999,
          0.087,
          0.088,
          0.09,
          0.091,
          0.099,
          0.1,
          0.094,
          0.09,
          0.093,
          0.095,
          0.097,
          0.095,
          0.097,
          0.098,
          0.095,
          0.098,
          0.10400000000000001,
          0.11100000000000002,
          0.11399999999999999,
          0.11300000000000002,
          0.11299999999999999,
          0.11800000000000002,
          0.121,
          0.11399999999999999,
          0.11500000000000002,
          0.11399999999999999,
          0.11700000000000002,
          0.11199999999999999,
          0.11000000000000001,
          0.11599999999999999,
          0.11800000000000002,
          0.11499999999999999,
          0.11300000000000002,
          0.11699999999999999,
          0.124,
          0.123,
          0.121,
          0.12,
          0.11699999999999999,
          0.11699999999999999,
          0.11099999999999999,
          0.11200000000000002,
          0.11399999999999999,
          0.11500000000000002,
          0.10500000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10800000000000001,
          0.10999999999999999,
          0.10400000000000001,
          0.101,
          0.10500000000000001,
          0.098,
          0.098,
          0.10300000000000001,
          0.10300000000000001,
          0.101,
          0.1,
          0.10800000000000001,
          0.10500000000000001,
          0.10800000000000001,
          0.10500000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.1,
          0.096,
          0.087,
          0.08800000000000001,
          0.087,
          0.086,
          0.089,
          0.08700000000000001,
          0.09,
          0.092,
          0.094,
          0.096,
          0.098,
          0.10300000000000001,
          0.10200000000000001,
          0.1,
          0.10200000000000001,
          0.096,
          0.093,
          0.095,
          0.099,
          0.101,
          0.10899999999999999,
          0.11400000000000002,
          0.11299999999999999,
          0.118,
          0.11800000000000002,
          0.122,
          0.125,
          0.12,
          0.123,
          0.11699999999999999,
          0.10600000000000001,
          0.10700000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.10200000000000001,
          0.10300000000000001,
          0.09999999999999999,
          0.1,
          0.099,
          0.097,
          0.101,
          0.095,
          0.094,
          0.1,
          0.1,
          0.10200000000000001,
          0.10800000000000001,
          0.10600000000000001,
          0.10600000000000001,
          0.11699999999999999,
          0.11299999999999999,
          0.10600000000000001,
          0.10800000000000001,
          0.101,
          0.10200000000000001,
          0.101,
          0.101,
          0.10300000000000001,
          0.098,
          0.093,
          0.093,
          0.097,
          0.101,
          0.11099999999999999,
          0.11000000000000001,
          0.11099999999999999,
          0.10400000000000001,
          0.10900000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.11000000000000001,
          0.10899999999999999,
          0.10500000000000001,
          0.10200000000000001,
          0.1,
          0.101,
          0.10400000000000001,
          0.101,
          0.098,
          0.099,
          0.101,
          0.099,
          0.099,
          0.095,
          0.09518367346938776
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=FSDS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "line": {
          "color": "green",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FSDS",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x2",
         "y": [
          0.097,
          0.093,
          0.096,
          0.1,
          0.095,
          0.093,
          0.095,
          0.091,
          0.091,
          0.08900000000000001,
          0.088,
          0.09,
          0.09,
          0.083,
          0.094,
          0.093,
          0.097,
          0.10200000000000001,
          0.099,
          0.098,
          0.097,
          0.10300000000000001,
          0.101,
          0.10400000000000001,
          0.092,
          0.096,
          0.098,
          0.10200000000000001,
          0.10699999999999998,
          0.10700000000000001,
          0.10300000000000001,
          0.097,
          0.099,
          0.099,
          0.098,
          0.093,
          0.087,
          0.08499999999999999,
          0.082,
          0.08299999999999999,
          0.085,
          0.08299999999999999,
          0.08099999999999999,
          0.086,
          0.08900000000000001,
          0.091,
          0.093,
          0.089,
          0.096,
          0.099,
          0.10499999999999998,
          0.11200000000000002,
          0.11199999999999999,
          0.10500000000000001,
          0.10899999999999999,
          0.11699999999999999,
          0.12300000000000003,
          0.125,
          0.12,
          0.122,
          0.121,
          0.119,
          0.122,
          0.123,
          0.11499999999999999,
          0.10800000000000001,
          0.1,
          0.1,
          0.1,
          0.098,
          0.095,
          0.094,
          0.096,
          0.10300000000000001,
          0.10800000000000001,
          0.10600000000000001,
          0.11500000000000002,
          0.118,
          0.11600000000000002,
          0.11200000000000002,
          0.11700000000000002,
          0.119,
          0.118,
          0.11200000000000002,
          0.10699999999999998,
          0.10800000000000001,
          0.10200000000000001,
          0.10600000000000001,
          0.10200000000000001,
          0.10600000000000001,
          0.098,
          0.099,
          0.097,
          0.1,
          0.099,
          0.10800000000000001,
          0.10300000000000001,
          0.093,
          0.095,
          0.096,
          0.095,
          0.093,
          0.093,
          0.094,
          0.098,
          0.094,
          0.098,
          0.10200000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.11099999999999999,
          0.11100000000000002,
          0.11499999999999999,
          0.11499999999999999,
          0.11199999999999999,
          0.11300000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11299999999999999,
          0.11100000000000002,
          0.11000000000000001,
          0.10400000000000001,
          0.10200000000000001,
          0.101,
          0.11199999999999999,
          0.10300000000000001,
          0.098,
          0.094,
          0.09,
          0.089,
          0.093,
          0.093,
          0.087,
          0.084,
          0.079,
          0.084,
          0.089,
          0.093,
          0.099,
          0.10500000000000001,
          0.10200000000000001,
          0.10200000000000001,
          0.11000000000000001,
          0.11099999999999999,
          0.11099999999999999,
          0.11499999999999999,
          0.11800000000000002,
          0.11499999999999999,
          0.11699999999999999,
          0.11400000000000002,
          0.11599999999999999,
          0.127,
          0.125,
          0.12100000000000002,
          0.121,
          0.11500000000000002,
          0.10999999999999999,
          0.11400000000000002,
          0.10900000000000001,
          0.11100000000000002,
          0.10500000000000001,
          0.097,
          0.094,
          0.097,
          0.09,
          0.094,
          0.094,
          0.095,
          0.092,
          0.08800000000000001,
          0.097,
          0.095,
          0.095,
          0.098,
          0.10400000000000001,
          0.096,
          0.097,
          0.097,
          0.101,
          0.1,
          0.097,
          0.1,
          0.101,
          0.10200000000000001,
          0.097,
          0.10500000000000001,
          0.101,
          0.101,
          0.11000000000000001,
          0.11099999999999999,
          0.11500000000000002,
          0.11600000000000002,
          0.11400000000000002,
          0.11600000000000002,
          0.119,
          0.12000000000000002,
          0.129,
          0.13399999999999998,
          0.125,
          0.127,
          0.122,
          0.12400000000000003,
          0.126,
          0.123,
          0.127,
          0.123,
          0.11599999999999999,
          0.11100000000000002,
          0.11599999999999999,
          0.11200000000000002,
          0.11499999999999999,
          0.11299999999999999,
          0.11399999999999999,
          0.11399999999999999,
          0.11299999999999999,
          0.11299999999999999,
          0.11300000000000002,
          0.11599999999999999,
          0.11300000000000002,
          0.11699999999999999,
          0.11000000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.10500000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.10900000000000001,
          0.10500000000000001,
          0.10700000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.10900000000000001,
          0.10400000000000001,
          0.099,
          0.10400000000000001,
          0.10200000000000001,
          0.10400000000000001,
          0.10300000000000001,
          0.099,
          0.10400000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.11700000000000002,
          0.11300000000000002,
          0.10900000000000001,
          0.10700000000000001,
          0.10700000000000001,
          0.11099999999999999,
          0.11400000000000002,
          0.10800000000000001,
          0.11099999999999999,
          0.11600000000000002,
          0.10400000000000001,
          0.11000000000000001,
          0.10700000000000001,
          0.11099999999999999,
          0.10800000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.10500000000000001,
          0.099,
          0.10200000000000001,
          0.10500000000000001,
          0.10500000000000001,
          0.11199999999999999,
          0.11099999999999999,
          0.10999999999999999,
          0.11299999999999999,
          0.11499999999999999,
          0.11599999999999999,
          0.11800000000000002,
          0.10999999999999999,
          0.10899999999999999,
          0.10600000000000001,
          0.10400000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10400000000000001,
          0.10500000000000001,
          0.10200000000000001,
          0.10200000000000001,
          0.10300000000000001,
          0.098,
          0.101,
          0.096,
          0.099,
          0.096,
          0.094,
          0.087,
          0.08700000000000001,
          0.086,
          0.093,
          0.097,
          0.095,
          0.10200000000000001,
          0.096,
          0.099,
          0.10300000000000001,
          0.10600000000000001,
          0.10499999999999998,
          0.11099999999999999,
          0.101,
          0.10600000000000001,
          0.10500000000000001,
          0.101,
          0.10500000000000001,
          0.10699999999999998,
          0.10700000000000001,
          0.10500000000000001,
          0.11000000000000001,
          0.10600000000000001,
          0.11000000000000001,
          0.11000000000000001,
          0.11699999999999999,
          0.11800000000000002,
          0.123,
          0.12600000000000003,
          0.127,
          0.127,
          0.121,
          0.122,
          0.121,
          0.122,
          0.11600000000000002,
          0.11699999999999999,
          0.10500000000000001,
          0.099,
          0.093,
          0.094,
          0.096,
          0.094,
          0.095,
          0.08800000000000001,
          0.092,
          0.087,
          0.095,
          0.097,
          0.094,
          0.097,
          0.1,
          0.10500000000000001,
          0.10400000000000001,
          0.10600000000000001,
          0.10200000000000001,
          0.10900000000000001,
          0.11000000000000001,
          0.11400000000000002,
          0.121,
          0.12100000000000002,
          0.12,
          0.11500000000000002,
          0.11300000000000002,
          0.10799999999999998,
          0.11099999999999999,
          0.10800000000000001,
          0.10499999999999998,
          0.10300000000000001,
          0.10300000000000001,
          0.10200000000000001,
          0.095,
          0.094,
          0.1,
          0.10900000000000001,
          0.11200000000000002,
          0.11100000000000002,
          0.10500000000000001,
          0.1,
          0.095,
          0.091,
          0.095,
          0.10200000000000001,
          0.10800000000000001,
          0.10400000000000001,
          0.10200000000000001,
          0.10400000000000001,
          0.10700000000000001,
          0.10400000000000001,
          0.10899999999999999,
          0.11400000000000002,
          0.11400000000000002,
          0.11200000000000002,
          0.10400000000000001,
          0.1,
          0.098,
          0.097,
          0.1,
          0.10400000000000001,
          0.10500000000000001,
          0.101,
          0.10400000000000001,
          0.098,
          0.096,
          0.10400000000000001,
          0.10500000000000001,
          0.10300000000000001,
          0.101,
          0.10200000000000001,
          0.10200000000000001,
          0.11000000000000001,
          0.11000000000000001,
          0.11199999999999999,
          0.11200000000000002,
          0.11099999999999999,
          0.11000000000000001,
          0.11099999999999999,
          0.12100000000000002,
          0.123,
          0.12,
          0.11000000000000001,
          0.11299999999999999,
          0.10999999999999999,
          0.11100000000000002,
          0.11199999999999999,
          0.11300000000000002,
          0.10900000000000001,
          0.10500000000000001,
          0.098,
          0.098,
          0.10200000000000001,
          0.096,
          0.10699999999999998,
          0.10800000000000001,
          0.10500000000000001,
          0.10600000000000001,
          0.11300000000000002,
          0.11100000000000002,
          0.11399999999999999,
          0.11600000000000002,
          0.118,
          0.11699999999999999,
          0.11699999999999999,
          0.11699999999999999,
          0.11700000000000002,
          0.11599999999999999,
          0.11700000000000002,
          0.11099999999999999,
          0.10900000000000001,
          0.11100000000000002,
          0.1143061224489796
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "variable=Pure<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "Pure",
         "line": {
          "color": "blue",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Pure",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x3",
         "y": [
          0.044299991828063615,
          0.043379258175751015,
          0.043832303377135076,
          0.04248267745137675,
          0.043166686424859414,
          0.04448809183936828,
          0.0516967784442813,
          0.061069796388817134,
          0.06364421320007604,
          0.058778724698572496,
          0.050480702099702436,
          0.04891563032936751,
          0.04575255398771975,
          0.047600079632806366,
          0.048451049194302244,
          0.04960178572176454,
          0.044993853833832656,
          0.04188783240753027,
          0.04814314673469815,
          0.052716994383365856,
          0.062316957792152794,
          0.06320680034142019,
          0.061885894718188984,
          0.062292727924597745,
          0.06286719279174555,
          0.05850198983275745,
          0.06234777599627948,
          0.0626608447644566,
          0.05691942884342112,
          0.054887736495212766,
          0.05071319681523939,
          0.05334631082577066,
          0.05603257592612605,
          0.058074655436847554,
          0.060917261249928335,
          0.06345371297060994,
          0.06176652329831598,
          0.056727964334060424,
          0.05742897804956241,
          0.055146812529378975,
          0.05573720076637738,
          0.05332662573511269,
          0.05719035598063675,
          0.05395791408514974,
          0.055039937862167786,
          0.05548559171827938,
          0.05504341137795023,
          0.05847171868102032,
          0.06157840492839269,
          0.06492629794524855,
          0.06790802556009555,
          0.07386558820254782,
          0.07091099274767455,
          0.07125063297951077,
          0.06694744070077503,
          0.06837305713360094,
          0.06675974991783054,
          0.06520474578218124,
          0.060653905575404454,
          0.0635704088433783,
          0.06366823074827467,
          0.0595234859393299,
          0.06253291030427524,
          0.060206605651291836,
          0.06085784281992031,
          0.05980273616187247,
          0.06183426137308541,
          0.06288355882485964,
          0.06214345029655351,
          0.061100916359901926,
          0.05377070638949812,
          0.06049159911244003,
          0.05806983080502792,
          0.06266350617801364,
          0.06308459658186265,
          0.06311012383238991,
          0.06033285232341109,
          0.06076658071675948,
          0.058758235583052154,
          0.05998608151337487,
          0.06953933614052112,
          0.06585635550549129,
          0.06605837579116722,
          0.06131408149687293,
          0.06184817098565344,
          0.062234495219346084,
          0.07033141829626917,
          0.07603011079257914,
          0.08243434065421726,
          0.08547678157380133,
          0.07963288523542514,
          0.08016093119217291,
          0.07823355399587265,
          0.08461929712781377,
          0.08920809286739517,
          0.08874330699871914,
          0.09479716467761115,
          0.0967518515975838,
          0.09829168327590783,
          0.09620850337264679,
          0.09794376409408884,
          0.09529980046368344,
          0.09722982716624434,
          0.0927182558769533,
          0.09111603125235546,
          0.0952068838779907,
          0.08958465995433777,
          0.08332050205341515,
          0.08997232735635048,
          0.09954330377293527,
          0.09577773614612238,
          0.0975981419242681,
          0.09583135293058385,
          0.09276535914176398,
          0.09202479630767953,
          0.0908917412883849,
          0.08359334318638148,
          0.08529391876219646,
          0.0783511383996522,
          0.06460095675357927,
          0.06581192626882164,
          0.06355639316122667,
          0.0650661970827953,
          0.06571763441358046,
          0.06100742368366089,
          0.059606927628071814,
          0.0686554588921294,
          0.0727556251235268,
          0.07202385972907097,
          0.07607572403608616,
          0.07641557571615434,
          0.07732791811751513,
          0.0722354867637027,
          0.07745267093611943,
          0.08052935790357105,
          0.08159272867969262,
          0.0750052474766851,
          0.06627651694890088,
          0.06294629682973187,
          0.06883257232442666,
          0.06729696933898029,
          0.07078073569067733,
          0.07533283774203707,
          0.07451051481436638,
          0.08227672057105614,
          0.08213886860287993,
          0.08574769354986278,
          0.09281107533740662,
          0.09359687206387639,
          0.08613219806637631,
          0.09684708965755642,
          0.09475195516753473,
          0.10396633371404666,
          0.10364384089035325,
          0.0976873803157278,
          0.09848172289071554,
          0.0957327584535932,
          0.08832418562520614,
          0.08810155394653998,
          0.09173806854305458,
          0.08539032279502648,
          0.08734219436584542,
          0.07626805537012323,
          0.0733285503195595,
          0.07600733308480083,
          0.07241368229115004,
          0.06988371189117965,
          0.07065408689769923,
          0.07233240287996258,
          0.06302990537746508,
          0.05969249831749703,
          0.058821542657837914,
          0.06188442400309304,
          0.06573530482958362,
          0.05994229665545416,
          0.059785725876672434,
          0.06512805798900455,
          0.07304593275711918,
          0.08007551563427348,
          0.09757939952815739,
          0.10167608619740502,
          0.0987304869895031,
          0.09829688688702606,
          0.09754107440439404,
          0.09849650493877195,
          0.09874268882980829,
          0.09355813449525396,
          0.08945881408393934,
          0.08604984195167421,
          0.07603114271440356,
          0.08220959753230472,
          0.08491471699316722,
          0.08567846476541803,
          0.09268313611580437,
          0.09834395358696665,
          0.10946425042375241,
          0.1195289184475223,
          0.12314917578507019,
          0.12089909646654769,
          0.11992929642531906,
          0.11159513800676543,
          0.11025026597820922,
          0.1139538166415122,
          0.10406159819216301,
          0.11070716600238599,
          0.1009712339273235,
          0.09447580753105296,
          0.09147314981476504,
          0.09129369139758955,
          0.09462355211658072,
          0.09987971451769197,
          0.10505818436655656,
          0.10636287995946747,
          0.11005117201684926,
          0.10402712398871458,
          0.11137627021286081,
          0.11635442563275852,
          0.11742767128530648,
          0.1140783187388884,
          0.11589388113751757,
          0.10924461334986235,
          0.10197721021206449,
          0.09645818028199313,
          0.09690239199535042,
          0.08892957855162362,
          0.08688008550081479,
          0.07811123419707976,
          0.07710302830128837,
          0.07488317208143215,
          0.0682180908441537,
          0.07060433455438991,
          0.07280113502502057,
          0.07153552084322992,
          0.0767185212277783,
          0.08515810869913047,
          0.09153155764717108,
          0.10004125347690622,
          0.10812087991719999,
          0.11826202020052409,
          0.11900440559290948,
          0.11701290769976173,
          0.11579392940695328,
          0.11106384925040251,
          0.1012340831639275,
          0.09540822118277141,
          0.08703083815711252,
          0.08066524353210627,
          0.07206960042251775,
          0.06641691921588802,
          0.07315859632633502,
          0.0747165186520463,
          0.07649004036842517,
          0.08889996881207454,
          0.09579779172618372,
          0.09958985076419778,
          0.0974056457799928,
          0.1053648528216506,
          0.11215597123598553,
          0.12073895090596647,
          0.11664644725632975,
          0.12050353641167473,
          0.12736512119382945,
          0.11976304413150698,
          0.11822321534231757,
          0.120301846398523,
          0.12046303090438834,
          0.1109356693054174,
          0.1030139939219773,
          0.0941218912511898,
          0.0923355976307392,
          0.09033904182998259,
          0.080193587346101,
          0.07909583171697512,
          0.0798088385553551,
          0.07379126835883754,
          0.07231666932114333,
          0.07170141986742172,
          0.06997634501966885,
          0.07122971068401444,
          0.07582799122798586,
          0.07814211113130659,
          0.0817606272642964,
          0.07979157093861869,
          0.07711968039135501,
          0.07567886318867413,
          0.07651361587160231,
          0.07503999015809124,
          0.07486696065921035,
          0.07473833098576088,
          0.06791460014790937,
          0.06348635228466151,
          0.06916481232364788,
          0.07625016178601346,
          0.07661388139973306,
          0.07722398749522853,
          0.07540636277687489,
          0.08180622112847358,
          0.081046248511503,
          0.08686950798056987,
          0.09422181614735739,
          0.09954866466043247,
          0.1011096555214233,
          0.10689938301043571,
          0.11730799062241862,
          0.12078397033882,
          0.13172888248260686,
          0.1301696134410292,
          0.1362252061242081,
          0.1363175906433675,
          0.13299102521939205,
          0.14214139892853916,
          0.14041000089018463,
          0.13559416004885455,
          0.1286524608609995,
          0.12807316985609607,
          0.11724657176118854,
          0.1148649422376137,
          0.11283558879535704,
          0.10273050151568994,
          0.09859463613002092,
          0.08438689660047419,
          0.08491355423217466,
          0.08119970323132965,
          0.07984372897107717,
          0.07856855008914228,
          0.07903292445709047,
          0.08640595704440879,
          0.08593893824292478,
          0.09290821492795777,
          0.09533333077888549,
          0.09858184570950176,
          0.09157197057296887,
          0.09195267605952143,
          0.0924651040084429,
          0.09609776602061618,
          0.09408735533516974,
          0.08846885199584884,
          0.09099611834548361,
          0.08348044308406134,
          0.0871965541766162,
          0.09217097509969037,
          0.09160437378169543,
          0.08531098113315402,
          0.07957389940663762,
          0.07228422221500624,
          0.07105598743695363,
          0.06924750873826604,
          0.06269529550206404,
          0.07012947993204947,
          0.06995856435611925,
          0.0675138963172496,
          0.07933619585306684,
          0.08754754684912305,
          0.09490968120599425,
          0.11368941070847624,
          0.12240351888107519,
          0.13032444421302697,
          0.1313303836326063,
          0.12144301437375474,
          0.11797310173028534,
          0.11362265719164677,
          0.10750701446095734,
          0.11018581498005262,
          0.11020190998875257,
          0.10120325712871507,
          0.09980838674573185,
          0.09719547188281699,
          0.1076557028207497,
          0.11383342251605869,
          0.11678009512449601,
          0.1160092906571398,
          0.11661374852211985,
          0.11902578555915691,
          0.11745879676859623,
          0.11021677838986002,
          0.11052616879992139,
          0.11538635861011119,
          0.1098428377840086,
          0.11406747061985831,
          0.11998323753268406,
          0.12464139989672876,
          0.12299687749670765,
          0.1158787087087246,
          0.11216210682835284,
          0.11254309699568077,
          0.1098386117822346,
          0.10999578060499568,
          0.1059080774533129,
          0.10263472258818684,
          0.09120297194326485,
          0.08595543660729138,
          0.08681017663850199,
          0.09111981933928247,
          0.09028758490704804,
          0.09793042594400672,
          0.10708278054200826,
          0.10270444031261879,
          0.10764230087989028,
          0.11284206102887558,
          0.11791790217222245,
          0.13184792301416076,
          0.13321164558433496,
          0.1316218283281942,
          0.14342468128918667,
          0.1424341453465145,
          0.14295196451564945,
          0.1463318513809933,
          0.14916123658017605,
          0.1500241774602891,
          0.1445050415019389,
          0.13527399726531555,
          0.1253312429988683,
          0.12234944585689873,
          0.11803677336584281,
          0.11319385280183333,
          0.10268216548330392,
          0.10880162922742517,
          0.10680376731809268,
          0.10342998442967084,
          0.10996786491515939,
          0.10788338451821715,
          0.11815920553627952,
          0.12607555942543025,
          0.12474337513176677,
          0.12673515082234307,
          0.12125527433346202,
          0.109321017874548,
          0.10600778698778772,
          0.10434379214414191,
          0.10560101903942806,
          0.10582383092829335,
          0.10360245079521246,
          0.10685298186694266,
          0.1131623430856074,
          0.11494585357824834,
          0.13147608602695904,
          0.13734380552967856,
          0.14719249962518116,
          0.15301523186080784,
          0.15622329937355012
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "variable=FIRES<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "line": {
          "color": "red",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FIRES",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x3",
         "y": [
          0.029966071580705446,
          0.03014993614137886,
          0.03396164895686526,
          0.03395418484203272,
          0.033180795602087046,
          0.03635611405429338,
          0.03627356688448206,
          0.035741406571676584,
          0.035671783170556075,
          0.03774744410305613,
          0.04063489254212679,
          0.045284232123826096,
          0.039483947879768264,
          0.03975295045613926,
          0.04092721563054087,
          0.03851121837243835,
          0.04361993484753414,
          0.04716941943648742,
          0.04851309027354702,
          0.045600239420992596,
          0.04924359266968565,
          0.047890062514056524,
          0.04855420997949432,
          0.05203119965648399,
          0.05634609450722485,
          0.0566179228967003,
          0.051179660967059074,
          0.05223430638788096,
          0.05042332096367643,
          0.05203174905732193,
          0.047664426905789245,
          0.04757730226572343,
          0.04939657158968182,
          0.0464393346237492,
          0.041408140433101204,
          0.042745818716290324,
          0.046886477746700905,
          0.04759632623154939,
          0.052211463207249745,
          0.050271336533169585,
          0.04730965005891944,
          0.04529839464766403,
          0.04522538217093632,
          0.044054697058946865,
          0.04621968384892079,
          0.04561307023585031,
          0.04917762008324923,
          0.04496152350377236,
          0.042380316366349674,
          0.04411698170644218,
          0.04865226678821683,
          0.05217434471029475,
          0.05055565370150454,
          0.048423776678850824,
          0.04590033419910149,
          0.04198143523554969,
          0.04096593162963724,
          0.04222127784836375,
          0.04310599269873076,
          0.04001083055093704,
          0.038745525564789926,
          0.03498270943355274,
          0.039312471891150245,
          0.04240964779931562,
          0.0426720286367025,
          0.04571293530912533,
          0.0423198289929539,
          0.042878381551506466,
          0.04036790972975024,
          0.04113496625996467,
          0.03730230869843386,
          0.03936401434595187,
          0.03625999578680396,
          0.03498319455387447,
          0.03450300540504421,
          0.03414831699502673,
          0.032409204670317146,
          0.02972542116410374,
          0.033798100778067754,
          0.034178193370660345,
          0.0416634002784479,
          0.038858260458163964,
          0.03866866039869325,
          0.038564702715945184,
          0.04071465462653398,
          0.04284350616715023,
          0.04860500943512408,
          0.04906498601540291,
          0.04853657069670626,
          0.04806977011049239,
          0.04192687418437509,
          0.04125106126857914,
          0.039606061268579136,
          0.04123658724055518,
          0.039543925533497185,
          0.034638379315009786,
          0.030244546710807056,
          0.030878943047331055,
          0.031807151308540026,
          0.03627370227877848,
          0.034476697298296576,
          0.03925564838632498,
          0.04225736881643251,
          0.041079742488148954,
          0.04098157459457101,
          0.046292436427676345,
          0.046783945799555846,
          0.046619998635608687,
          0.04537296556663062,
          0.04513186902875989,
          0.051056247080375795,
          0.051707336468253796,
          0.05051782383035407,
          0.05071348713541428,
          0.054204872535876955,
          0.05192904578102311,
          0.05239727282760835,
          0.05565920093218352,
          0.05111976322035853,
          0.051237207590832,
          0.04679737905522503,
          0.044758317208033103,
          0.048398789211631335,
          0.05143874294653598,
          0.05403196041850107,
          0.05399496825890959,
          0.05363040947388733,
          0.052789252656062845,
          0.05648428661192022,
          0.05322891350351801,
          0.060513055100317834,
          0.06290988904985592,
          0.05725586538053211,
          0.05505837950329638,
          0.04928184427381997,
          0.048244099838925955,
          0.054450555687487065,
          0.055011696545439234,
          0.06045914222160542,
          0.06963096480643872,
          0.06495680563227955,
          0.06689430387589719,
          0.0700551902330751,
          0.07828955420527875,
          0.07893844190294692,
          0.08232506808378363,
          0.07743835389706945,
          0.07756737741168936,
          0.07705854291607472,
          0.07074571310317537,
          0.0717696558271181,
          0.07096463656643459,
          0.07172913448681487,
          0.06263838741342555,
          0.061748407474665125,
          0.05657046284244236,
          0.054167254939234466,
          0.04977854150213393,
          0.0424918434429735,
          0.04523273717888571,
          0.0453385176729015,
          0.04789210195723178,
          0.046537041145028116,
          0.047128459530564146,
          0.046313676556258655,
          0.05023476655188993,
          0.05282018525505057,
          0.0564535185883839,
          0.057746298561621945,
          0.06225885516621889,
          0.06688656588356583,
          0.059284634124199376,
          0.05644386246669917,
          0.059574269777772915,
          0.06440119469099378,
          0.06444670521495259,
          0.060351635344246056,
          0.05904979710895193,
          0.06898047881294342,
          0.059019569935095974,
          0.0523648543464927,
          0.05894313309830086,
          0.06689079969878624,
          0.06623788156520168,
          0.06336426776481441,
          0.06736597387398775,
          0.06699465316056177,
          0.06951441458220012,
          0.06027450478218551,
          0.06768858931653823,
          0.07317013742801556,
          0.0664669607720992,
          0.06437428130566103,
          0.06318163895621168,
          0.06144484241941515,
          0.05880064776430499,
          0.06460223758942424,
          0.06316220913992211,
          0.0619931854740056,
          0.05489189061643993,
          0.05231463127794831,
          0.05317380310828092,
          0.05247778764185938,
          0.058942469063347804,
          0.06609824106911981,
          0.0693261596759858,
          0.06778820325485083,
          0.07746989667759688,
          0.07824032103062703,
          0.0804957413596782,
          0.08422726394876393,
          0.08330476436372565,
          0.08804684289112677,
          0.07829016770048931,
          0.06924685360717522,
          0.062230331011705255,
          0.060760848901872264,
          0.05101454395030416,
          0.05243336300811753,
          0.04897776119802324,
          0.046048277121979474,
          0.047519985492007526,
          0.03928048617526015,
          0.04247519047207322,
          0.046659702256585,
          0.05109522692575452,
          0.049348206253686425,
          0.050054731274820394,
          0.04554024086327115,
          0.04980356030074909,
          0.04922142739370504,
          0.05219481706289266,
          0.05223201795723642,
          0.05775814025521222,
          0.05878346199760713,
          0.05989557349401494,
          0.06303567737916627,
          0.07295443336357646,
          0.08331666482580792,
          0.08324492618213465,
          0.0812136865906541,
          0.0805435510244659,
          0.08221915268137599,
          0.07627057502809244,
          0.07505088024674245,
          0.07801748909541012,
          0.07400720512361672,
          0.06005382609523768,
          0.0509736459150575,
          0.050050535032699885,
          0.04859140683503957,
          0.044916329207342,
          0.042157621054481405,
          0.04040180546659751,
          0.040738770958667,
          0.03590298246054495,
          0.03650371283181701,
          0.044994870911210384,
          0.05125745707057074,
          0.05917546671216469,
          0.061339059867283274,
          0.0706754215548843,
          0.07357144601971609,
          0.0730285510497189,
          0.07192903803968395,
          0.06606539633837578,
          0.06722207836602556,
          0.06041716367287557,
          0.0575374017970748,
          0.05779238050723725,
          0.06347614184947317,
          0.05587849397278795,
          0.06261073053061858,
          0.06842835687212132,
          0.07099561794762982,
          0.07835756798016809,
          0.0825804569333202,
          0.0846679028207661,
          0.08316126901339699,
          0.07808365211066362,
          0.07790865342102446,
          0.07985120943029496,
          0.07760371280124095,
          0.0788251278451986,
          0.07636771479130282,
          0.07256942445806783,
          0.06763254464541402,
          0.06361597787884724,
          0.06404479327597384,
          0.059970376710018494,
          0.05497972914115425,
          0.04959302316420438,
          0.05157767759023811,
          0.04743909212387234,
          0.04476831954133505,
          0.04261406925144119,
          0.041894197677080455,
          0.050860465952120085,
          0.051669766863463786,
          0.05261749833990813,
          0.04955357918001116,
          0.05013702377280155,
          0.04166338927222238,
          0.03991159652067067,
          0.04317085577992993,
          0.047474872990197134,
          0.05387957046163526,
          0.054050539948833395,
          0.05783189408888952,
          0.06586999191960616,
          0.07530254467020543,
          0.08215988955109925,
          0.08597259303485197,
          0.08780350050868714,
          0.09271619892138555,
          0.09481020925012296,
          0.0925638019146626,
          0.08554215119695925,
          0.0835370298140014,
          0.07795609937729428,
          0.06940008174206505,
          0.064888036919548,
          0.06152068367921089,
          0.06385932437992056,
          0.058321368436673696,
          0.05888733216166035,
          0.05812275049226308,
          0.06042383011439532,
          0.05937743730309879,
          0.055574342590793545,
          0.056945726470072164,
          0.058716528304165794,
          0.06023170634911808,
          0.06020971417424455,
          0.05990614557442643,
          0.05618878300867677,
          0.058563593060614795,
          0.06320239538148234,
          0.05981512510789627,
          0.07260578202974514,
          0.0749675229204334,
          0.07152911709169198,
          0.07134262769852158,
          0.0747757516078964,
          0.07667385815475135,
          0.07416596819524848,
          0.06993845496773526,
          0.060357344954560035,
          0.06472622607344115,
          0.05300990369484696,
          0.04694800494656483,
          0.05060780984428265,
          0.05129932271824815,
          0.045631928710028385,
          0.0469172234569387,
          0.05133644379329459,
          0.056669025074354805,
          0.0630648935872446,
          0.06259786617021718,
          0.06502111345466607,
          0.06668098791145025,
          0.06772769550542887,
          0.06433909879878633,
          0.07143653662764425,
          0.07433130550708358,
          0.07694344806071127,
          0.07353922175800603,
          0.07058544886879083,
          0.0699808558258999,
          0.06772721104669993,
          0.06842020887293009,
          0.06344532245165822,
          0.0694121905468402,
          0.06669095297077185,
          0.0660262264125513,
          0.06645705425581108,
          0.07371619927745612,
          0.07914833589213141,
          0.07912979885078601,
          0.08486919840060203,
          0.09029547930512535,
          0.09910421777589593,
          0.10195484946842648,
          0.09814969522849952,
          0.09141110948991378,
          0.08790663545857316,
          0.08621357990301762,
          0.08622308364783926,
          0.09028280784171315,
          0.08089399441028512,
          0.07736171574674951,
          0.07460782959665405,
          0.0695369185028986,
          0.06962025925187895,
          0.07472364271052558,
          0.07482863227924988,
          0.07129847354909116,
          0.06610590698839745,
          0.06099636527678002,
          0.06128908345275537,
          0.062038375729300134,
          0.07093912760899938,
          0.08438100315196113,
          0.08627758285422886,
          0.08776998694136978,
          0.08534715235021836,
          0.0858616906574396,
          0.09135544453985983,
          0.09330803883922832,
          0.09430611066245419,
          0.08961649561800045,
          0.07536370853478085,
          0.06319054644211147,
          0.058825633406510425,
          0.05437314111968079,
          0.059136299743235456,
          0.06317177745415167,
          0.05898069651378564,
          0.056587933692754555,
          0.06243150239041204,
          0.06931956069226344,
          0.07719183399102189,
          0.08311851482353796,
          0.08565286139094905,
          0.08630405091619608,
          0.07776394896207545,
          0.06887728631117483,
          0.06526376379861216,
          0.0685730157308904,
          0.06540825564919996,
          0.06226600843689968,
          0.05941364971752058,
          0.053076048938078366,
          0.05766670237066729,
          0.06732108515082287,
          0.08102379367256292,
          0.08959494322930267,
          0.0966319288361022,
          0.09658824655291223,
          0.10303169520793413
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "variable=OFS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "line": {
          "color": "purple",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFS",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x3",
         "y": [
          0.029334042681082157,
          0.03249141906198795,
          0.032769785278178476,
          0.03575719100970186,
          0.04247093804697831,
          0.04696291302249349,
          0.04927858424511097,
          0.05185597861923856,
          0.04630205073143044,
          0.042686008157652014,
          0.04285305189822517,
          0.0390154953371392,
          0.03766914666480832,
          0.036807258552920205,
          0.03311327436149356,
          0.032209652928460356,
          0.03227051954363731,
          0.029763089057254905,
          0.030264500385868524,
          0.0356665422571531,
          0.03792863016924101,
          0.04269328797744438,
          0.04170697391218295,
          0.04255305005825909,
          0.04687506634830607,
          0.047177422906476585,
          0.045173383582650835,
          0.04975852852961102,
          0.053589704110942805,
          0.04936916687825356,
          0.04896280671555172,
          0.04958203169123113,
          0.05029689790609735,
          0.05224086921256865,
          0.04768883366641546,
          0.04746926377462295,
          0.050752535533365103,
          0.04594705075881013,
          0.043792174611854764,
          0.04553955241157584,
          0.04640305543142053,
          0.0419046930095287,
          0.04326105534048268,
          0.04214479224311494,
          0.042072009479888775,
          0.04422964677362914,
          0.043949838100511396,
          0.0457922026325311,
          0.041846712479120154,
          0.038017975178684736,
          0.03549722046170361,
          0.03816086235720825,
          0.037493121632958065,
          0.03710780739207344,
          0.0372866137613232,
          0.039329012481370974,
          0.041346361539374245,
          0.043699235102592625,
          0.04465470068963716,
          0.04957557981051629,
          0.05654111251373882,
          0.05943626520055818,
          0.06319880354501432,
          0.06095100332811885,
          0.06062666470378022,
          0.05616852755480117,
          0.0545597322282639,
          0.055334467580523204,
          0.05541173521770125,
          0.05350892918300667,
          0.048140013265730794,
          0.04330030939661516,
          0.03663352722983299,
          0.0346802893448654,
          0.034434035598611655,
          0.03468859089550262,
          0.03424897352362718,
          0.03258002913181986,
          0.042746198965323855,
          0.0403363214219143,
          0.040727126019615444,
          0.042110153478090474,
          0.04261506364153723,
          0.043630372131845715,
          0.04309482434629793,
          0.04710488033251671,
          0.05001213973977612,
          0.04611648308945845,
          0.04051654115005743,
          0.04202082136681703,
          0.04574096086115007,
          0.04680651381683744,
          0.04945394971427333,
          0.052005055365378985,
          0.05501402972435334,
          0.050750140835464454,
          0.04523811952344314,
          0.04579263422549883,
          0.04427507170857186,
          0.04494061792705926,
          0.04329806751031529,
          0.045214011823422724,
          0.04811762384461756,
          0.04899731108849521,
          0.04504653577685034,
          0.04699091946333929,
          0.04953800941042923,
          0.05008514003774165,
          0.051600187543427455,
          0.05499066373390364,
          0.053092411888283376,
          0.05071301967555784,
          0.0456951571104491,
          0.04510418167283363,
          0.04836901528390266,
          0.04462554902860637,
          0.044887061232054055,
          0.047394176423211185,
          0.04428468086557732,
          0.03969102165122845,
          0.039707403073693893,
          0.038316933794545364,
          0.03861412981470301,
          0.03366857858618085,
          0.029555918888155307,
          0.030834488636449824,
          0.03796634172959324,
          0.03681642379662347,
          0.04052924198841632,
          0.044285478233577515,
          0.045804646310534845,
          0.04904447456404235,
          0.04950279216789351,
          0.05663407876460067,
          0.05765172582342419,
          0.06219547090643057,
          0.06382453947227333,
          0.06349926380089348,
          0.05935499708629528,
          0.062238474950113566,
          0.06156420446522058,
          0.056039179263197916,
          0.060881212670653606,
          0.05667734429321656,
          0.05846180391301249,
          0.05814517825712554,
          0.053313028184975464,
          0.05535925572309689,
          0.05570439472209272,
          0.05448108672297719,
          0.054438472474480595,
          0.05531010939811498,
          0.05232080024601513,
          0.05261442835168665,
          0.05137753906437155,
          0.049132086344230635,
          0.045156105641682764,
          0.04538502945324686,
          0.04386188130509871,
          0.04427722964767886,
          0.045251846697295914,
          0.05431537610906062,
          0.052509845948879294,
          0.051926378774305795,
          0.052239651085518604,
          0.04969667901723472,
          0.058975161285420484,
          0.05968984867336339,
          0.06365011803363277,
          0.06169883317186196,
          0.06294243034045913,
          0.056460319510113,
          0.05941795567240034,
          0.064001060871295,
          0.06601577629698298,
          0.06587819648549012,
          0.05727378382281918,
          0.05237357719221416,
          0.054056405475042445,
          0.05741907853173085,
          0.058561195648847965,
          0.056102108758726586,
          0.05305075513722372,
          0.050741847336586585,
          0.053144315800156994,
          0.052072624684557145,
          0.05797391467630377,
          0.06222129854512544,
          0.06176631209013898,
          0.056577368117665595,
          0.05243992792627804,
          0.05635393716726036,
          0.059293151331796204,
          0.057594519190767746,
          0.05401477713289608,
          0.0544521855139327,
          0.0466909680500411,
          0.04092282946423831,
          0.03811031740466742,
          0.03949501603936605,
          0.04409292134703269,
          0.04516560297114413,
          0.04494487682628005,
          0.04243122918360016,
          0.04384813394919924,
          0.04588570061871807,
          0.04906148820184511,
          0.05919400681936386,
          0.06261805959837022,
          0.06464901197932257,
          0.05949764297288333,
          0.05598809131596325,
          0.05236984466371182,
          0.05944710074096791,
          0.06002843464562907,
          0.05825363961307541,
          0.06243193678311572,
          0.05283922050162569,
          0.05398696835276466,
          0.05010374627888838,
          0.052826531460266904,
          0.05398299160704963,
          0.057520669020111125,
          0.05171114521058732,
          0.053386242952407535,
          0.058932055760289315,
          0.049615014455278474,
          0.05028275928906104,
          0.04865104847106438,
          0.048044274913660624,
          0.04447363215455239,
          0.0428572408138762,
          0.04276800055222215,
          0.04297446815154689,
          0.040777164491276816,
          0.0354229392003557,
          0.04068544149015236,
          0.04617322555816471,
          0.04257345033338948,
          0.04513981583375855,
          0.04542280807087922,
          0.04691696852841371,
          0.05007008763153281,
          0.05178294841139547,
          0.05002047130516837,
          0.05295758764249296,
          0.05357055333027304,
          0.05591995369487037,
          0.05531566477990184,
          0.054591128517818846,
          0.05751078663747696,
          0.05379891935846206,
          0.0511288394158669,
          0.049584792086379156,
          0.05305001931439411,
          0.04709766144422183,
          0.04146747648551301,
          0.03193704798716992,
          0.033725399965511854,
          0.03201233584860276,
          0.029958062344329257,
          0.03704127322228533,
          0.03632180382533114,
          0.033371098200206915,
          0.030176179919106417,
          0.0355118363979393,
          0.04002601777347187,
          0.045794733537318486,
          0.04779839079959644,
          0.047798390799596434,
          0.05596083161480263,
          0.04950340690036858,
          0.04809925549621717,
          0.05540458784502779,
          0.052887034709280356,
          0.04898083495426486,
          0.045788242361672275,
          0.04577061252378424,
          0.041533645148885835,
          0.04073761665762747,
          0.03923823487641054,
          0.04228303774379405,
          0.04342758191498619,
          0.04400647645040246,
          0.04780432713656324,
          0.05264825704895373,
          0.05840213996412698,
          0.05505208069627956,
          0.05776766481403086,
          0.06440456500733349,
          0.06066810416798572,
          0.06296133893501081,
          0.06221451116153507,
          0.05776862371564763,
          0.056517101467404074,
          0.05067416578845959,
          0.045157825919178544,
          0.04324249615698946,
          0.04267051473284085,
          0.04255451822934435,
          0.04072624582655805,
          0.03949246912729274,
          0.036903983498807115,
          0.0388955176289282,
          0.03957377849849341,
          0.043533392656058253,
          0.04788823519913609,
          0.0548360537096216,
          0.05866381666639149,
          0.05825779680905584,
          0.05892566371339333,
          0.060542037698884964,
          0.0624109352529438,
          0.061638956421325386,
          0.06419995021014527,
          0.06385430863703687,
          0.06304227655147536,
          0.057798243061001287,
          0.05366703080124082,
          0.050110042079556646,
          0.05555547905803711,
          0.058519533947752556,
          0.061754610459292494,
          0.05909378531951999,
          0.056004390605112475,
          0.05925401734967593,
          0.06477847268736656,
          0.06872485414904214,
          0.07656884853496912,
          0.07446289029649271,
          0.06673247535303428,
          0.06322164697811618,
          0.05899726395976802,
          0.06317165440323062,
          0.06774877858623715,
          0.0704414202582906,
          0.061485088926959273,
          0.06238973199630822,
          0.05329604006022498,
          0.052740484504669415,
          0.057915980084420324,
          0.0576812720881415,
          0.06309341103928753,
          0.06070373237527356,
          0.0609926328886902,
          0.05653265195928987,
          0.05958987922704345,
          0.05283659362375785,
          0.05382165435250279,
          0.06084263421543312,
          0.06289595408392311,
          0.06520024347644779,
          0.062392323001860664,
          0.06286588827096562,
          0.06092588185070537,
          0.060533616969500756,
          0.06074692115757274,
          0.06905597479314811,
          0.07239872131462421,
          0.0641433810408629,
          0.05812243980984201,
          0.062356022131659625,
          0.06812404982890694,
          0.06781797681986387,
          0.06602867868630345,
          0.0687634055744458,
          0.06620737043311653,
          0.06143091655072915,
          0.058155721782365874,
          0.060657489816312124,
          0.059922020777379646,
          0.05281939004666543,
          0.04614949899538086,
          0.046167836694833105,
          0.044176494703491116,
          0.04487978774780903,
          0.053450740698367236,
          0.054905092399522015,
          0.05354175117272497,
          0.05190619629070616,
          0.051889389568017086,
          0.049213193343433756,
          0.048635403017817345,
          0.0594094914713571,
          0.06055988484609829,
          0.05384932080827659,
          0.043188324567675095,
          0.040120603882563104,
          0.040842358268528015,
          0.04433398201654275,
          0.045114486218223414,
          0.0500038892109408,
          0.05203592384297543,
          0.042964309523488765,
          0.042419976754808165,
          0.048721070867666985,
          0.05700916610576223,
          0.06512709500522099,
          0.06627156386968984,
          0.06915878191480263,
          0.07337819808260755,
          0.06685200040046389,
          0.061298694806381594,
          0.06081373999511099,
          0.06367750254834724,
          0.059851707646081755,
          0.055603068190299434,
          0.05618037738607877,
          0.06658856138631862,
          0.06767337213112937,
          0.06811333351731501,
          0.06683084157316893,
          0.06923103361413767,
          0.06945060956946339,
          0.0701895515663001,
          0.07094475353233451,
          0.0724195834643073,
          0.06671370111136612,
          0.05588681505846196,
          0.05264910623134137,
          0.04936733519963452,
          0.050759476266587625,
          0.053322443299554656,
          0.05947733622199571,
          0.056128215159373496,
          0.052219729885881215,
          0.05363503470756174,
          0.05589763974957855,
          0.06042152340665722,
          0.062355425414703736,
          0.06744361046932476,
          0.07082596304888687,
          0.06942605354662443,
          0.061195125338714115,
          0.06277234262943256,
          0.06807430092203601,
          0.0638987689974121,
          0.06782278756161872,
          0.06518276672236513,
          0.06536663447232534
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "variable=OFSSGD<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "line": {
          "color": "yellow",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "OFSSGD",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x3",
         "y": [
          0.03419450775889746,
          0.03800316293799645,
          0.04046684305312754,
          0.04484505670437592,
          0.04688849974551717,
          0.041521175892899206,
          0.04421529740357244,
          0.04905191971368381,
          0.04848810982539631,
          0.0510802474175339,
          0.05230769014778168,
          0.05152623294464727,
          0.054039696884502775,
          0.05514358949681245,
          0.05340576108481524,
          0.054522424205759826,
          0.053422163654104335,
          0.05227784961796722,
          0.054675047619642834,
          0.0544579036613224,
          0.0615642161570696,
          0.061390663562937174,
          0.06268193423777307,
          0.059190902135276904,
          0.057956126303726874,
          0.060927116705729936,
          0.06243974925320569,
          0.06852013647508683,
          0.07404657228046999,
          0.07758833978025606,
          0.07516771491722168,
          0.0799363888932402,
          0.07820968820203791,
          0.08204355003136152,
          0.08312014404472973,
          0.08390400716347242,
          0.0868082279426932,
          0.07979531546062721,
          0.06975474972601976,
          0.06213091788534582,
          0.05804643629296948,
          0.05412605922741458,
          0.05141870563069377,
          0.04531499783209891,
          0.04458602188051426,
          0.04538443503857117,
          0.047013997548551636,
          0.046958382552874295,
          0.053612147489380625,
          0.06054944593972256,
          0.0633508905477461,
          0.06802778021834303,
          0.07075537707480868,
          0.07638436572414048,
          0.0797097690708622,
          0.07843059557363595,
          0.0732000194221246,
          0.07411618258032096,
          0.06985805046128338,
          0.06311235880048638,
          0.06855252258407121,
          0.06331213261628185,
          0.05684506964938687,
          0.0544253043254169,
          0.05386841905482196,
          0.060595645945578244,
          0.06519386890444041,
          0.07214445426679048,
          0.07586978312098147,
          0.07847815413141433,
          0.07873626823952844,
          0.082790911520642,
          0.08776773863594212,
          0.08604124233932182,
          0.08526158140885443,
          0.07707828529795725,
          0.07754434624694503,
          0.0714010794778718,
          0.0700351113606478,
          0.07764979667533312,
          0.07575690727809589,
          0.07102187653099115,
          0.07103064690963448,
          0.07296774653209216,
          0.07017335553409584,
          0.073836657584999,
          0.06946274410617105,
          0.06877614629537969,
          0.07005670480243943,
          0.06670751634964929,
          0.06075033359681435,
          0.05950154987279843,
          0.05612927839642479,
          0.058919598969098305,
          0.06335449429622994,
          0.0644580973787804,
          0.06619006962457483,
          0.07060338574108245,
          0.06982716282004821,
          0.0675479255319126,
          0.06913421635779153,
          0.07265718770849397,
          0.0736883581089288,
          0.07121629874552751,
          0.0735334606656046,
          0.07134856005792099,
          0.06936297649385549,
          0.067109416686954,
          0.07285920442333557,
          0.07690468664753472,
          0.08595887019560775,
          0.09115863884999825,
          0.09128199496020448,
          0.08586821554364935,
          0.07899037824528973,
          0.07881572071104316,
          0.07617176722177299,
          0.07098401924091677,
          0.06846123833485912,
          0.06579700472638535,
          0.06206150777611051,
          0.05507841537199344,
          0.05381276289581464,
          0.05610989364000422,
          0.05810752486338579,
          0.05706888295974748,
          0.06586302171572835,
          0.07113536408459001,
          0.06605648543635653,
          0.06950358705035106,
          0.07047302594262345,
          0.08154290215117138,
          0.07902775063601987,
          0.08069957711432614,
          0.07969509288887416,
          0.0771943047231737,
          0.07185102572725245,
          0.06925164554931729,
          0.06623490941189149,
          0.06373099561800485,
          0.061701900647376705,
          0.049882465180882414,
          0.05227543839124693,
          0.055083307263868876,
          0.053128911659473275,
          0.05615730672120167,
          0.05406161265314987,
          0.051932987282577246,
          0.05481142114257033,
          0.05196075921654099,
          0.050758439967162915,
          0.058844482820078835,
          0.059151004559209276,
          0.056854551391294396,
          0.060984015381223514,
          0.06030409986663058,
          0.06598390870772973,
          0.06945248052755325,
          0.07504029736809276,
          0.07527057297483895,
          0.07013194798327278,
          0.0588863225745479,
          0.0570410844793098,
          0.05178511242356658,
          0.04511375046905909,
          0.044303766993753046,
          0.04372793121662694,
          0.052665828603009016,
          0.05455021947040077,
          0.05195523798130164,
          0.05173284586441411,
          0.061227095387676934,
          0.062187198347779894,
          0.0658009035925531,
          0.06822138262518622,
          0.07637100305306753,
          0.07546655086357786,
          0.06872947206900407,
          0.06971236148912388,
          0.07718547724705496,
          0.09458106051174664,
          0.09171857329690732,
          0.09785003942345541,
          0.10332652041709696,
          0.11376435079425688,
          0.10590484835992531,
          0.10374830230600587,
          0.10427912696355465,
          0.09532514621954198,
          0.09238179453852173,
          0.08308555008184731,
          0.08445026740344622,
          0.08210613137397066,
          0.08087705624666702,
          0.08100591977819184,
          0.082410681617453,
          0.09009893255920416,
          0.08771888772639654,
          0.08682119515227481,
          0.08910035890181371,
          0.08201156723877706,
          0.08030083385594472,
          0.085252217583008,
          0.08906056609545487,
          0.08283380029624093,
          0.08824847757298718,
          0.09022731890080278,
          0.0929259619604845,
          0.10244597606531007,
          0.1027380413633829,
          0.11519498509086043,
          0.12277087970222415,
          0.1229239124750779,
          0.11970092032739917,
          0.1303924815748047,
          0.13607176016398317,
          0.1361125511826053,
          0.13628746937578434,
          0.1307990592352003,
          0.1275813629529879,
          0.12492847325197924,
          0.11736540800673342,
          0.10996097486301477,
          0.10156009143271957,
          0.09320594456674416,
          0.08343822713027729,
          0.0715912533937015,
          0.07275092181949731,
          0.06909310702447322,
          0.07650121258451668,
          0.07140097670451215,
          0.07343080288903764,
          0.07584891987437795,
          0.08467944490490299,
          0.0877790983665928,
          0.08890695283701776,
          0.097943721370711,
          0.10063234796494933,
          0.10753919292292535,
          0.10624179391140179,
          0.11230928407773626,
          0.11997189533088237,
          0.1210781085584092,
          0.11393270214758222,
          0.10425681540365668,
          0.10676907723079572,
          0.10409521124171235,
          0.09715064244714355,
          0.09446332834590768,
          0.09314237998354066,
          0.08338605787453335,
          0.07405230980446452,
          0.07546514633700022,
          0.07906256538468603,
          0.0910112527987251,
          0.09605646713548911,
          0.09901016918057046,
          0.10398412855452983,
          0.11129935721551773,
          0.10808417196259452,
          0.114660802810482,
          0.1212667241966349,
          0.12536079939775388,
          0.12343263712655723,
          0.1188379479694867,
          0.11383400530622816,
          0.11267689157479392,
          0.11341771473855826,
          0.10608140602767677,
          0.11004941507213344,
          0.10680274484421322,
          0.10000200150581902,
          0.09270499728126166,
          0.09460874154319408,
          0.09532382090827345,
          0.08912867398229463,
          0.08793101809215619,
          0.08888484916304609,
          0.08874280785154247,
          0.09141758262631725,
          0.09449372408476134,
          0.1004237196447569,
          0.10394742913635083,
          0.10296040604124261,
          0.10139635740331339,
          0.10327531854242489,
          0.10467432902568263,
          0.10481737247271586,
          0.1041895414464061,
          0.09742215631691573,
          0.10011483272136557,
          0.09860695066970192,
          0.10032671235605288,
          0.10704363813655157,
          0.10360201762093932,
          0.10201560155811074,
          0.09547692781355464,
          0.0929816602507679,
          0.08963630750216971,
          0.09160023179377304,
          0.08507415475486993,
          0.08570670176146168,
          0.08732261156445298,
          0.08761651840287202,
          0.09797793197539323,
          0.10151785505618442,
          0.10521078283016483,
          0.1020156137835252,
          0.11157274674065816,
          0.11605057412881829,
          0.11465871541282166,
          0.10724014436398743,
          0.09903977474123396,
          0.09666411549904247,
          0.09733932346101513,
          0.10028384321551516,
          0.10300159538955245,
          0.10210724381913705,
          0.09560241529313204,
          0.08596693763174786,
          0.08316423127978494,
          0.0864165360613467,
          0.08850753296483459,
          0.0885381215164259,
          0.07300089207919648,
          0.07259687548071796,
          0.07759922210875791,
          0.08428905597465561,
          0.0927342491120282,
          0.1008130962882438,
          0.11253481043261715,
          0.11148387161089593,
          0.11560454290170455,
          0.10967377436195544,
          0.12197275150566941,
          0.11692605130708018,
          0.10868503262508926,
          0.10264251281895051,
          0.09224718524653301,
          0.09288667052041458,
          0.09175938033510969,
          0.08914248926111389,
          0.08638136436450514,
          0.09284231712775033,
          0.08703827544073652,
          0.08675009956432533,
          0.08194198268120845,
          0.08158952482907166,
          0.08316981889511368,
          0.08490795640479532,
          0.07917417521976414,
          0.08560129859363794,
          0.0843117141994024,
          0.07630351426882684,
          0.07766997943681844,
          0.08346211128158186,
          0.08844623826570885,
          0.08999141099035592,
          0.09645193020188561,
          0.08969860033872519,
          0.09177775614309838,
          0.10075302657024851,
          0.09934612267016969,
          0.10254603446467472,
          0.10935890721153893,
          0.11142985481606187,
          0.11659026170182085,
          0.1250334732288559,
          0.11847140813611931,
          0.11739369261492553,
          0.12457108819107432,
          0.11724373713402358,
          0.12744729118205686,
          0.13191153847947487,
          0.12072843989058306,
          0.11390302277895906,
          0.110067789364715,
          0.10264609161801723,
          0.10828496611020241,
          0.11110215126422969,
          0.10821475948933792,
          0.10843185304663046,
          0.10161690106149593,
          0.10079173036023359,
          0.09867473140174526,
          0.10202040976878586,
          0.10646049413884455,
          0.10550173372118003,
          0.10455639895987634,
          0.09884342772058932,
          0.09000745780814882,
          0.08798397302679631,
          0.0864325635831268,
          0.08419582920615543,
          0.10012226719602624,
          0.10423685151965711,
          0.10492670534006313,
          0.1127658419033212,
          0.12041146070097204,
          0.13030070819299241,
          0.13816204872799026,
          0.1406735629343928,
          0.15078135340969687,
          0.15731487719599052,
          0.1504576875696153,
          0.14582642920794817,
          0.15051071572948432,
          0.14095321027661484,
          0.1284927431767739,
          0.12513306942485355,
          0.1239918593041038,
          0.12344886681330873,
          0.116337862227509,
          0.11056064091067572,
          0.10741348189574004,
          0.10925828246554063,
          0.10226490166333628,
          0.1003670441294964,
          0.10139278109094765,
          0.09631978629821601,
          0.09514228651540205,
          0.09049375347340163,
          0.09285208587608167,
          0.09066937461597316,
          0.09121037380276471,
          0.08141195004455834,
          0.07481649955667088,
          0.07503680513134078,
          0.0784754123116021,
          0.08639069789952147,
          0.09064204643073961,
          0.0967596732891753,
          0.10513071782453147,
          0.11590881800944068,
          0.11464971635408225,
          0.12270578207122369,
          0.12318182737038157,
          0.12738615898647787,
          0.13249760972412056,
          0.13152628946595873
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "variable=FSDS<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "line": {
          "color": "green",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "FSDS",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x3",
         "y": [
          0.03680022418928036,
          0.0331823658885977,
          0.039124486923058,
          0.03681131358636856,
          0.03898017764033418,
          0.034345390646246324,
          0.03860078032569475,
          0.03455503697175092,
          0.0368113169950046,
          0.037832389199109015,
          0.03604137561499198,
          0.04090599576810089,
          0.039565181923183076,
          0.03761046036407065,
          0.045216972369391636,
          0.04810961206733945,
          0.05009559463571489,
          0.05387246490503367,
          0.048995249307225104,
          0.04707188313540616,
          0.047148438159329606,
          0.045388356506985604,
          0.04183364374468771,
          0.04319449475808109,
          0.031247848940239686,
          0.0337308581265449,
          0.032553287659595996,
          0.03673624847483793,
          0.0405963004739947,
          0.042365048742125794,
          0.04266975010226772,
          0.04007115150366912,
          0.04156306389564272,
          0.04415745763749408,
          0.04509681407313765,
          0.04158761170757279,
          0.037124532835683594,
          0.03099928821728829,
          0.028961443605759463,
          0.02746199267234627,
          0.02618708277198587,
          0.025681142869819557,
          0.02729474864389044,
          0.027527959877101677,
          0.028890834810257844,
          0.02997481145841636,
          0.029904771525985134,
          0.031139582691830786,
          0.035496629154140404,
          0.03968858138262514,
          0.04436071974740502,
          0.046672624906864024,
          0.04607556060154687,
          0.04075697983590728,
          0.043553795145968986,
          0.046300039429918186,
          0.049794746557652834,
          0.05254158937001289,
          0.04770812991259869,
          0.04928337345130972,
          0.04635337345130972,
          0.04636012657277314,
          0.04909410777256533,
          0.05062685313309241,
          0.04520429994627681,
          0.041555047809524674,
          0.042266892950210674,
          0.03931067490225613,
          0.0403980710002793,
          0.03661200583737203,
          0.03738073414927242,
          0.03980740815829579,
          0.037459520761500165,
          0.04013522185647837,
          0.0414115851179978,
          0.04016032972445517,
          0.04060845573207384,
          0.04156714678594966,
          0.04124766346051216,
          0.03900587597292527,
          0.04642569198360219,
          0.04786460647412958,
          0.049706092284896516,
          0.04802832047212969,
          0.04648738226891003,
          0.048783438904187855,
          0.04466272411624047,
          0.052931999869726756,
          0.050378595330340906,
          0.05276175933614642,
          0.044940769945780425,
          0.042120318493187356,
          0.03915648707556283,
          0.04335759222166299,
          0.044305797919036286,
          0.05042555254981731,
          0.052155350529615285,
          0.04390298885620098,
          0.04629904928840599,
          0.04833224368022107,
          0.04669346721591866,
          0.047793283747876815,
          0.04722132092546027,
          0.046537528752720735,
          0.04698025321092507,
          0.04177303448324598,
          0.041184838196773835,
          0.03885310930188704,
          0.0400284774411106,
          0.03958554992527668,
          0.041986758587354914,
          0.041944756145352466,
          0.042219239267252295,
          0.04217962621593241,
          0.04269183064003614,
          0.04737426622247172,
          0.04917936657262213,
          0.04813488751412438,
          0.04723960889203725,
          0.046491074995720104,
          0.04627336856748736,
          0.042462836447277816,
          0.041398616263791585,
          0.03872419422739217,
          0.04480189341607534,
          0.035307712125667634,
          0.03125669591245667,
          0.031530097151562,
          0.029057002009048944,
          0.02752390325230487,
          0.029723844772772706,
          0.028909712668318023,
          0.027265915300946658,
          0.027729544523256166,
          0.02582404422645152,
          0.029914913885961392,
          0.03625144279167025,
          0.03716180760957298,
          0.04188732423131601,
          0.04858825878745639,
          0.04588588902834994,
          0.045925162469685234,
          0.05087918349838657,
          0.052537748650903014,
          0.04904527515948216,
          0.049332685827670524,
          0.050704358707348705,
          0.05063450466536814,
          0.05231932746726411,
          0.046773105984471895,
          0.05080195444032019,
          0.05745982385612776,
          0.05380130109599125,
          0.049837398851843184,
          0.05403711441572351,
          0.05482198982671778,
          0.05024387720235768,
          0.049433703505087204,
          0.04718006082741484,
          0.04966412326427077,
          0.04481809633798069,
          0.04139476300464735,
          0.040238474947490575,
          0.04124430177408048,
          0.035499312630210576,
          0.039271769868518755,
          0.03960100800332399,
          0.04206720518642258,
          0.04247671770289162,
          0.04103177357927547,
          0.0472998055684235,
          0.04611843301940389,
          0.04929352538521401,
          0.04840609815726954,
          0.05061022734198188,
          0.041485565160393714,
          0.04699184349410308,
          0.04693397964433783,
          0.04422920094368928,
          0.043203989263048255,
          0.041385304016589096,
          0.04466447187806567,
          0.046958510177736015,
          0.0496239237115706,
          0.05003192178797146,
          0.05255958285239724,
          0.04487490286817094,
          0.04760221167047975,
          0.05500495930293855,
          0.05303819488456123,
          0.056560742913767115,
          0.05254780998663124,
          0.05008918215037276,
          0.0567515140736954,
          0.05748986282172157,
          0.062188437417333084,
          0.07085903790457392,
          0.07317638722192324,
          0.06738547621109495,
          0.06956461880762885,
          0.06430415750152596,
          0.07101995682009238,
          0.07057735022623897,
          0.0614210333405103,
          0.059344876090680496,
          0.05364679297606504,
          0.04596456417822683,
          0.04053472486788708,
          0.04833459779383596,
          0.04570870195054881,
          0.048138094909793865,
          0.042446852137490235,
          0.040615522088229154,
          0.045952786257751385,
          0.048849077190990034,
          0.05448330209654859,
          0.05491872297196946,
          0.05438672127179563,
          0.05030892141732911,
          0.05943381842048697,
          0.056281922699449226,
          0.05672626720872557,
          0.05746392954638789,
          0.051603991720247044,
          0.05532490456341107,
          0.0495071934193204,
          0.04862277274195855,
          0.05038058348322446,
          0.043877426516734166,
          0.03905526639933205,
          0.037817521351781666,
          0.03667750060097993,
          0.03692777042248263,
          0.03624287092935942,
          0.029307269519467643,
          0.033562150723890134,
          0.037659294883372385,
          0.03980507054173386,
          0.041157257435300056,
          0.03730127379629755,
          0.04214829896792227,
          0.043690303404300565,
          0.04207538711815141,
          0.054604419580762745,
          0.05242186285020535,
          0.0485728600012025,
          0.046323927621596615,
          0.04600265515295572,
          0.047071293209087706,
          0.04973005892667696,
          0.04467178411195716,
          0.04513192483598767,
          0.04783973264379547,
          0.03573297586976644,
          0.04140571079557934,
          0.044623308996822715,
          0.04460484589963621,
          0.04025156501241037,
          0.039258012789984906,
          0.037944272417421,
          0.03912894140696804,
          0.03736893590944193,
          0.038363055633836886,
          0.0420059345486305,
          0.0416256783164227,
          0.047370495940095146,
          0.050289421564370204,
          0.05061582192906335,
          0.05048378729702872,
          0.05293414550642308,
          0.055236133348017954,
          0.05553700929977323,
          0.050937366295088646,
          0.048951125229461614,
          0.04742926550444708,
          0.04471630501722189,
          0.044289918716368504,
          0.043923515045617,
          0.044415055366425614,
          0.04465959810193221,
          0.040819957545654664,
          0.03964150112775067,
          0.04226310382411972,
          0.03895958590490601,
          0.04002954571168524,
          0.03656576379286475,
          0.0392066524449763,
          0.04083416457248844,
          0.04182114055738059,
          0.038130659479131045,
          0.04096835667935553,
          0.045372318607179836,
          0.049092760327621554,
          0.052870211490669006,
          0.052879149555528124,
          0.05500597493039701,
          0.050918857786888885,
          0.05377174813977923,
          0.05372990277973529,
          0.05633560908321006,
          0.057602423028994064,
          0.06128676483098292,
          0.05637129752421126,
          0.06093957700592358,
          0.05684258253386524,
          0.05526521871561206,
          0.05457943516271888,
          0.051558852502136224,
          0.05164599108028891,
          0.04825727313157097,
          0.04752363737691119,
          0.04080298730213947,
          0.04162517236345496,
          0.03595991254952259,
          0.041691977119575584,
          0.04338838770917567,
          0.050066976869160174,
          0.053589025061931264,
          0.05241640601431221,
          0.054785413818102625,
          0.051284875835041197,
          0.05193379850475218,
          0.049823492546620135,
          0.05408724406492658,
          0.04882674676255734,
          0.05041336456631971,
          0.04013689620680559,
          0.03479302983221632,
          0.03356869009632196,
          0.032643955130870914,
          0.03216218716034598,
          0.034209914167917195,
          0.035509265065206234,
          0.029580678893895606,
          0.03547833613861168,
          0.03002522068481129,
          0.03254929416463184,
          0.03781483633330655,
          0.03781549882052365,
          0.04031424336084523,
          0.044349357334862186,
          0.042195348606974166,
          0.042916952875377126,
          0.0451695844543245,
          0.03995540059896417,
          0.04552111833328656,
          0.047006782795197814,
          0.04437523272138478,
          0.04643894756404699,
          0.0472818393117207,
          0.045524475564995254,
          0.04671266005977147,
          0.04468043275237254,
          0.042322986774127574,
          0.043631110023427296,
          0.03926715512073044,
          0.03623359693822415,
          0.037310311914069555,
          0.03609241717722746,
          0.033435639963157245,
          0.029799217826735103,
          0.027964151455230242,
          0.03200932312450758,
          0.03776368098146733,
          0.04186251243323996,
          0.039435141126005956,
          0.03855779857608276,
          0.03596058670582741,
          0.036708381740681265,
          0.03531004427986702,
          0.037289527562541794,
          0.038410856426303236,
          0.04111097016215785,
          0.03563511091502201,
          0.03178188225882305,
          0.034019479856420655,
          0.03377724568676713,
          0.03269556866813359,
          0.03372205934756544,
          0.03562483132968169,
          0.03678697499435675,
          0.040248411611164214,
          0.0359112608483885,
          0.034916311353439006,
          0.0343180044994978,
          0.036453443095989024,
          0.03744843809098401,
          0.041417205597986825,
          0.043212113129479715,
          0.04050005376027749,
          0.040190746975035045,
          0.03742889314259298,
          0.03524490370918566,
          0.040433970851193976,
          0.04092142216803204,
          0.03629128271683997,
          0.03961217780547699,
          0.03605509254146484,
          0.03568476631102384,
          0.04252969312699767,
          0.045319705185449734,
          0.04371503648250517,
          0.04675983537293512,
          0.04702969744261,
          0.04536924801137847,
          0.04838966695170587,
          0.04895581857364497,
          0.05323364018723135,
          0.0506850957525389,
          0.045996501274178196,
          0.04934944916566355,
          0.04704052073219545,
          0.0440839021214484,
          0.044535506820299116,
          0.05054727803759997,
          0.04708825422388509,
          0.046496653156580706,
          0.04063639458302254,
          0.040375667017953705,
          0.04197812095347052,
          0.0356073803373973,
          0.04640031249737792,
          0.0523077075056405,
          0.0486330137783152,
          0.04647024667968137,
          0.04842437112122001,
          0.05005588815491095,
          0.0542926092584467,
          0.056935788956740986,
          0.05890202666774043,
          0.05848395333718235,
          0.05686386054760308,
          0.05436200189900531,
          0.05797678886642386,
          0.05688965666752347,
          0.05826469653993177,
          0.052726784452019684,
          0.05033645909110608,
          0.05284015496547077,
          0.05438973455214265
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "variable=random<br>batches=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "random",
         "line": {
          "color": "cyan",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "random",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439
         ],
         "xaxis": "x3",
         "y": [
          0.03919169014024721,
          0.037521718934708695,
          0.035176635446768065,
          0.035735851133042576,
          0.037642009490813845,
          0.037529166902207145,
          0.038878148636580484,
          0.03837392622606216,
          0.039153273327994204,
          0.039861375436762235,
          0.04167839462023494,
          0.046103051093459343,
          0.045351535941944195,
          0.04693153594194419,
          0.047346454356862605,
          0.04509982272762228,
          0.041382856803525624,
          0.04143598825134308,
          0.04166397197647871,
          0.03986317685081595,
          0.03836848776443064,
          0.03778949031496357,
          0.04237340182828685,
          0.04647500562989065,
          0.044344476494110205,
          0.04041977156940528,
          0.043533186889717156,
          0.04390606779481008,
          0.04464376620750849,
          0.043394305234012956,
          0.039548165613116054,
          0.0370388422605781,
          0.033206445898769976,
          0.028254744631279232,
          0.029821304403090314,
          0.0314026471883166,
          0.02980663500150693,
          0.03070781424678995,
          0.03269825830565506,
          0.032776261352649085,
          0.0332159587269259,
          0.034470597161246994,
          0.038816463351794034,
          0.03949114492922161,
          0.03635594745343007,
          0.04117550006909919,
          0.040773870051370106,
          0.03821060474524766,
          0.032992907017619436,
          0.03478670095028684,
          0.03736777050347067,
          0.03783006807432088,
          0.03881998973552957,
          0.03902347579942753,
          0.0405869521470623,
          0.040571195580113587,
          0.04238202179093979,
          0.04644013547119451,
          0.04676368543625391,
          0.0477292427117957,
          0.04643228530814459,
          0.04960055076817475,
          0.04855527675041112,
          0.04826357021133615,
          0.04856638219985208,
          0.04720467062091159,
          0.04939721532078387,
          0.047749554541665296,
          0.04757573068737887,
          0.049537287171646245,
          0.049740315709794175,
          0.04409017186989424,
          0.04270555648527885,
          0.04229477683111767,
          0.042399605606678145,
          0.03687023844950563,
          0.038596338030586624,
          0.04346710254855981,
          0.04512158229093246,
          0.04493553997782354,
          0.04735069325785743,
          0.0480562779359889,
          0.046812472110968964,
          0.04760954259100909,
          0.047475217439036876,
          0.05477228312575003,
          0.04886068786832175,
          0.043211762304007445,
          0.041123340585574736,
          0.039408877562370735,
          0.03691761882111199,
          0.04028769080339328,
          0.03944203174547008,
          0.039314244411003264,
          0.04141980848278583,
          0.036739123455738563,
          0.04162062662076575,
          0.04263544850932036,
          0.04438251293029286,
          0.046656891265136315,
          0.04882506622742892,
          0.046036429863792555,
          0.05160931923762909,
          0.05373943495130838,
          0.049230742286123494,
          0.053948529549201964,
          0.05112016710704642,
          0.05319477410327468,
          0.053672650209469375,
          0.054829027165846325,
          0.056459211612506346,
          0.05484102979432452,
          0.052085251603878245,
          0.05178423018112146,
          0.057125568930380996,
          0.05393513193704632,
          0.051636463003497925,
          0.04677537599109512,
          0.04425780575310216,
          0.0415404296426226,
          0.04129312963938054,
          0.04420075103692771,
          0.04607621340901423,
          0.042303708300995585,
          0.03987156705043328,
          0.03884172584944639,
          0.03665057540696852,
          0.03749539579126258,
          0.04142160938349559,
          0.042574436222108804,
          0.045522291060049326,
          0.041339966105189904,
          0.034401126679660846,
          0.036726399928729656,
          0.03857560439635518,
          0.04198603385163589,
          0.0435830590232606,
          0.047664469221649894,
          0.04556520840964636,
          0.04709210837429818,
          0.04514014402507245,
          0.04675024034496193,
          0.05007027792717302,
          0.05099354836742459,
          0.053761290214578206,
          0.048071744439444626,
          0.048100360293460945,
          0.04842466044938881,
          0.04939117633641441,
          0.045140624548088384,
          0.04008493339492178,
          0.040164194635058256,
          0.037371695388751354,
          0.03588598110303707,
          0.03124250790956387,
          0.03064437706844238,
          0.03114593910793545,
          0.029525344463856084,
          0.03377164755609683,
          0.038698141373408365,
          0.040198141373408366,
          0.045876660377383506,
          0.046795634912237316,
          0.04582412994661471,
          0.042253386781039216,
          0.049102893667414035,
          0.04809569060227993,
          0.046055955659979296,
          0.04087553840061467,
          0.034503104430683745,
          0.03318492261250193,
          0.0277180122320757,
          0.029321746337982672,
          0.029049265923023686,
          0.030487119569155036,
          0.026497414055370573,
          0.027650141328097844,
          0.02925938786917396,
          0.036765562704296165,
          0.04102038716437527,
          0.039706101450089556,
          0.03944183718582529,
          0.03800999745135398,
          0.03693969711764987,
          0.03832520966559195,
          0.03769637358938745,
          0.035302891599679045,
          0.034082597449477704,
          0.024073304111236992,
          0.020440399787096712,
          0.02064357439027132,
          0.021879598427627208,
          0.023364905162933942,
          0.027129190877219655,
          0.03186533530807741,
          0.030898662341404447,
          0.03509885800578769,
          0.03952746424675727,
          0.04224151106949974,
          0.04528887546980532,
          0.04666149973881116,
          0.044161183371742393,
          0.04115455677288278,
          0.041073265458832844,
          0.03419575058131796,
          0.03501669273559345,
          0.033217953542577304,
          0.027333008823687627,
          0.030059748395078405,
          0.029401933100285788,
          0.03409790421912061,
          0.041013472837880684,
          0.043926212236470114,
          0.0452311119093743,
          0.04899192396366463,
          0.05364818833434178,
          0.0537686770561463,
          0.05246438142037505,
          0.05233188727453405,
          0.05411945046848633,
          0.050498762728553304,
          0.04504230625932594,
          0.04288684841413457,
          0.04831836954567296,
          0.046646808396423024,
          0.044551731721685334,
          0.04622808749671199,
          0.04749237982642489,
          0.04886026623818226,
          0.0457449721205352,
          0.04521213597977827,
          0.050227750196479445,
          0.053285972188748976,
          0.045971049654925364,
          0.04424469946572688,
          0.04167353987780962,
          0.038115581255458456,
          0.03973260387248108,
          0.03586275159632793,
          0.033916084929661264,
          0.03601194370179526,
          0.03790520045283602,
          0.041335392770097304,
          0.03746574858409104,
          0.03877142195061632,
          0.03740212943163572,
          0.041562933959632495,
          0.04435069279925834,
          0.050549115851519465,
          0.05481895712136074,
          0.05255550158955078,
          0.04608104508793972,
          0.042332796822397496,
          0.04844964435842311,
          0.05239838814337379,
          0.05537817857152488,
          0.052568942419151464,
          0.05259121820509423,
          0.050927921624247384,
          0.04804419146551723,
          0.04909838726971304,
          0.04856249927710862,
          0.04782359552488086,
          0.04573311236521961,
          0.045838441403996934,
          0.04519709081909796,
          0.0465585435102608,
          0.04382525566732133,
          0.037676110504318246,
          0.03654185124505899,
          0.03722664194455557,
          0.039166256496670125,
          0.03849370432973594,
          0.0402522982318081,
          0.037072243918305506,
          0.03692058812686477,
          0.033567224714231465,
          0.03256319383358652,
          0.0366637671732903,
          0.0392638691526163,
          0.03638851901256028,
          0.03265614721768849,
          0.03518366601468097,
          0.03115039501577182,
          0.030121029936406744,
          0.027039660688370826,
          0.02840708207201863,
          0.02946308929875756,
          0.0277657417655054,
          0.02516563978617939,
          0.026490135678636444,
          0.03137990729942073,
          0.03274612283826785,
          0.031711690633762515,
          0.02953391285598474,
          0.03498238120554202,
          0.035939377542538356,
          0.03729526979843061,
          0.035840573403743706,
          0.0377385051016754,
          0.04226984189876696,
          0.03871748286539527,
          0.039646484853000714,
          0.04387075491950379,
          0.05019428433126849,
          0.04771332682824537,
          0.048618754733673275,
          0.05044937436280037,
          0.05081165576184647,
          0.052039432391581486,
          0.04674445162901056,
          0.04934356427528992,
          0.04672194840002415,
          0.044258618251911394,
          0.04370365166134109,
          0.042812009962841034,
          0.04456783659497951,
          0.045540832957703704,
          0.04660274941962017,
          0.04725654132721594,
          0.04873882665514022,
          0.05530813774199046,
          0.05313018331697722,
          0.057042225585856456,
          0.051525514616513904,
          0.050588756622437205,
          0.05295039030775904,
          0.04755245613408957,
          0.0455145912466834,
          0.05031787035905956,
          0.053095502528890136,
          0.04563728019163206,
          0.04719322323144607,
          0.04485485246015136,
          0.04790776251306142,
          0.04841076638693334,
          0.04459098877892044,
          0.04478405558053987,
          0.04851029982965337,
          0.0394215805798484,
          0.03629886310316781,
          0.03747524179387636,
          0.03589613273089633,
          0.03536054557459979,
          0.035664385820375524,
          0.039886091182682396,
          0.03636503184985835,
          0.04022767629500178,
          0.040612956606954125,
          0.04228175053962153,
          0.043503698591569585,
          0.04450220466066389,
          0.04700177176023099,
          0.043721142024973306,
          0.04057726479352952,
          0.03640140591946406,
          0.03663157948421707,
          0.032800648939208595,
          0.03207983744039198,
          0.03427745039861875,
          0.034968391278215,
          0.032553013631853076,
          0.03451524055221954,
          0.03641617103935692,
          0.03987922389804084,
          0.04065355009425784,
          0.046324920931049236,
          0.044597825414480034,
          0.04055743515209489,
          0.040020671867070735,
          0.03760124237463804,
          0.03675993324372495,
          0.03319573720103539,
          0.03348625858646618,
          0.03447873464525025,
          0.03950991494643055,
          0.041365444053901405,
          0.0427285734754578,
          0.044534538732750484,
          0.04686771502814427,
          0.04858818225060637,
          0.05147487009934822,
          0.05464421484122086,
          0.05666189451399113,
          0.05408705856089472,
          0.046782205670621274,
          0.04900215372494834,
          0.047639024303391946,
          0.04613411239302416,
          0.04309012413181842,
          0.04283166364586013,
          0.04175142138297562,
          0.04012364791851737,
          0.040745226018356354,
          0.04164147480155757,
          0.045743919403055736,
          0.04010138157380111,
          0.040472932631500175,
          0.04497894216140559,
          0.04737551764474578,
          0.04755374986029143,
          0.049537176279823326,
          0.04595082087797879,
          0.044464253938431876,
          0.0517051824543604,
          0.047898388463933406,
          0.04443873975748973,
          0.046176807626858885,
          0.04136974475002857,
          0.03824652091504003,
          0.036873500734557155,
          0.03685866915420834,
          0.037302351258267794,
          0.035344767525403165,
          0.029244129712112744,
          0.03050253660576554,
          0.032053098403518346,
          0.03496169854658409,
          0.04287178059926101,
          0.04387582372594564,
          0.043097273747395665,
          0.03784594915547701,
          0.04072363866226284,
          0.04114277208139626,
          0.03889040972766782,
          0.03761672605471956,
          0.0421268314464039,
          0.03803296327355897,
          0.03478055317855402,
          0.0342907957661551,
          0.03600347272883206,
          0.04033987897069166,
          0.042414716063423494,
          0.03985441343770031,
          0.04289577080307636,
          0.047890737191008816,
          0.04102741542505547,
          0.04208671051141241,
          0.0384640368547938,
          0.039800091276562505
         ],
         "yaxis": "y3"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "matches": "x3",
         "showticklabels": false
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "matches": "x3",
         "showticklabels": false
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "batches"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.7333333333333334,
          1
         ],
         "title": {
          "text": "Stability"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.3666666666666667,
          0.6333333333333333
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.26666666666666666
         ],
         "title": {
          "text": "F1-Score"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.1) # subplot_titles=(\"Stability\",\"Accuracy\", \"F1-Score\"),\n",
    "for i in range(len(stability_trace)):\n",
    "    stability_trace[i][\"showlegend\"] = False\n",
    "    fig.add_trace(stability_trace[i], row=1, col=1)\n",
    "for i in range(len(accuracy_trace)):\n",
    "    fig.add_trace(accuracy_trace[i], row=2, col=1)\n",
    "for i in range(len(f1_trace)):\n",
    "    f1_trace[i][\"showlegend\"] = False\n",
    "    fig.add_trace(f1_trace[i], row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"batches\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Stability\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Accuracy\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"F1-Score\", row=3, col=1)\n",
    "fig.write_image(\"{}/all_scores_{}.{}\".format(folder, dataset_name, export_type))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"mnist\" or dataset_name == \"mnist_norm\":\n",
    "    trace1 = mnist_fig_fires['data'][0]\n",
    "    trace2 = mnist_fig_fsds['data'][0]\n",
    "    trace3 = mnist_fig_ofs['data'][0]\n",
    "    trace4 = mnist_fig_ofssgd['data'][0]\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=(\"FIRES\", \"FSDS\", \"OFS\", \"OFSSGD\"))\n",
    "    fig.add_trace(trace1, row=1,col=1)\n",
    "    fig.add_trace(trace2, row=1,col=2)\n",
    "    fig.add_trace(trace3, row=2,col=1)\n",
    "    fig.add_trace(trace4, row=2,col=2)\n",
    "    fig.update_xaxes(\n",
    "        visible=False \n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        visible=False\n",
    "    )\n",
    "    fig.update_layout(height=500, width=500)\n",
    "    fig.write_image(\"{}/digits.{}\".format(folder, export_type))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=Pure<br>=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "Pure",
         "marker": {
          "color": "blue"
         },
         "name": "Pure",
         "offsetgroup": "Pure",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Pure"
         ],
         "xaxis": "x",
         "y": [
          0.1808
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=FIRES<br>=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "marker": {
          "color": "red"
         },
         "name": "FIRES",
         "offsetgroup": "FIRES",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "FIRES"
         ],
         "xaxis": "x",
         "y": [
          0.0982
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=FSDS<br>=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "marker": {
          "color": "green"
         },
         "name": "FSDS",
         "offsetgroup": "FSDS",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "FSDS"
         ],
         "xaxis": "x",
         "y": [
          0.1132
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=OFS<br>=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "marker": {
          "color": "purple"
         },
         "name": "OFS",
         "offsetgroup": "OFS",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "OFS"
         ],
         "xaxis": "x",
         "y": [
          0.1542
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=OFSSGD<br>=%{x}<br>accuracy=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "marker": {
          "color": "yellow"
         },
         "name": "OFSSGD",
         "offsetgroup": "OFSSGD",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "OFSSGD"
         ],
         "xaxis": "x",
         "y": [
          0.1964
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Accuracy on test data"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "accuracy"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "col_names = [\"Pure\",\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\"]\n",
    "values = [accuracy_no_ofs, accuracy_fires, accuracy_fsds, accuracy_ofs, accuracy_ofssgd]\n",
    "fig = px.bar(x=col_names, y=values, title=\"Accuracy on test data\", labels={\"y\":\"accuracy\", \"x\":\"\"}, color=col_names, color_discrete_map={\"Pure\":\"blue\",'FIRES': 'red',\n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\"})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/test_acc.csv\".format(folder), \"a\") as outfile:\n",
    "    outfile.write(\"{},{},{},{},{}\\n\".format(col_names[0],col_names[1],col_names[2], col_names[3],col_names[4]))\n",
    "    outfile.write(\"{},{},{},{},{}\\n\".format(values[0],values[1],values[2],values[3],values[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=FIRES<br>=%{x}<br>s=%{y}<extra></extra>",
         "legendgroup": "FIRES",
         "marker": {
          "color": "red"
         },
         "name": "FIRES",
         "offsetgroup": "FIRES",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "FIRES"
         ],
         "xaxis": "x",
         "y": [
          11.443306557001051
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=FSDS<br>=%{x}<br>s=%{y}<extra></extra>",
         "legendgroup": "FSDS",
         "marker": {
          "color": "green"
         },
         "name": "FSDS",
         "offsetgroup": "FSDS",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "FSDS"
         ],
         "xaxis": "x",
         "y": [
          3.358700012002373
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=OFS<br>=%{x}<br>s=%{y}<extra></extra>",
         "legendgroup": "OFS",
         "marker": {
          "color": "purple"
         },
         "name": "OFS",
         "offsetgroup": "OFS",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "OFS"
         ],
         "xaxis": "x",
         "y": [
          5.572109654000087
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "color=OFSSGD<br>=%{x}<br>s=%{y}<extra></extra>",
         "legendgroup": "OFSSGD",
         "marker": {
          "color": "yellow"
         },
         "name": "OFSSGD",
         "offsetgroup": "OFSSGD",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "OFSSGD"
         ],
         "xaxis": "x",
         "y": [
          38.44966359300088
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Runtime"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "s"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# run times\n",
    "col_names = [\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\"]\n",
    "values = [fires_cuda_run_time, fsds_run_time, ofs_run_time, ofssgd_run_time]\n",
    "fig = px.bar(x=col_names, y=values, title=\"Runtime\", labels={\"y\":\"s\", \"x\":\"\"}, color=col_names, color_discrete_map={'FIRES': 'red', \n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\"})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/runtime.csv\".format(folder), \"a\") as outfile:\n",
    "    outfile.write(\"{},{},{},{}\\n\".format(col_names[0],col_names[1],col_names[2], col_names[3]))\n",
    "    outfile.write(\"{},{},{},{}\\n\".format(values[0],values[1],values[2],values[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_ftrs:\n",
    "    col_names = [\"FIRES\",\"FSDS\", \"OFS\", \"OFSSGD\"]\n",
    "    values = [fires_perc_ftr_found, fsds_perc_ftr_found, ofs_perc_ftr_found, ofssgd_perc_ftr_found]\n",
    "    fig = px.bar(x=col_names, y=values, title=\"True labels found\", labels={\"y\":\"%\", \"x\":\"\"}, color=col_names, color_discrete_map={'FIRES': 'red', \n",
    "                                                   'FSDS': 'green', 'OFS': 'purple', \"OFSSGD\":\"yellow\"})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "207.83296213808464\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ofssgd_n_ftrs_selected))\n"
   ]
  }
 ]
}