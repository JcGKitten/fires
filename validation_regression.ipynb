{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd09e4c97bd779caefcb7cd845411b070731e96d735053e38eececd02f8b1decf55",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Regression Data\n",
    "The FIRES Model can't be compared to a real datastream algorithm, instead the SGDRegressor form scikit learn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the functions needed for validate and comparsion\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#mean_squared_error: mse squared=true, rmse squared=false\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from skmultiflow.data import FileStream\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from skmultiflow.data.regression_generator import RegressionGenerator\n",
    "\n",
    "\n",
    "# using plotly for plots\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fires import FIRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stability import stability_factor "
   ]
  },
  {
   "source": [
    "### Load Datasets as Streaming Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = FileStream('datasets/Regression/ailerons_norm.csv', target_idx=40)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"ailerons_norm\"\n",
    "n_selected_ftr = 10\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Regression/ailerons_test_norm.csv', header=None)\n",
    "test_y = test_data[40].to_numpy()\n",
    "test_x = test_data.drop(columns=40).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized data\n",
    "stream = FileStream('datasets/Regression/dataset_1_norm_train.csv', target_idx=150)\n",
    "stream.prepare_for_use()\n",
    "dataset_name = \"dataset_1_normalized\"\n",
    "n_selected_ftr = 38 #25 are informative\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv('datasets/Regression/dataset_1_norm_test.csv')\n",
    "test_x = test_data.drop(columns=\"y\").to_numpy()\n",
    "test_y = test_data[\"y\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare folder for plots\n",
    "folder = \"plots/regression/{}\".format(dataset_name)\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "export_type = \"pdf\" # \"png\", \"jpeg\", \"webp\", \"pdf\", \"svg\""
   ]
  },
  {
   "source": [
    "### Without FS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "predictor = SGDRegressor()\n",
    "X, y = stream.next_sample(batch_size=100)\n",
    "predictor.partial_fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_rmse = []\n",
    "while stream.has_more_samples():\n",
    "    x, y = stream.next_sample(batch_size=100)\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x)\n",
    "    \n",
    "    pure_rmse.append(mean_squared_error(y, y_pred, squared=False))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x, y)\n",
    "\n",
    "\n",
    "y_pred = predictor.predict(test_x)\n",
    "pure_rmse_test = mean_squared_error(test_y, y_pred, squared=False)"
   ]
  },
  {
   "source": [
    "### FIRES for Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGDRegressor as predictor\n",
    "stream.restart()\n",
    "predictor = SGDRegressor()\n",
    "X, y = stream.next_sample(batch_size=100)\n",
    "predictor.partial_fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_model = FIRES(n_total_ftr=stream.n_features,\n",
    "                    target_values=None,\n",
    "                    mu_init=0,\n",
    "                    sigma_init=1,\n",
    "                    model='regression')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_mse = []\n",
    "fires_rmse = []\n",
    "fires_msa = []\n",
    "fires_r2 = []\n",
    "fires_times = []\n",
    "\n",
    "fires_selected_ftrs = []\n",
    "fires_stability = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=100)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    ftr_weights = fires_model.weigh_features(x,y)\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    fires_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    fires_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(fires_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(fires_selected_ftrs[-10:])\n",
    "        fires_stability.append(stability)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    fires_mse.append(mean_squared_error(y, y_pred, squared=True))\n",
    "    fires_rmse.append(mean_squared_error(y, y_pred, squared=False))\n",
    "    fires_r2.append(r2_score(y,y_pred))\n",
    "    \n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "fires_run_time = timer() - start_time_all\n",
    "print(\"The whole fires run took {}\".format(fires_run_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_x)\n",
    "fires_mse_test = mean_squared_error(test_y, y_pred, squared=False)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(fires_mse_test))"
   ]
  },
  {
   "source": [
    "### Feature selection via SGDRegressor\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGDRegressor as predictor\n",
    "stream.restart()\n",
    "predictor = SGDRegressor()\n",
    "X, y = stream.next_sample(batch_size=100)\n",
    "predictor.partial_fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr_model = SGDRegressor(penalty=\"l1\") #penalty could be elasticnet as well\n",
    "#n_selectey_ftrs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr_mse = []\n",
    "sgdr_rmse = []\n",
    "sgdr_mae = []\n",
    "sgdr_r2 = []\n",
    "\n",
    "sgdr_times = []\n",
    "\n",
    "sgdr_selected_ftrs = []\n",
    "sgdr_stability = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "start_time_all = timer()\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=100)\n",
    "    # Select features\n",
    "    start_time = timer()\n",
    "    sgdr_model.partial_fit(x,y)\n",
    "    ftr_weights = sgdr_model.coef_\n",
    "    ftr_selection = np.argsort(ftr_weights)[::-1][:n_selected_ftr]\n",
    "    sgdr_times.append(timer()-start_time)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "    # stability test\n",
    "    ftr_array = np.zeros(stream.n_features)\n",
    "    ftr_array[ftr_selection] = 1\n",
    "    sgdr_selected_ftrs.append(ftr_array)\n",
    "\n",
    "    if len(sgdr_selected_ftrs) >= 10:\n",
    "        stability = stability_factor(sgdr_selected_ftrs[-10:])\n",
    "        sgdr_stability.append(stability)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "    \n",
    "    sgdr_mse.append(mean_squared_error(y, y_pred))\n",
    "    sgdr_rmse.append(mean_squared_error(y, y_pred, squared=False))\n",
    "    sgdr_r2.append(r2_score(y,y_pred))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)\n",
    "\n",
    "# Restart the FileStream\n",
    "end_time_all = timer()\n",
    "sgdr_run_time = timer() - start_time_all\n",
    "print(\"The whole sgdr run took {}\".format(sgdr_run_time))\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_x)\n",
    "sgdr_mse_test = mean_squared_error(test_y, y_pred, squared=False)\n",
    "print(\"For the test dataset the previous trained predictor reached: {}\".format(sgdr_mse_test))"
   ]
  },
  {
   "source": [
    "### Random FS\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.restart()\n",
    "predictor = SGDRegressor()\n",
    "X, y = stream.next_sample(batch_size=100)\n",
    "predictor.partial_fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rmse = []\n",
    "\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=100)\n",
    "\n",
    "    \n",
    "    # select features\n",
    "    ftr_selection = np.random.choice(len(x[0]), n_selected_ftr)\n",
    "\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, ftr_selection] = x[:, ftr_selection]\n",
    "\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x_reduced)\n",
    "\n",
    "    random_rmse.append(mean_squared_error(y, y_pred, squared=False))\n",
    "    \n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_x)\n",
    "random_rmse_test = mean_squared_error(test_y, y_pred, squared=False)"
   ]
  },
  {
   "source": [
    "### Plot all\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability\n",
    "title = \"Stability on dataset {}\".format(dataset_name)\n",
    "col_names = [\"FIRES\", \"SGDR\"]\n",
    "d = {\"FIRES\":fires_stability, \"SGDR\":sgdr_stability}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y = col_names, title=title, labels={\"index\":\"batches\", \"value\":\"stability\"}, color_discrete_map={'FIRES': 'red', \"SGDR\": \"green\"})\n",
    "stability_trace = fig[\"data\"]\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"RMSE on dataset {}\".format(dataset_name)\n",
    "col_names = [\"Pure\", \"FIRES\", \"SGDR\", \"Random\"]\n",
    "d = {\"Pure\":pure_rmse, \"FIRES\":fires_rmse, \"SGDR\":sgdr_rmse, \"Random\":random_rmse}\n",
    "df = pd.DataFrame(d, columns=col_names)\n",
    "fig = px.line(df, y = col_names, title=title, labels={\"index\":\"batches\", \"value\":\"rmse\"}, color_discrete_map={\"Pure\":'blue','FIRES': 'red', \"SGDR\": \"green\", \"Random\":\"cyan\"})\n",
    "rmse_trace = fig[\"data\"]\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pure_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1) # subplot_titles=(\"Stability\",\"Accuracy\", \"F1-Score\"),\n",
    "for i in range(len(stability_trace)):\n",
    "    stability_trace[i][\"showlegend\"] = False\n",
    "    if stability_trace[i][\"name\"] == \"FIRES\":\n",
    "        trace = stability_trace[i]\n",
    "    else:\n",
    "        fig.add_trace(stability_trace[i], row=1, col=1)\n",
    "fig.add_trace(trace, row=1, col=1)\n",
    "for i in range(len(rmse_trace)):\n",
    "    if rmse_trace[i][\"name\"] == \"FIRES\":\n",
    "        trace = rmse_trace[i]\n",
    "    else:\n",
    "        fig.add_trace(rmse_trace[i], row=2, col=1)\n",
    "fig.add_trace(trace, row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"batches\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Stability\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"RMSE\", row=2, col=1)\n",
    "\n",
    "fig.write_image(\"{}/all_scores_{}.{}\".format(folder, dataset_name, export_type))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"FIRES\", \"SGDR\" ]\n",
    "values = [fires_run_time, sgdr_run_time]\n",
    "fig = px.bar(x=col_names, y=values, title=\"Runtime\", labels={\"y\":\"s\", \"x\":\"\"}, color=col_names, color_discrete_map={'FIRES': 'red', \"SGDR\": \"blue\"})\n",
    "with open(\"{}/runtime.csv\".format(folder),\"a\") as outfile:\n",
    "    outfile.write(\"{},{}\\n\".format( values[0],values[1]) )\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [pure_rmse_test, fires_mse_test, sgdr_mse_test, random_rmse_test]\n",
    "with open(\"{}/rmse.csv\".format(folder),\"a\") as outfile:\n",
    "    outfile.write(\"{},{},{},{}\\n\".format( values[0],values[1], values[2], values[3]))\n"
   ]
  }
 ]
}