{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## OFS via Sparse Projection\n",
    "\n",
    "As given by Online Feature Selection and its Applications.\n",
    "\n",
    "- shouldn't the threshold within the training function be zero not one?\n",
    "- the original code wasn't available anymore\n",
    "  - neither here https://www.stevenhoi.com/publications\n",
    "  - or here http://OFS.stevenhoi.org/\n",
    "- found implementations:\n",
    "  - matlap: https://github.com/Isilendil/OFS\n",
    "  - java: https://github.com/mbdemoraes/moafs\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "df = pd.read_csv(\"datasets/binary/shuffle_spambase.csv\")\n",
    "df_class_col = df['class']\n",
    "df_class_col\n",
    "\n",
    "df_scaled = pd.DataFrame(sc.fit_transform(df))\n",
    "df_scaled.columns = df.columns\n",
    "\n",
    "df_scaled['class'] = df_class_col\n",
    "df_scaled.head()\n",
    "df_scaled.to_csv(\"datasets/binary/shuffle_spambase_normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ofs via sparse projection\n",
    "import numpy as np\n",
    "\n",
    "class OFS:\n",
    "    def __init__(self, regularization_param, step_size, n_selected_ftr, n_total_ftr):\n",
    "        self.regularization_param = regularization_param\n",
    "        self.step_size = step_size\n",
    "        self.n_selected_ftr = n_selected_ftr\n",
    "        self.w = np.zeros(n_total_ftr)\n",
    "    \n",
    "\n",
    "    def train(self, x, y):\n",
    "        if y == 0:\n",
    "            y = -1\n",
    "\n",
    "        if np.dot(x, self.w) * y <= 1: # should be 0, shouldn't it\n",
    "            w_tilde = (1-self.regularization_param * self.step_size)*self.w + self.step_size * y * x\n",
    "            w_hat = min(1, (1/np.sqrt(self.regularization_param)) / np.linalg.norm(w_tilde) )*w_tilde\n",
    "            self.w = self.__truncate(w_hat, self.n_selected_ftr)\n",
    "        else:\n",
    "            self.w *= (1-self.regularization_param*self.step_size)\n",
    "\n",
    "    def __truncate(self, weights_array, B):\n",
    "        w = np.zeros(len(weights_array))\n",
    "        indices = np.argsort(weights_array)[::-1][:B-1]\n",
    "        w[indices] = weights_array[indices]\n",
    "        return w\n",
    "\n",
    "    def get_feature_indices(self):\n",
    "        return np.argsort(self.w)[::-1][:self.n_selected_ftr - 1]\n",
    "        #return only indices where value is greater zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use OFS\n",
    "import numpy as np\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stream = FileStream('datasets/binary/shuffle_spambase_normalized.csv', target_idx=57)\n",
    "stream.prepare_for_use()\n",
    "\n",
    "x,y = stream.next_sample(batch_size=100)\n",
    "predictor = PerceptronMask()\n",
    "predictor.partial_fit(x,y, stream.target_values)\n",
    "\n",
    "n_selected_ftr = 10\n",
    "\n",
    "ofs = OFS(regularization_param = 0.01, step_size = 0.1, n_selected_ftr=n_selected_ftr, n_total_ftr=stream.n_num_features)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "while stream.has_more_samples():\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample(batch_size=10)\n",
    "\n",
    "    # Select features\n",
    "    for idx, label in enumerate(y):\n",
    "        ofs.train(x[idx],label)\n",
    "\n",
    "    selected_ftr = ofs.get_feature_indices()\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, selected_ftr] = x[:, selected_ftr]\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x)\n",
    "    accuracy.append(accuracy_score(y, y_pred))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x, y)\n",
    "\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.show()\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  },
  {
   "source": [
    "### Multiclass Case\n",
    "- more then one vector perceptron\n",
    "- maybe build mean over all vectors befor truncation\n",
    "\n",
    "#### Idea\n",
    "- calculate $\\hat{w}$ and $\\tilde{w}$ seperatly for the vector of the actual class(y) and the one of the predicted one (p)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbspif predicton(x) != y:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp&nbsp;&nbsp;&nbsp;&nbsp$\\tilde{w}_y$ = (1-$\\lambda\\eta$)$w_{ty}$ + $\\eta$*x  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp&nbsp;&nbsp;&nbsp;&nbsp$\\hat{w}_y$ = min{1, $\\frac{\\frac{1}{\\lambda}}{||\\tilde{w}_y||_2}\\tilde{w}_y$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp&nbsp;&nbsp;&nbsp;&nbsp$w_{t+1y}$ = Truncate( $\\hat{w}_y$ , B)  \n",
    "  \n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp&nbsp;&nbsp;&nbsp;&nbsp$\\tilde{w}_p$ = (1-$\\lambda\\eta$)$w_{tp}$ - $\\eta$*x  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp&nbsp;&nbsp;&nbsp;&nbsp$\\hat{w}_p$ = min{1, $\\frac{\\frac{1}{\\lambda}}{||\\tilde{w}_p||_2}\\tilde{w}_p$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp&nbsp;&nbsp;&nbsp;&nbsp$w_{t+1p}$ = Truncate( $\\hat{w}_p$ , B)  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC_OFS:\n",
    "    def __init__(self, regularization_param, step_size, n_selected_ftr, n_total_ftr, n_classes):\n",
    "        self.regularization_param = regularization_param\n",
    "        self.step_size = step_size\n",
    "        self.n_selected_ftr = n_selected_ftr\n",
    "        self.w = np.zeros((n_classes, n_total_ftr))\n",
    "\n",
    "    def train(self, x, y):\n",
    "\n",
    "        predictions = np.dot(self.w, x)\n",
    "        print(\"Predictions: {}\".format(predictions))\n",
    "        prediction = np.where(predictions == np.amax(predictions))[0][0]\n",
    "        print(\"Prediction: {}, class: {}\".format(prediction, y))\n",
    "        if y != prediction:\n",
    "            print(\"{} \\n {}\".format(self.w[prediction], self.w[y]))\n",
    "            #reduce wrong\n",
    "            w_tilde = (1-self.regularization_param * self.step_size)*self.w[prediction] - self.step_size  * x\n",
    "            w_hat = min(1, (1/np.sqrt(self.regularization_param)) / np.linalg.norm(w_tilde) )*w_tilde\n",
    "            self.w[prediction] = self.__truncate(w_hat, self.n_selected_ftr)\n",
    "\n",
    "            #increase right\n",
    "            w_tilde = (1-self.regularization_param * self.step_size)*self.w[y] + self.step_size * x\n",
    "            w_hat = min(1, (1/np.sqrt(self.regularization_param)) / np.linalg.norm(w_tilde) )*w_tilde\n",
    "            self.w[y] = self.__truncate(w_hat, self.n_selected_ftr)\n",
    "        else:\n",
    "            self.w[y] *= (1-self.regularization_param*self.step_size)\n",
    "\n",
    "    def __truncate(self, weights_array, B):\n",
    "        w = np.zeros(len(weights_array))\n",
    "        indices = np.argsort(weights_array)[::-1][:B-1]\n",
    "        w[indices] = weights_array[indices]\n",
    "        return w\n",
    "\n",
    "    def get_feature_indices(self):\n",
    "        w_mean = np.mean(self.w, axis=0)\n",
    "        return np.argsort(w_mean)[::-1][:self.n_selected_ftr - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test\n",
    "import numpy as np\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stream = FileStream('datasets/Multiclass/mnist_train_normalized.csv', target_idx=0)\n",
    "stream.prepare_for_use()\n",
    "\n",
    "x,y = stream.next_sample(batch_size=100)\n",
    "predictor = PerceptronMask()\n",
    "predictor.partial_fit(x,y, stream.target_values)\n",
    "\n",
    "n_selected_ftr = 100\n",
    "\n",
    "ofs = MC_OFS(regularization_param = 0.01, step_size = 0.1, n_selected_ftr=n_selected_ftr, n_total_ftr=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "i = 0\n",
    "#while stream.has_more_samples():\n",
    "while i < 3: # only for checking code errors\n",
    "    # Load a new sample\n",
    "    x, y = stream.next_sample()\n",
    "\n",
    "    # Select features\n",
    "    ofs.train(x[0],y[0])\n",
    "\n",
    "    selected_ftr = ofs.get_feature_indices()\n",
    "    # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "    x_reduced = np.zeros(x.shape)\n",
    "    x_reduced[:, selected_ftr] = x[:, selected_ftr]\n",
    "\n",
    "    # Test\n",
    "    y_pred = predictor.predict(x)\n",
    "    accuracy.append(accuracy_score(y, y_pred))\n",
    "\n",
    "    # Train\n",
    "    predictor.partial_fit(x, y)\n",
    "    i += 1\n",
    "\n",
    "#plt.plot(accuracy)\n",
    "#plt.show()\n",
    "# Restart the FileStream\n",
    "stream.restart()"
   ]
  }
 ]
}