{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### OFS with sparse gradient\n",
    "- as given by \"An online approach for feature selection for classification in big data\"\n",
    "- no implementation found\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean of dataset, as recommended by the paper, not necessary\n",
    "import pandas as pd \n",
    "df = pd.read_csv('datasets/binary/shuffle_spambase.csv')\n",
    "df = df.drop(labels='class', axis=1)\n",
    "ftr_means = df.mean()\n",
    "total_mean = ftr_means.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OFSSGD:\n",
    "    def __init__(self, reduction_threshold, reduction_value, n_total_ftrs, regularization_param, step_size):\n",
    "        try:\n",
    "            if len(reduction_threshold) == n_total_ftrs:\n",
    "                self.vartheta = reduction_threshold\n",
    "            else:\n",
    "                raise ValueError(\"threshold vector and amount of features is not matching\")\n",
    "        except TypeError as e:\n",
    "            self.vartheta = np.ones(n_total_ftrs) * reduction_threshold\n",
    "        self.sigma = reduction_value\n",
    "        self.W = np.zeros(n_total_ftrs)\n",
    "        self.regularization_param = regularization_param\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def __ola(self, x, y):\n",
    "        # copied from ofs \n",
    "        if np.dot(x, self.W) * y <= 1: # should be 0, shouldn't it\n",
    "            w_tilde = (1-self.regularization_param * self.step_size)*self.W + self.step_size * y * x\n",
    "            w_hat = min(1, (1/np.sqrt(self.regularization_param)) / np.linalg.norm(w_tilde) )*w_tilde\n",
    "            self.W = w_hat\n",
    "        else:\n",
    "            self.W *= (1-self.regularization_param*self.step_size)\n",
    "\n",
    "    def __SGr(self):\n",
    "\n",
    "        for i in range(len(self.W)):\n",
    "            if self.W[i] > 0 and self.W[i] < self.vartheta[i]:\n",
    "                self.W[i] = max(0, self.W[i] - self.sigma)\n",
    "            elif self.W[i] < 0 and self.W[i] > -self.vartheta[i]:\n",
    "                self.W[i] = min(0, self.W[i] + self.sigma)\n",
    "\n",
    "\n",
    "    def train(self, x, y):\n",
    "        self.__ola(x,y)\n",
    "        self.__SGr()\n",
    "            \n",
    "    def get_weights(self):\n",
    "        return np.where(self.W != 0)[0]    \n",
    "        # i suppose that all featurs with weight unequal zero are kept\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stream = FileStream('datasets/binary/shuffle_spambase.csv', target_idx=57)\n",
    "stream.prepare_for_use()\n",
    "\n",
    "x,y = stream.next_sample(batch_size=100)\n",
    "predictor = PerceptronMask()\n",
    "predictor.partial_fit(x,y, stream.target_values)\n",
    "\n",
    "n_selected_ftr = 10\n",
    "\n",
    "ofssgd = OFSSGD(reduction_threshold=ftr_means, reduction_value=0.2, regularization_param=0.01, step_size=0.2, n_total_ftrs=stream.n_num_features)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    while stream.has_more_samples():\n",
    "        # Load a new sample\n",
    "        x, y = stream.next_sample(batch_size=10)\n",
    "\n",
    "        # Select features\n",
    "        for idx, label in enumerate(y):\n",
    "            if label == 0:\n",
    "                label = -1\n",
    "\n",
    "            ofssgd.train(x[idx],label)\n",
    "\n",
    "        selected_ftr = ofssgd.get_weights()\n",
    "        # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "        x_reduced = np.zeros(x.shape)\n",
    "        x_reduced[:, selected_ftr] = x[:, selected_ftr]\n",
    "\n",
    "        # Test\n",
    "        y_pred = predictor.predict(x)\n",
    "        accuracy.append(accuracy_score(y, y_pred))\n",
    "\n",
    "        # Train\n",
    "        predictor.partial_fit(x, y)\n",
    "\n",
    "    # Restart the FileStream\n",
    "    stream.restart()\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.show()\n",
    "print(\"Amount of selected features: {}\".format(len(selected_ftr)))"
   ]
  },
  {
   "source": [
    "### Multiclass varition\n",
    "- use multiclass OFS\n",
    "- apply sgd only on updated vectors\n",
    "- how to find selected ftrs:\n",
    "    - mean zero or below threshold?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC_OFSSGD:\n",
    "    def __init__(self, reduction_threshold, reduction_value, n_total_ftrs, regularization_param, step_size, n_classes):\n",
    "        try:\n",
    "            if len(reduction_threshold) == n_total_ftrs:\n",
    "                self.vartheta = reduction_threshold\n",
    "            else:\n",
    "                raise ValueError(\"threshold vector and amount of features is not matching\")\n",
    "        except TypeError as e:\n",
    "            self.vartheta = np.ones(n_total_ftrs) * reduction_threshold\n",
    "        self.sigma = reduction_value\n",
    "        self.W = np.zeros((n_classes, n_total_ftrs))\n",
    "        self.regularization_param = regularization_param\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def __ola(self, x, y):\n",
    "        predictions = np.dot(self.W, x)\n",
    "        print(\"Predictions: {}\".format(predictions))\n",
    "        prediction = np.where(predictions == np.amax(predictions))[0][0]\n",
    "        print(\"Prediction: {}, class: {}\".format(prediction, y))\n",
    "        if y != prediction:\n",
    "            #print(\"{} \\n {}\".format(self.W[prediction], self.W[y]))\n",
    "            #reduce wrong\n",
    "            w_tilde = (1-self.regularization_param * self.step_size)*self.W[prediction] - self.step_size  * x\n",
    "            w_hat = min(1, (1/np.sqrt(self.regularization_param)) / np.linalg.norm(w_tilde) )*w_tilde\n",
    "            self.W[prediction] = w_hat\n",
    "\n",
    "            #increase right\n",
    "            w_tilde = (1-self.regularization_param * self.step_size)*self.W[y] + self.step_size * x\n",
    "            w_hat = min(1, (1/np.sqrt(self.regularization_param)) / np.linalg.norm(w_tilde) )*w_tilde\n",
    "            self.W[y] = w_hat\n",
    "            self.__SGr(y, prediction)\n",
    "        else:\n",
    "            self.W[y] *= (1-self.regularization_param*self.step_size)\n",
    "            self.__SGr(y)\n",
    "\n",
    "    def __SGr(self, y , prediction=None):\n",
    "\n",
    "        for i in range(len(self.W[y])):\n",
    "            if self.W[y,i] > 0 and self.W[y,i] < self.vartheta[i]:\n",
    "                self.W[y,i] = max(0, self.W[y,i] - self.sigma)\n",
    "            elif self.W[y,i] < 0 and self.W[y,i] > -self.vartheta[i]:\n",
    "                self.W[y,i] = min(0, self.W[y,i] + self.sigma)\n",
    "        if prediction != None:\n",
    "            for i in range(len(self.W[y])):\n",
    "                if self.W[prediction,i] > 0 and self.W[prediction,i] < self.vartheta[i]:\n",
    "                    self.W[prediction,i] = max(0, self.W[prediction,i] - self.sigma)\n",
    "                elif self.W[prediction,i] < 0 and self.W[prediction,i] > -self.vartheta[i]:\n",
    "                    self.W[prediction,i] = min(0, self.W[prediction,i] + self.sigma)\n",
    "\n",
    "\n",
    "    def train(self, x, y):\n",
    "        self.__ola(x,y)\n",
    "        # calling it now from __ola to get the updated vectors\n",
    "        # self.__SGr()\n",
    "            \n",
    "    def get_weights(self):\n",
    "        W_mean = np.mean(self.W, axis=0)\n",
    "        return np.where(W_mean != 0)[0]    \n",
    "        # i suppose that all featurs with weight unequal zero are kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('datasets/Multiclass/mnist_test_normalized.csv')\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "ftr_means = df.mean()\n",
    "total_mean = ftr_means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.neural_networks import PerceptronMask\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stream = FileStream('datasets/Multiclass/mnist_test_normalized.csv', target_idx=0)\n",
    "stream.prepare_for_use()\n",
    "\n",
    "x,y = stream.next_sample(batch_size=100)\n",
    "predictor = PerceptronMask()\n",
    "predictor.partial_fit(x,y, stream.target_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "ofssgd = MC_OFSSGD(reduction_threshold=ftr_means, reduction_value=0.2, regularization_param=0.01, step_size=0.2, n_total_ftrs=stream.n_num_features, n_classes=stream.n_classes)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    while stream.has_more_samples():\n",
    "    #if True:\n",
    "        # Load a new sample\n",
    "        x, y = stream.next_sample(batch_size=10)\n",
    "\n",
    "        # Select features\n",
    "        for idx, label in enumerate(y):\n",
    "            ofssgd.train(x[idx],label)\n",
    "\n",
    "        selected_ftr = ofssgd.get_weights()\n",
    "        # Truncate x (retain only selected features, 'remove' all others, e.g. by replacing them with 0)\n",
    "        x_reduced = np.zeros(x.shape)\n",
    "        x_reduced[:, selected_ftr] = x[:, selected_ftr]\n",
    "\n",
    "        # Test\n",
    "        y_pred = predictor.predict(x)\n",
    "        accuracy.append(accuracy_score(y, y_pred))\n",
    "\n",
    "        # Train\n",
    "        predictor.partial_fit(x, y)\n",
    "\n",
    "    # Restart the FileStream\n",
    "    stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_ftr)"
   ]
  }
 ]
}