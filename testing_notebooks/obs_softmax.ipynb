{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other test variables, which are self parameters\n",
    "# classes schould be given as int from 0 to k\n",
    "n_total_ftr = 3\n",
    "target_values = [1,2]\n",
    "mu = np.ones((n_total_ftr, len(target_values))) * 0\n",
    "sigma = np.ones((n_total_ftr, len(target_values))) * 1\n",
    "penalty_s = 0.01\n",
    "penalty_r = 0.01\n",
    "epochs = 1\n",
    "lr_mu = 0.01\n",
    "lr_sigma = 0.01\n",
    "no_mc_samples = 2 #10000 # monte carlo samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __softmax(x,y): # needs self in model\n",
    "    # sort observations\n",
    "    print(\"{} {}\".format(\"len(y)\", len(x.shape)))\n",
    "    if len(x.shape) != 2:\n",
    "        # if only one observation array is given, reshape it\n",
    "        # only one ftr should not happen...\n",
    "        x = x.reshape(1,len(x))\n",
    " \n",
    "    observed_classes = np.unique(y)\n",
    "\n",
    "    for obs_class in observed_classes:\n",
    "        # fix access\n",
    "        print(\"obs_class: {}\".format(obs_class))\n",
    "        observations_index = np.where(y == obs_class)[0]\n",
    "        print(observations_index)\n",
    "        x_obs = x[observations_index]\n",
    "        print(x_obs)\n",
    "        n_obs = len(x_obs)\n",
    "        print(n_obs)\n",
    "    \n",
    "        for epoch in range(epochs): #changed to self.epoch in model\n",
    "                \n",
    "                # Iterative update of mu and sigma\n",
    "                try:\n",
    "                    # o number of obs, l number of samples, j features, c classes\n",
    "                    # create 3d array with all r for current observation for multiple observation calculation we would need 4d array\n",
    "                    # r^cl_j = r[l, j, c] lxjxc\n",
    "                    r = np.random.randn(n_obs, no_mc_samples, n_total_ftr, len(target_values))\n",
    "                    #r = np.array([[[-0.558, 1.555], [0.325, -0.726], [0.347,-0.159]],\n",
    "                    #              [[-0.955, 0.283], [0.115,-1.637], [-0.516,0.161]]])  \n",
    "                    print(r)\n",
    "                    # we only change the psi for the actuall given class still need all classes of course\n",
    "                    # r = np.random.randn(monte_carlo, n_total_ftr)\n",
    "\n",
    "                    print(r.shape)\n",
    "                    # calculate thetas for all samples and classes theta^cl_jt = theta[l,j,c]\n",
    "                    # oxlxjxc\n",
    "                    theta = r * sigma + mu\n",
    "                    print(theta.shape)\n",
    "                    print(theta)\n",
    "                    #calculate all the etas\n",
    "                    eta = np.einsum(\"oljc,oj->oljc\", theta, x_obs) # multiply all ftr_cols with given ftr_vector x\n",
    "                    print('theta * x:')\n",
    "                    print(eta)\n",
    "                    eta = np.einsum(\"oljc->olc\", eta) #sum up all theta^cl_j * x_tj so we got l samples for all c classes\n",
    "                    print(\"eta:\")\n",
    "                    print(eta)\n",
    "                    eta = np.exp(eta) # we only need them exp\n",
    "                    print(\"eta_exp:\")\n",
    "                    print(eta)\n",
    "                    print(eta.shape)\n",
    "                    eta_sum = np.einsum(\"olc->ol\", eta) #sum up etas for the l samples\n",
    "                    print(\"eta_sum:\")\n",
    "                    print(eta_sum)\n",
    "                    print(eta_sum.shape)\n",
    "                    #calculate softmax only for observed class\n",
    "                    #observation_etas = eta[:,y] with more observations we need transposition\n",
    "                    obs_eta = eta[:,:,obs_class]\n",
    "                    print(\"Obs_eta shape: {}\".format(obs_eta.shape))\n",
    "                    softmax_lh = obs_eta / eta_sum # \n",
    "                    print(softmax_lh)\n",
    "                    print(softmax_lh.shape) #should be oxl\n",
    "                    #marginal = np.einsum(\"lo->o\", softmax_lh) / monte_carlo # 1xy\n",
    "                    marginal = np.einsum(\"ol->o\", softmax_lh) / no_mc_samples\n",
    "                    print(marginal.shape) #should be o\n",
    "                    print(marginal)\n",
    "                    # calculate derivatives nabla_mu, nabla_sigma must be handled better\n",
    "\n",
    "                    #first calculate softmax dtheta\n",
    "                    # x_eta means observations x times the beloning etas\n",
    "                    x_eta = np.einsum(\"oj,ol->olj\", x_obs, obs_eta)\n",
    "                    print(x_eta)\n",
    "\n",
    "                    softmax_derivative = np.einsum(\"olj,ol->olj\", x_eta, (eta_sum - obs_eta))\n",
    "                    softmax_derivative = np.einsum(\"olj->jol\", softmax_derivative) /  eta_sum**2\n",
    "                    softmax_derivative = np.einsum(\"jol->olj\", softmax_derivative)\n",
    "                    print(softmax_derivative.shape)\n",
    "                    print(softmax_derivative)\n",
    "                    nabla_mu = np.einsum(\"olj->oj\", softmax_derivative) / no_mc_samples\n",
    "                    print(nabla_mu.shape) #oj\n",
    "                    print(nabla_mu)\n",
    "                    r_jc = r[:,:,:,obs_class]\n",
    "                    print(r_jc.shape)\n",
    "                    nabla_sigma = np.einsum(\"olj->oj\", softmax_derivative * r_jc) / no_mc_samples\n",
    "                    print(nabla_sigma.shape) #oj\n",
    "                    # Update parameters\n",
    "                    mu[:,obs_class] += lr_mu * np.einsum(\"jo->j\", (nabla_mu.T / marginal))\n",
    "                    sigma[:,obs_class] += lr_sigma * np.einsum(\"jo->j\",(nabla_sigma.T / marginal))\n",
    "                    \n",
    "\n",
    "                except TypeError as e:\n",
    "                        raise TypeError('All features must be a numeric data type.') from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(y) 1\nobs_class: 0\n[0]\n[[1 2 3]]\n1\n[[[[ 0.55337784  0.57773496]\n   [ 0.65122606 -0.12512872]\n   [ 0.67635371 -0.35135007]]\n\n  [[ 0.4028947   0.057346  ]\n   [ 0.35996952 -1.32636098]\n   [ 0.52585572 -0.55072548]]]]\n(1, 2, 3, 2)\n(1, 2, 3, 2)\n[[[[ 0.55337784  0.58158716]\n   [ 0.65122606 -0.105573  ]\n   [ 0.67635371 -0.31165715]]\n\n  [[ 0.4028947   0.06669203]\n   [ 0.35996952 -1.31013804]\n   [ 0.52585572 -0.5054496 ]]]]\ntheta * x:\n[[[[ 0.55337784  0.58158716]\n   [ 1.30245213 -0.211146  ]\n   [ 2.02906113 -0.93497145]]\n\n  [[ 0.4028947   0.06669203]\n   [ 0.71993905 -2.62027607]\n   [ 1.57756715 -1.51634881]]]]\neta:\n[[[ 3.88489109 -0.56453029]\n  [ 2.7004009  -4.06993285]]]\neta_exp:\n[[[4.86616424e+01 5.68627172e-01]\n  [1.48856982e+01 1.70785353e-02]]]\n(1, 2, 2)\neta_sum:\n[[49.23026953 14.9027767 ]]\n(1, 2)\nObs_eta shape: (1, 2)\n[[0.98844964 0.998854  ]]\n(1, 2)\n(1,)\n[0.99365182]\n[[[ 48.66164236  97.32328471 145.98492707]\n  [ 14.88569817  29.77139633  44.6570945 ]]]\n(1, 2, 3)\n[[[0.01141695 0.02283389 0.03425084]\n  [0.00114468 0.00228937 0.00343405]]]\n(1, 3)\n[[0.00628081 0.01256163 0.01884244]]\n(1, 2, 3)\n(1, 3)\n"
     ]
    }
   ],
   "source": [
    "y = np.array((0))\n",
    "x = np.array((1,2,3))\n",
    "__softmax(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.00003411, 0.98944284],\n",
       "       [1.00007897, 1.00277446],\n",
       "       [1.00012566, 0.97199775]])"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(np.array((1,1))):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "x = np.array((1,2,3,1,2,4,3,2))\n",
    "x.reshape(1,8)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x: (2, 2) theta: (2, 2, 2, 2)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.],\n",
       "         [ 6.,  8.]],\n",
       "\n",
       "        [[ 1.,  2.],\n",
       "         [ 6.,  8.]]],\n",
       "\n",
       "\n",
       "       [[[ 3.,  6.],\n",
       "         [12., 16.]],\n",
       "\n",
       "        [[ 3.,  6.],\n",
       "         [12., 16.]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "theta = np.ones((2,2,2,2)) * np.array(([1,2],[3,4]))\n",
    "x = np.array(([1,2], [3,4]))\n",
    "print(\"x: {} theta: {}\".format(x.shape, theta.shape))\n",
    "np.einsum(\"oljc,oj->oljc\", theta, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.        , 0.5       ],\n",
       "       [0.33333333, 0.25      ]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "np.ones((2,2)) / np.array(([1,2],[3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# test for obs_eta eta[:,:,y]\n",
    "test = np.array([[1,2,3],[1,2,3],[1,2,3],[1,2,3]])\n",
    "len(test[[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[1 2 3 4]\n  [4 5 6 7]]\n\n [[1 2 3 4]\n  [4 5 6 7]]\n\n [[1 2 3 4]\n  [4 5 6 7]]]\n[[[1 2 3 4]\n  [1 2 3 4]\n  [1 2 3 4]]\n\n [[4 5 6 7]\n  [4 5 6 7]\n  [4 5 6 7]]]\n[[[1.         2.         3.         4.        ]\n  [0.5        1.         1.5        2.        ]\n  [0.33333333 0.66666667 1.         1.33333333]]\n\n [[4.         5.         6.         7.        ]\n  [2.         2.5        3.         3.5       ]\n  [1.33333333 1.66666667 2.         2.33333333]]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1.        , 2.        , 3.        , 4.        ],\n",
       "        [4.        , 5.        , 6.        , 7.        ]],\n",
       "\n",
       "       [[0.5       , 1.        , 1.5       , 2.        ],\n",
       "        [2.        , 2.5       , 3.        , 3.5       ]],\n",
       "\n",
       "       [[0.33333333, 0.66666667, 1.        , 1.33333333],\n",
       "        [1.33333333, 1.66666667, 2.        , 2.33333333]]])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "#test calculate derivative\n",
    "test =np.array((np.array((np.array((1,2,3,4)), np.array((4,5,6,7)))), np.array((np.array((1,2,3,4)), np.array((4,5,6,7)))), np.array((np.array((1,2,3,4)), np.array((4,5,6,7))))))\n",
    "print(test)\n",
    "test = np.einsum(\"ojl->jol\",test)\n",
    "print(test)\n",
    "der = test / np.array(([1,1,1,1],[2,2,2,2],[3,3,3,3]))\n",
    "print(der)\n",
    "np.einsum(\"jol->ojl\", der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    " a = np.array([[1,2],[3,4]])\n",
    " np.dot(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 3,  6,  9, 12],\n",
       "       [12, 15, 18, 21]])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "np.einsum(\"olj->oj\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1. , 0.5],\n",
       "       [2. , 1. ],\n",
       "       [3. , 1.5]])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "np.array(([1,2,3],[1,2,3])).T / np.array((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}