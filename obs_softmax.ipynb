{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other test variables, which are self parameters\n",
    "# classes schould be given as int from 0 to k\n",
    "n_total_ftr = 3\n",
    "target_values = [1,2]\n",
    "mu = np.ones((n_total_ftr, len(target_values))) * 0\n",
    "sigma = np.ones((n_total_ftr, len(target_values))) * 1\n",
    "penalty_s = 0.01\n",
    "penalty_r = 0.01\n",
    "epochs = 1\n",
    "lr_mu = 0.01\n",
    "lr_sigma = 0.01\n",
    "no_mc_samples = 2 #10000 # monte carlo samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __softmax(x,y): # needs self in model\n",
    "    # sort observations\n",
    "    observed_classes = np.unique(y)\n",
    "\n",
    "    for obs_class in observed_classes:\n",
    "\n",
    "        observations_index = np.where(y == obs_class)[0]\n",
    "        x_obs = x[observations_index]\n",
    "        n_observations = len(x_obs)\n",
    "    \n",
    "        for epoch in range(epochs): #changed to self.epoch in model\n",
    "                \n",
    "                # Iterative update of mu and sigma\n",
    "                try:\n",
    "                    # o number of obs, l number of samples, j features, c classes\n",
    "                    # create 3d array with all r for current observation for multiple observation calculation we would need 4d array\n",
    "                    # r^cl_j = r[l, j, c] lxjxc\n",
    "                    r = np.random.randn(n_obs, no_mc_samples, n_total_ftr, len(target_values))\n",
    "                    #r = np.array([[[-0.558, 1.555], [0.325, -0.726], [0.347,-0.159]],\n",
    "                    #              [[-0.955, 0.283], [0.115,-1.637], [-0.516,0.161]]])  \n",
    "                    print(r)\n",
    "                    # we only change the psi for the actuall given class still need all classes of course\n",
    "                    # r = np.random.randn(monte_carlo, n_total_ftr)\n",
    "\n",
    "                    print(r.shape)\n",
    "                    # calculate thetas for all samples and classes theta^cl_jt = theta[l,j,c]\n",
    "                    # oxlxjxc\n",
    "                    theta = r * sigma + mu\n",
    "                    print(theta.shape)\n",
    "                    print(theta)\n",
    "                    #calculate all the etas\n",
    "                    eta = np.einsum(\"oljc,oj->oljc\", theta, x) # multiply all ftr_cols with given ftr_vector x\n",
    "                    print('theta * x:')\n",
    "                    print(eta)\n",
    "                    eta = np.einsum(\"oljc->olc\", eta) #sum up all theta^cl_j * x_tj so we got l samples for all c classes\n",
    "                    print(\"eta:\")\n",
    "                    print(eta)\n",
    "                    eta = np.exp(eta) # we only need them exp\n",
    "                    print(\"eta_exp:\")\n",
    "                    print(eta)\n",
    "                    print(eta.shape)\n",
    "                    eta_sum = np.einsum(\"olc->ol\", eta) #sum up etas for the l samples\n",
    "                    print(\"eta_sum:\")\n",
    "                    print(eta_sum)\n",
    "                    print(eta_sum.shape)\n",
    "                    #calculate softmax only for observed class\n",
    "                    #observation_etas = eta[:,y] with more observations we need transposition\n",
    "                    obs_eta = eta[:,:,obs_class]\n",
    "                    print(\"Obs_eta shape: {}\".format(obs_eta.shape))\n",
    "                    softmax_lh = obs_eta / eta_sum # \n",
    "                    print(softmax_lh)\n",
    "                    print(softmax_lh.shape) #should be oxl\n",
    "                    #marginal = np.einsum(\"lo->o\", softmax_lh) / monte_carlo # 1xy\n",
    "                    marginal = np.einsum(\"ol->o\", softmax_lh) / no_mc_samples\n",
    "                    print(marginal.shape) #should be o\n",
    "                    print(marginal)\n",
    "                    # calculate derivatives nabla_mu, nabla_sigma must be handled better\n",
    "\n",
    "                    #first calculate softmax dtheta\n",
    "                    # x_eta means observations x times the beloning etas\n",
    "                    x_eta = np.einsum(\"oj,ol->olj\", x_obs, obs_eta)\n",
    "                    print(x_eta)\n",
    "\n",
    "                    softmax_derivative = np.einsum(\"olj,ol->olj\", x_eta, (eta_sum - obs_eta))\n",
    "                    softmax_derivative = np.einsum(\"olj->jol\", softmax_derivative) /  eta_sum**2\n",
    "                    softmax_derivative = np.einsum(\"jol->olj\", softmax_derivative)\n",
    "                    print(softmax_derivative.shape)\n",
    "                    print(softmax_derivative)\n",
    "                    nabla_mu = np.einsum(\"olj->oj\", softmax_derivative) / no_mc_samples\n",
    "                    print(nabla_mu.shape) #oj\n",
    "                    print(nabla_mu)\n",
    "                    r_jc = r[:,:,:,obs_class]\n",
    "                    print(r_jc.shape)\n",
    "                    nabla_sigma = np.einsum(\"olj->oj\", softmax_derivative * r_jc) / no_mc_samples\n",
    "                    print(nabla_sigma.shape) #oj\n",
    "                    # Update parameters\n",
    "                    mu[:,obs_class] += lr_mu * np.einsum(\"jo->j\", (nabla_mu.T / marginal))\n",
    "                    sigma[:,obs_class] += lr_sigma * np.einsum(\"jo->j\",(nabla_sigma.T / marginal))\n",
    "                    \n",
    "\n",
    "                except TypeError as e:\n",
    "                        raise TypeError('All features must be a numeric data type.') from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(np.array((1,1))):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 4, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "np.where(np.array((1,2,3,1,2,4,3,2)) == 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x: (2, 2) theta: (2, 2, 2, 2)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.],\n",
       "         [ 6.,  8.]],\n",
       "\n",
       "        [[ 1.,  2.],\n",
       "         [ 6.,  8.]]],\n",
       "\n",
       "\n",
       "       [[[ 3.,  6.],\n",
       "         [12., 16.]],\n",
       "\n",
       "        [[ 3.,  6.],\n",
       "         [12., 16.]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "theta = np.ones((2,2,2,2)) * np.array(([1,2],[3,4]))\n",
    "x = np.array(([1,2], [3,4]))\n",
    "print(\"x: {} theta: {}\".format(x.shape, theta.shape))\n",
    "np.einsum(\"oljc,oj->oljc\", theta, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.        , 0.5       ],\n",
       "       [0.33333333, 0.25      ]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "np.ones((2,2)) / np.array(([1,2],[3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3],\n",
       "        [1, 2, 3]]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# test for obs_eta eta[:,:,y]\n",
    "test = np.array([[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]]])\n",
    "test\n",
    "test[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[1 2 3 4]\n  [4 5 6 7]]\n\n [[1 2 3 4]\n  [4 5 6 7]]\n\n [[1 2 3 4]\n  [4 5 6 7]]]\n[[[1 2 3 4]\n  [1 2 3 4]\n  [1 2 3 4]]\n\n [[4 5 6 7]\n  [4 5 6 7]\n  [4 5 6 7]]]\n[[[1.         2.         3.         4.        ]\n  [0.5        1.         1.5        2.        ]\n  [0.33333333 0.66666667 1.         1.33333333]]\n\n [[4.         5.         6.         7.        ]\n  [2.         2.5        3.         3.5       ]\n  [1.33333333 1.66666667 2.         2.33333333]]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1.        , 2.        , 3.        , 4.        ],\n",
       "        [4.        , 5.        , 6.        , 7.        ]],\n",
       "\n",
       "       [[0.5       , 1.        , 1.5       , 2.        ],\n",
       "        [2.        , 2.5       , 3.        , 3.5       ]],\n",
       "\n",
       "       [[0.33333333, 0.66666667, 1.        , 1.33333333],\n",
       "        [1.33333333, 1.66666667, 2.        , 2.33333333]]])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "#test calculate derivative\n",
    "test =np.array((np.array((np.array((1,2,3,4)), np.array((4,5,6,7)))), np.array((np.array((1,2,3,4)), np.array((4,5,6,7)))), np.array((np.array((1,2,3,4)), np.array((4,5,6,7))))))\n",
    "print(test)\n",
    "test = np.einsum(\"ojl->jol\",test)\n",
    "print(test)\n",
    "der = test / np.array(([1,1,1,1],[2,2,2,2],[3,3,3,3]))\n",
    "print(der)\n",
    "np.einsum(\"jol->ojl\", der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    " a = np.array([[1,2],[3,4]])\n",
    " np.dot(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 3,  6,  9, 12],\n",
       "       [12, 15, 18, 21]])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "np.einsum(\"olj->oj\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1. , 0.5],\n",
       "       [2. , 1. ],\n",
       "       [3. , 1.5]])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "np.array(([1,2,3],[1,2,3])).T / np.array((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}