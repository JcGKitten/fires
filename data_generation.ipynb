{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Dataset Generation\n",
    "\n",
    "Generation of datasets for multiclass classification and regression cases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Multiclass classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "Because we want to know which are the real informative features, we generate the data without shuffeling.\n",
    "Then we safe the the names of the features with x for informative and y for the rest. Random state is set to 42 so the datasets will always be the same."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset 1\n",
    "20000 samples with 100 features with 15 informative features, 10 classes. \n",
    "There are no redundant or repeated features,\n",
    "all classes have the same weights.\n",
    "\"\"\"\n",
    "data1 = make_classification(n_samples=20000,n_features=100, n_classes=10, n_informative=15, shuffle=False, random_state=42)\n",
    "\n",
    "# create feature names\n",
    "columns = []\n",
    "for i in range(100):\n",
    "    if i < 15:\n",
    "        columns.append(\"x\"+str(i))\n",
    "    else:\n",
    "        columns.append(\"y\"+str(i))\n",
    "\n",
    "# create dataframe\n",
    "data1_df = pd.DataFrame(data1[0], columns=columns)\n",
    "\n",
    "# shuffle features\n",
    "data1_df = data1_df.sample(frac=1, axis=1)\n",
    "\n",
    "# add label\n",
    "data1_df[\"label\"] = data1[1]\n",
    "\n",
    "# shuffle rows\n",
    "data1_df = data1_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split into train and test\n",
    "data1_df_train = data1_df.iloc[:14999,]\n",
    "data1_df_test = data1_df.iloc[15000:,]\n",
    "\n",
    "#write data\n",
    "data1_df_train.to_csv(\"dataset_1_train.csv\", header=False,index=False)\n",
    "data1_df_test.to_csv(\"dataset_1_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Dataset 2\n",
    "50000 samples with 500 features with 80 informative features, 6 classes. \n",
    "There are 50 redundant and repeated features,\n",
    "all classes have the same weights.\n",
    "\"\"\"\n",
    "data2 = make_classification(n_samples=50000,n_features=500, n_classes=6, n_informative=80, n_redundant=50, n_repeated=50, shuffle=False, random_state=42)\n",
    "\n",
    "# create feature names\n",
    "columns = []\n",
    "for i in range(500):\n",
    "    if i < 80:\n",
    "        columns.append(\"x\"+str(i))\n",
    "    else:\n",
    "        columns.append(\"y\"+str(i))\n",
    "\n",
    "# create dataframe\n",
    "data2_df = pd.DataFrame(data2[0], columns=columns)\n",
    "\n",
    "# shuffle features\n",
    "data2_df = data2_df.sample(frac=1, axis=1)\n",
    "\n",
    "# add label\n",
    "data2_df[\"label\"] = data2[1]\n",
    "\n",
    "# shuffle rows\n",
    "data2_df = data2_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split into train and test\n",
    "data2_df_train = data2_df.iloc[:39999,]\n",
    "data2_df_test = data2_df.iloc[40000:,]\n",
    "\n",
    "#write data\n",
    "data2_df_train.to_csv(\"dataset_2_train.csv\", header=False,index=False)\n",
    "data2_df_test.to_csv(\"dataset_2_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset 3\n",
    "5000 samples with 250 features with 20 informative features, 8 classes. \n",
    "There are 50 redundant and repeated features,\n",
    "all classes have the different weights.\n",
    "\n",
    "\"\"\"\n",
    "weights = [0.1, 0.05, 0.15, 0.2, 0.025, 0.125, 0.075, 0.275]\n",
    "data3 = make_classification(n_samples=5000,n_features=250, n_classes=8, n_informative=20, n_redundant=50, n_repeated=50, shuffle=False, random_state=42, weights=weights)\n",
    "\n",
    "# create feature names\n",
    "columns = []\n",
    "for i in range(250):\n",
    "    if i < 20:\n",
    "        columns.append(\"x\"+str(i))\n",
    "    else:\n",
    "        columns.append(\"y\"+str(i))\n",
    "\n",
    "# create dataframe\n",
    "data3_df = pd.DataFrame(data3[0], columns=columns)\n",
    "\n",
    "# shuffle features\n",
    "data3_df = data3_df.sample(frac=1, axis=1)\n",
    "\n",
    "# add label\n",
    "data3_df[\"label\"] = data3[1]\n",
    "\n",
    "# shuffle rows\n",
    "data3_df = data3_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split into train and test\n",
    "data3_df_train = data3_df.iloc[:4199,]\n",
    "data3_df_test = data3_df.iloc[4200:,]\n",
    "\n",
    "#write data\n",
    "data3_df_train.to_csv(\"dataset_3_train.csv\", header=False,index=False)\n",
    "data3_df_test.to_csv(\"dataset_3_test.csv\", index=False)"
   ]
  },
  {
   "source": [
    "### Regression Case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Here we can get the informative features via the coef parameter. So we don't need to shuffle the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['x27', 'x30', 'x31', 'x33', 'x36', 'x37', 'x42', 'x43', 'x44', 'x47',\n       'x50', 'x62', 'x70', 'x71', 'x75', 'x83', 'x84', 'x92', 'x106', 'x111',\n       'x121', 'x127', 'x129', 'x130', 'x134'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataset1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data1 = make_regression(n_samples=20000, n_features=150, n_informative=25, coef=True, random_state=42)\n",
    "\n",
    "data1_df = pd.DataFrame(data1[0], columns = ['x'+str(i) for i in range(150)])\n",
    "\n",
    "data1_df_norm = pd.DataFrame(MinMaxScaler().fit_transform(data1_df))\n",
    "data1_df_norm.columns = data1_df.columns\n",
    "\n",
    "\n",
    "data1_df[\"y\"] = data1[1]\n",
    "data1_df_norm[\"y\"] = data1[1]\n",
    "\n",
    "informative_ftrs = data1_df.columns[np.where(data1[2] != 0)[0]]\n",
    "\n",
    "print(informative_ftrs)\n",
    "\n",
    "# shall labels also be scaled?\n",
    "scaler = MinMaxScaler()\n",
    "data1_df_norm = pd.DataFrame(scaler.fit_transform(data1_df))\n",
    "data1_df_norm.columns = data1_df.columns\n",
    "\n",
    "# split into train and test\n",
    "data1_df_train = data1_df.iloc[:16999,]\n",
    "data1_df_test = data1_df.iloc[17000:,]\n",
    "data1_df_norm_train = data1_df_norm.iloc[:16999,]\n",
    "data1_df_norm_test = data1_df_norm.iloc[17000:,]\n",
    "\n",
    "#write data\n",
    "data1_df_train.to_csv(\"dataset_1_train.csv\", header=False,index=False)\n",
    "data1_df_test.to_csv(\"dataset_1_test.csv\", index=False)\n",
    "data1_df_norm_train.to_csv(\"dataset_1_norm_train.csv\", header=False,index=False)\n",
    "data1_df_norm_test.to_csv(\"dataset_1_norm_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.363295 -0.012783  0.374919  0.260799  0.917397  0.639888 -0.010880   \n",
       "1 -0.726582 -1.445475  1.016521 -0.969239  1.391141 -0.108439 -0.939410   \n",
       "2  1.344817 -0.525121 -1.173074  0.400606  0.039496 -2.424165 -0.611450   \n",
       "3  0.050311  0.439528 -1.876262  0.139468  1.168241 -1.960861 -0.435479   \n",
       "4  1.067035 -0.623631  0.512916  0.825379  0.286030  1.089491  0.356538   \n",
       "\n",
       "         x7        x8        x9  ...      x141      x142      x143      x144  \\\n",
       "0  0.506227 -0.351040 -1.217388  ...  1.091412  0.981406  1.750194  0.182395   \n",
       "1  1.873355 -0.909133  2.001106  ... -0.903256 -0.427354  0.753269 -0.410664   \n",
       "2  1.133134  2.512017 -0.710126  ...  1.229416 -0.368352 -0.771242 -0.810087   \n",
       "3  0.031992  0.395617  0.449874  ... -0.449745  3.290793  0.232329  0.064201   \n",
       "4  0.410469 -1.327049 -0.233147  ... -1.284710  0.812966 -1.351775 -1.103220   \n",
       "\n",
       "       x145      x146      x147      x148      x149           y  \n",
       "0  0.864996  0.795631 -0.433815  2.324069 -1.105584 -377.899587  \n",
       "1  2.061592  0.787312  2.012739 -1.796911  0.455194 -305.270482  \n",
       "2 -0.061102  0.736047 -2.409314  0.354049 -1.319514  224.077706  \n",
       "3  1.600393  0.812813  0.907833 -0.566153  0.086339 -539.531037  \n",
       "4 -1.152273  1.004233  0.875706  1.953713 -1.144131   12.304537  \n",
       "\n",
       "[5 rows x 151 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>...</th>\n      <th>x141</th>\n      <th>x142</th>\n      <th>x143</th>\n      <th>x144</th>\n      <th>x145</th>\n      <th>x146</th>\n      <th>x147</th>\n      <th>x148</th>\n      <th>x149</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.363295</td>\n      <td>-0.012783</td>\n      <td>0.374919</td>\n      <td>0.260799</td>\n      <td>0.917397</td>\n      <td>0.639888</td>\n      <td>-0.010880</td>\n      <td>0.506227</td>\n      <td>-0.351040</td>\n      <td>-1.217388</td>\n      <td>...</td>\n      <td>1.091412</td>\n      <td>0.981406</td>\n      <td>1.750194</td>\n      <td>0.182395</td>\n      <td>0.864996</td>\n      <td>0.795631</td>\n      <td>-0.433815</td>\n      <td>2.324069</td>\n      <td>-1.105584</td>\n      <td>-377.899587</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.726582</td>\n      <td>-1.445475</td>\n      <td>1.016521</td>\n      <td>-0.969239</td>\n      <td>1.391141</td>\n      <td>-0.108439</td>\n      <td>-0.939410</td>\n      <td>1.873355</td>\n      <td>-0.909133</td>\n      <td>2.001106</td>\n      <td>...</td>\n      <td>-0.903256</td>\n      <td>-0.427354</td>\n      <td>0.753269</td>\n      <td>-0.410664</td>\n      <td>2.061592</td>\n      <td>0.787312</td>\n      <td>2.012739</td>\n      <td>-1.796911</td>\n      <td>0.455194</td>\n      <td>-305.270482</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.344817</td>\n      <td>-0.525121</td>\n      <td>-1.173074</td>\n      <td>0.400606</td>\n      <td>0.039496</td>\n      <td>-2.424165</td>\n      <td>-0.611450</td>\n      <td>1.133134</td>\n      <td>2.512017</td>\n      <td>-0.710126</td>\n      <td>...</td>\n      <td>1.229416</td>\n      <td>-0.368352</td>\n      <td>-0.771242</td>\n      <td>-0.810087</td>\n      <td>-0.061102</td>\n      <td>0.736047</td>\n      <td>-2.409314</td>\n      <td>0.354049</td>\n      <td>-1.319514</td>\n      <td>224.077706</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.050311</td>\n      <td>0.439528</td>\n      <td>-1.876262</td>\n      <td>0.139468</td>\n      <td>1.168241</td>\n      <td>-1.960861</td>\n      <td>-0.435479</td>\n      <td>0.031992</td>\n      <td>0.395617</td>\n      <td>0.449874</td>\n      <td>...</td>\n      <td>-0.449745</td>\n      <td>3.290793</td>\n      <td>0.232329</td>\n      <td>0.064201</td>\n      <td>1.600393</td>\n      <td>0.812813</td>\n      <td>0.907833</td>\n      <td>-0.566153</td>\n      <td>0.086339</td>\n      <td>-539.531037</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.067035</td>\n      <td>-0.623631</td>\n      <td>0.512916</td>\n      <td>0.825379</td>\n      <td>0.286030</td>\n      <td>1.089491</td>\n      <td>0.356538</td>\n      <td>0.410469</td>\n      <td>-1.327049</td>\n      <td>-0.233147</td>\n      <td>...</td>\n      <td>-1.284710</td>\n      <td>0.812966</td>\n      <td>-1.351775</td>\n      <td>-1.103220</td>\n      <td>-1.152273</td>\n      <td>1.004233</td>\n      <td>0.875706</td>\n      <td>1.953713</td>\n      <td>-1.144131</td>\n      <td>12.304537</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 151 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0      0.539695  0.451124  0.559326  0.525103  0.653768  0.586027  0.481511   \n",
       "1      0.396130  0.281250  0.646126  0.382438  0.706285  0.493985  0.365994   \n",
       "2      0.668987  0.390376  0.349904  0.541319  0.556449  0.209156  0.406795   \n",
       "3      0.498467  0.504754  0.254772  0.511031  0.681575  0.266141  0.428688   \n",
       "4      0.632396  0.378696  0.577996  0.590586  0.583778  0.641327  0.527221   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995  0.303048  0.397097  0.495176  0.307644  0.467716  0.317082  0.450125   \n",
       "19996  0.249990  0.403292  0.609317  0.550561  0.551938  0.596971  0.382092   \n",
       "19997  0.611281  0.307671  0.573076  0.550150  0.422382  0.556910  0.260108   \n",
       "19998  0.398906  0.516442  0.477008  0.321167  0.762279  0.583806  0.596648   \n",
       "19999  0.612468  0.428362  0.714816  0.473858  0.546581  0.398795  0.549202   \n",
       "\n",
       "             x7        x8        x9  ...      x141      x142      x143  \\\n",
       "0      0.528733  0.459680  0.342833  ...  0.582495  0.652170  0.697513   \n",
       "1      0.688980  0.388020  0.736403  ...  0.350362  0.466225  0.567283   \n",
       "2      0.602215  0.827300  0.404863  ...  0.598555  0.474013  0.368134   \n",
       "3      0.473145  0.555552  0.546712  ...  0.403140  0.956990  0.499232   \n",
       "4      0.517508  0.334359  0.463190  ...  0.305970  0.629937  0.292298   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19995  0.489887  0.365290  0.337080  ...  0.423336  0.389491  0.508987   \n",
       "19996  0.438703  0.485087  0.583505  ...  0.570975  0.359941  0.820436   \n",
       "19997  0.287418  0.417166  0.495153  ...  0.465654  0.568454  0.576269   \n",
       "19998  0.393516  0.542167  0.676879  ...  0.574789  0.512894  0.537328   \n",
       "19999  0.722345  0.499850  0.489066  ...  0.326562  0.431985  0.630175   \n",
       "\n",
       "           x144      x145      x146      x147      x148      x149         y  \n",
       "0      0.516525  0.629170  0.607629  0.483760  0.807431  0.340381  0.300358  \n",
       "1      0.443299  0.775412  0.606506  0.773343  0.292013  0.550230  0.333430  \n",
       "2      0.393982  0.515988  0.599585  0.249934  0.561037  0.311618  0.574471  \n",
       "3      0.501931  0.719046  0.609949  0.642562  0.445946  0.500637  0.226758  \n",
       "4      0.357788  0.382631  0.635791  0.638760  0.761110  0.335198  0.478039  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "19995  0.446840  0.506757  0.500543  0.584103  0.452739  0.679037  0.554957  \n",
       "19996  0.404821  0.435515  0.454742  0.543995  0.472672  0.539340  0.431584  \n",
       "19997  0.460062  0.579696  0.557853  0.460491  0.351093  0.420336  0.432653  \n",
       "19998  0.628543  0.506139  0.609193  0.377617  0.578704  0.351134  0.384493  \n",
       "19999  0.374499  0.530650  0.347490  0.433771  0.725023  0.422903  0.517498  \n",
       "\n",
       "[20000 rows x 151 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>...</th>\n      <th>x141</th>\n      <th>x142</th>\n      <th>x143</th>\n      <th>x144</th>\n      <th>x145</th>\n      <th>x146</th>\n      <th>x147</th>\n      <th>x148</th>\n      <th>x149</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.539695</td>\n      <td>0.451124</td>\n      <td>0.559326</td>\n      <td>0.525103</td>\n      <td>0.653768</td>\n      <td>0.586027</td>\n      <td>0.481511</td>\n      <td>0.528733</td>\n      <td>0.459680</td>\n      <td>0.342833</td>\n      <td>...</td>\n      <td>0.582495</td>\n      <td>0.652170</td>\n      <td>0.697513</td>\n      <td>0.516525</td>\n      <td>0.629170</td>\n      <td>0.607629</td>\n      <td>0.483760</td>\n      <td>0.807431</td>\n      <td>0.340381</td>\n      <td>0.300358</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.396130</td>\n      <td>0.281250</td>\n      <td>0.646126</td>\n      <td>0.382438</td>\n      <td>0.706285</td>\n      <td>0.493985</td>\n      <td>0.365994</td>\n      <td>0.688980</td>\n      <td>0.388020</td>\n      <td>0.736403</td>\n      <td>...</td>\n      <td>0.350362</td>\n      <td>0.466225</td>\n      <td>0.567283</td>\n      <td>0.443299</td>\n      <td>0.775412</td>\n      <td>0.606506</td>\n      <td>0.773343</td>\n      <td>0.292013</td>\n      <td>0.550230</td>\n      <td>0.333430</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.668987</td>\n      <td>0.390376</td>\n      <td>0.349904</td>\n      <td>0.541319</td>\n      <td>0.556449</td>\n      <td>0.209156</td>\n      <td>0.406795</td>\n      <td>0.602215</td>\n      <td>0.827300</td>\n      <td>0.404863</td>\n      <td>...</td>\n      <td>0.598555</td>\n      <td>0.474013</td>\n      <td>0.368134</td>\n      <td>0.393982</td>\n      <td>0.515988</td>\n      <td>0.599585</td>\n      <td>0.249934</td>\n      <td>0.561037</td>\n      <td>0.311618</td>\n      <td>0.574471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.498467</td>\n      <td>0.504754</td>\n      <td>0.254772</td>\n      <td>0.511031</td>\n      <td>0.681575</td>\n      <td>0.266141</td>\n      <td>0.428688</td>\n      <td>0.473145</td>\n      <td>0.555552</td>\n      <td>0.546712</td>\n      <td>...</td>\n      <td>0.403140</td>\n      <td>0.956990</td>\n      <td>0.499232</td>\n      <td>0.501931</td>\n      <td>0.719046</td>\n      <td>0.609949</td>\n      <td>0.642562</td>\n      <td>0.445946</td>\n      <td>0.500637</td>\n      <td>0.226758</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.632396</td>\n      <td>0.378696</td>\n      <td>0.577996</td>\n      <td>0.590586</td>\n      <td>0.583778</td>\n      <td>0.641327</td>\n      <td>0.527221</td>\n      <td>0.517508</td>\n      <td>0.334359</td>\n      <td>0.463190</td>\n      <td>...</td>\n      <td>0.305970</td>\n      <td>0.629937</td>\n      <td>0.292298</td>\n      <td>0.357788</td>\n      <td>0.382631</td>\n      <td>0.635791</td>\n      <td>0.638760</td>\n      <td>0.761110</td>\n      <td>0.335198</td>\n      <td>0.478039</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>0.303048</td>\n      <td>0.397097</td>\n      <td>0.495176</td>\n      <td>0.307644</td>\n      <td>0.467716</td>\n      <td>0.317082</td>\n      <td>0.450125</td>\n      <td>0.489887</td>\n      <td>0.365290</td>\n      <td>0.337080</td>\n      <td>...</td>\n      <td>0.423336</td>\n      <td>0.389491</td>\n      <td>0.508987</td>\n      <td>0.446840</td>\n      <td>0.506757</td>\n      <td>0.500543</td>\n      <td>0.584103</td>\n      <td>0.452739</td>\n      <td>0.679037</td>\n      <td>0.554957</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>0.249990</td>\n      <td>0.403292</td>\n      <td>0.609317</td>\n      <td>0.550561</td>\n      <td>0.551938</td>\n      <td>0.596971</td>\n      <td>0.382092</td>\n      <td>0.438703</td>\n      <td>0.485087</td>\n      <td>0.583505</td>\n      <td>...</td>\n      <td>0.570975</td>\n      <td>0.359941</td>\n      <td>0.820436</td>\n      <td>0.404821</td>\n      <td>0.435515</td>\n      <td>0.454742</td>\n      <td>0.543995</td>\n      <td>0.472672</td>\n      <td>0.539340</td>\n      <td>0.431584</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>0.611281</td>\n      <td>0.307671</td>\n      <td>0.573076</td>\n      <td>0.550150</td>\n      <td>0.422382</td>\n      <td>0.556910</td>\n      <td>0.260108</td>\n      <td>0.287418</td>\n      <td>0.417166</td>\n      <td>0.495153</td>\n      <td>...</td>\n      <td>0.465654</td>\n      <td>0.568454</td>\n      <td>0.576269</td>\n      <td>0.460062</td>\n      <td>0.579696</td>\n      <td>0.557853</td>\n      <td>0.460491</td>\n      <td>0.351093</td>\n      <td>0.420336</td>\n      <td>0.432653</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>0.398906</td>\n      <td>0.516442</td>\n      <td>0.477008</td>\n      <td>0.321167</td>\n      <td>0.762279</td>\n      <td>0.583806</td>\n      <td>0.596648</td>\n      <td>0.393516</td>\n      <td>0.542167</td>\n      <td>0.676879</td>\n      <td>...</td>\n      <td>0.574789</td>\n      <td>0.512894</td>\n      <td>0.537328</td>\n      <td>0.628543</td>\n      <td>0.506139</td>\n      <td>0.609193</td>\n      <td>0.377617</td>\n      <td>0.578704</td>\n      <td>0.351134</td>\n      <td>0.384493</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>0.612468</td>\n      <td>0.428362</td>\n      <td>0.714816</td>\n      <td>0.473858</td>\n      <td>0.546581</td>\n      <td>0.398795</td>\n      <td>0.549202</td>\n      <td>0.722345</td>\n      <td>0.499850</td>\n      <td>0.489066</td>\n      <td>...</td>\n      <td>0.326562</td>\n      <td>0.431985</td>\n      <td>0.630175</td>\n      <td>0.374499</td>\n      <td>0.530650</td>\n      <td>0.347490</td>\n      <td>0.433771</td>\n      <td>0.725023</td>\n      <td>0.422903</td>\n      <td>0.517498</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 151 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data1_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "x0      1.0\n",
       "x1      1.0\n",
       "x2      1.0\n",
       "x3      1.0\n",
       "x4      1.0\n",
       "       ... \n",
       "x146    1.0\n",
       "x147    1.0\n",
       "x148    1.0\n",
       "x149    1.0\n",
       "y       1.0\n",
       "Length: 151, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data1_df_norm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}